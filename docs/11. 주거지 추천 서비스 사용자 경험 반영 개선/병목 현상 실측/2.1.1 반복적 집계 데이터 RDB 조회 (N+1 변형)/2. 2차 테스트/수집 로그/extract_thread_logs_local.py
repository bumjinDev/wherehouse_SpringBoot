#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ìŠ¤ë ˆë“œë³„ ì„±ëŠ¥ ë¡œê·¸ íŒŒì‹± ë° CSV ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ (ë¡œì»¬ í™˜ê²½ìš©)
- 50ê°œ ìŠ¤ë ˆë“œ(http-nio-8185-exec-1 ~ exec-50)ì˜ ì„±ëŠ¥ ë°ì´í„° ì¶”ì¶œ
- Bottleneck Resolved 2.1.1 ë©”íŠ¸ë¦­ íŒŒì‹±
- ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ê²½ë¡œ ìˆ˜ì •
"""

import re
import csv
import os
from collections import defaultdict

def parse_log_file(file_path):
    """
    ë¡œê·¸ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ìŠ¤ë ˆë“œë³„ ì„±ëŠ¥ ë°ì´í„° ì¶”ì¶œ
    """
    
    # ìŠ¤ë ˆë“œë³„ ë°ì´í„° ì €ì¥
    thread_data = defaultdict(list)
    
    # ì •ê·œ í‘œí˜„ì‹ íŒ¨í„´ë“¤
    thread_pattern = r'(\d{2}:\d{2}:\d{2}\.\d{3})\s+\[([^\]]+)\]\s+(\w+)'
    bottleneck_pattern = r'=== \[Bottleneck Resolved: ([\d.]+)\] ==='
    total_time_pattern = r'1\. ì´ ì†Œìš” ì‹œê°„: (\d+)ms'
    rdb_time_pattern = r'2\. RDB ì¡°íšŒ ì‹œê°„ \(Bulk\): (\d+)ms \(ì „ì²´ì˜ ([\d.]+)%\)'
    rdb_count_pattern = r'3\. RDB í˜¸ì¶œ íšŸìˆ˜: (\d+)íšŒ'
    status_pattern = r'ì „ì„¸ ì§€ì—­êµ¬ ì¶”ì²œ ìš”ì²­ ì™„ë£Œ - ìƒíƒœ: (\w+)'
    
    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìŠ¤ë ˆë“œ ì •ë³´
    current_thread_info = {}
    current_thread = None
    current_timestamp = None
    current_log_level = None
    
    # íŒŒì¼ ì½ê¸°
    with open(file_path, 'r', encoding='utf-8') as file:
        for line_num, line in enumerate(file, 1):
            line = line.strip()
            
            # ë¹ˆ ì¤„ ë˜ëŠ” ì¤‘ê°„ ìƒëµ í‘œì‹œ ê±´ë„ˆë›°ê¸°
            if not line or '[ì¤‘ê°„ ìƒëµ]' in line:
                continue
            
            # ìŠ¤ë ˆë“œ ì •ë³´ ì¶”ì¶œ
            thread_match = re.match(thread_pattern, line)
            if thread_match:
                current_timestamp = thread_match.group(1)
                current_thread = thread_match.group(2)
                current_log_level = thread_match.group(3)
            
            # Bottleneck Resolved ì„¹ì…˜ ì‹œì‘
            if 'Bottleneck Resolved' in line and current_thread:
                bottleneck_match = re.search(bottleneck_pattern, line)
                if bottleneck_match:
                    version = bottleneck_match.group(1)
                    # ìƒˆë¡œìš´ ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
                    current_thread_info[current_thread] = {
                        'timestamp': current_timestamp,
                        'log_level': current_log_level,
                        'version': version,
                        'line_number': line_num
                    }
            
            # ì´ ì†Œìš” ì‹œê°„
            elif 'ì´ ì†Œìš” ì‹œê°„' in line and current_thread:
                total_match = re.search(total_time_pattern, line)
                if total_match and current_thread in current_thread_info:
                    current_thread_info[current_thread]['total_time_ms'] = int(total_match.group(1))
            
            # RDB ì¡°íšŒ ì‹œê°„
            elif 'RDB ì¡°íšŒ ì‹œê°„' in line and current_thread:
                rdb_match = re.search(rdb_time_pattern, line)
                if rdb_match and current_thread in current_thread_info:
                    current_thread_info[current_thread]['rdb_time_ms'] = int(rdb_match.group(1))
                    current_thread_info[current_thread]['rdb_percentage'] = float(rdb_match.group(2))
            
            # RDB í˜¸ì¶œ íšŸìˆ˜
            elif 'RDB í˜¸ì¶œ íšŸìˆ˜' in line and current_thread:
                count_match = re.search(rdb_count_pattern, line)
                if count_match and current_thread in current_thread_info:
                    current_thread_info[current_thread]['rdb_call_count'] = int(count_match.group(1))
                    
                    # ì´ ì‹œì ì—ì„œ í•˜ë‚˜ì˜ ì™„ì„±ëœ ë°ì´í„° ì„¸íŠ¸
                    # thread_dataì— ì €ì¥
                    thread_data[current_thread].append(dict(current_thread_info[current_thread]))
            
            # ìƒíƒœ ì •ë³´
            elif 'ì „ì„¸ ì§€ì—­êµ¬ ì¶”ì²œ ìš”ì²­ ì™„ë£Œ' in line and current_thread:
                status_match = re.search(status_pattern, line)
                if status_match and current_thread in current_thread_info:
                    # ê°€ì¥ ìµœê·¼ ë ˆì½”ë“œì— ìƒíƒœ ì¶”ê°€
                    if thread_data[current_thread]:
                        thread_data[current_thread][-1]['status'] = status_match.group(1)
                        thread_data[current_thread][-1]['completion_timestamp'] = current_timestamp
    
    return thread_data

def save_to_csv(thread_data, output_file):
    """
    íŒŒì‹±ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    """
    
    # CSV í—¤ë”
    headers = [
        'thread_name',
        'timestamp',
        'log_level',
        'version',
        'total_time_ms',
        'rdb_time_ms',
        'rdb_percentage',
        'rdb_call_count',
        'status',
        'completion_timestamp',
        'line_number'
    ]
    
    # ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í‰íƒ„í™”
    all_records = []
    
    for thread_name, records in thread_data.items():
        for record in records:
            row = {
                'thread_name': thread_name,
                'timestamp': record.get('timestamp', ''),
                'log_level': record.get('log_level', ''),
                'version': record.get('version', ''),
                'total_time_ms': record.get('total_time_ms', ''),
                'rdb_time_ms': record.get('rdb_time_ms', ''),
                'rdb_percentage': record.get('rdb_percentage', ''),
                'rdb_call_count': record.get('rdb_call_count', ''),
                'status': record.get('status', ''),
                'completion_timestamp': record.get('completion_timestamp', ''),
                'line_number': record.get('line_number', '')
            }
            all_records.append(row)
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    all_records.sort(key=lambda x: (x['timestamp'], x['thread_name']))
    
    # CSV íŒŒì¼ ì‘ì„±
    with open(output_file, 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=headers)
        writer.writeheader()
        writer.writerows(all_records)
    
    return len(all_records)

def generate_summary_statistics(thread_data, summary_file):
    """
    ìŠ¤ë ˆë“œë³„ ìš”ì•½ í†µê³„ë¥¼ ìƒì„±í•˜ì—¬ ë³„ë„ CSVë¡œ ì €ì¥
    """
    
    summary_headers = [
        'thread_name',
        'execution_count',
        'avg_total_time_ms',
        'min_total_time_ms',
        'max_total_time_ms',
        'avg_rdb_time_ms',
        'min_rdb_time_ms',
        'max_rdb_time_ms',
        'avg_rdb_percentage',
        'min_rdb_percentage',
        'max_rdb_percentage'
    ]
    
    summary_data = []
    
    for thread_name, records in thread_data.items():
        if not records:
            continue
            
        # ìœ íš¨í•œ ë°ì´í„°ë§Œ í•„í„°ë§
        valid_records = [r for r in records if 'total_time_ms' in r and 'rdb_time_ms' in r]
        
        if not valid_records:
            continue
        
        total_times = [r['total_time_ms'] for r in valid_records]
        rdb_times = [r['rdb_time_ms'] for r in valid_records]
        rdb_percentages = [r['rdb_percentage'] for r in valid_records]
        
        summary = {
            'thread_name': thread_name,
            'execution_count': len(valid_records),
            'avg_total_time_ms': round(sum(total_times) / len(total_times), 2),
            'min_total_time_ms': min(total_times),
            'max_total_time_ms': max(total_times),
            'avg_rdb_time_ms': round(sum(rdb_times) / len(rdb_times), 2),
            'min_rdb_time_ms': min(rdb_times),
            'max_rdb_time_ms': max(rdb_times),
            'avg_rdb_percentage': round(sum(rdb_percentages) / len(rdb_percentages), 2),
            'min_rdb_percentage': min(rdb_percentages),
            'max_rdb_percentage': max(rdb_percentages)
        }
        
        summary_data.append(summary)
    
    # ìŠ¤ë ˆë“œ ì´ë¦„ìœ¼ë¡œ ì •ë ¬
    summary_data.sort(key=lambda x: x['thread_name'])
    
    # CSV íŒŒì¼ ì‘ì„±
    with open(summary_file, 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=summary_headers)
        writer.writeheader()
        writer.writerows(summary_data)
    
    return len(summary_data)

def main():
    # ë¡œì»¬ í™˜ê²½ìš© íŒŒì¼ ê²½ë¡œ ì„¤ì •
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # ì…ë ¥ íŒŒì¼ - ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìˆë‹¤ê³  ê°€ì •
    log_file_name = '2ì°¨ í…ŒìŠ¤íŠ¸_50ê°œ ìŠ¤ë ˆë“œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¡œê·¸.txt'
    log_file_path = os.path.join(script_dir, log_file_name)
    
    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(log_file_path):
        print(f"âŒ ì—ëŸ¬: ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print(f"   ê²½ë¡œ: {log_file_path}")
        print(f"\nğŸ“ í•´ê²° ë°©ë²•:")
        print(f"   1. ë¡œê·¸ íŒŒì¼ëª…ì„ '{log_file_name}'ë¡œ ë³€ê²½í•˜ì„¸ìš”")
        print(f"   2. íŒŒì¼ì„ ë‹¤ìŒ ìœ„ì¹˜ì— ë†“ìœ¼ì„¸ìš”: {script_dir}")
        print(f"   3. ë˜ëŠ” ì´ ìŠ¤í¬ë¦½íŠ¸ì˜ log_file_name ë³€ìˆ˜ë¥¼ ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”")
        return
    
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ - ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìƒì„±
    output_csv_path = os.path.join(script_dir, 'thread_performance_data.csv')
    summary_csv_path = os.path.join(script_dir, 'thread_performance_summary.csv')
    
    print("=" * 80)
    print("ìŠ¤ë ˆë“œ ì„±ëŠ¥ ë¡œê·¸ íŒŒì‹± ì‹œì‘")
    print("=" * 80)
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {log_file_path}")
    print(f"ğŸ“Š ì¶œë ¥ íŒŒì¼ 1: {output_csv_path}")
    print(f"ğŸ“Š ì¶œë ¥ íŒŒì¼ 2: {summary_csv_path}")
    print("-" * 80)
    
    # ë¡œê·¸ íŒŒì¼ íŒŒì‹±
    print("ğŸ” ë¡œê·¸ íŒŒì¼ íŒŒì‹± ì¤‘...")
    thread_data = parse_log_file(log_file_path)
    
    # íŒŒì‹± ê²°ê³¼ ì¶œë ¥
    total_threads = len(thread_data)
    total_records = sum(len(records) for records in thread_data.values())
    
    print(f"âœ… íŒŒì‹± ì™„ë£Œ:")
    print(f"   - ìŠ¤ë ˆë“œ ìˆ˜: {total_threads}")
    print(f"   - ì´ ë ˆì½”ë“œ ìˆ˜: {total_records}")
    
    # CSV ì €ì¥
    print("\nğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì¤‘...")
    records_saved = save_to_csv(thread_data, output_csv_path)
    print(f"âœ… ìƒì„¸ ë°ì´í„° CSV ì €ì¥ ì™„ë£Œ: {records_saved}ê°œ ë ˆì½”ë“œ")
    
    # ìš”ì•½ í†µê³„ ìƒì„±
    print("\nğŸ“ˆ ìš”ì•½ í†µê³„ ìƒì„± ì¤‘...")
    summary_count = generate_summary_statistics(thread_data, summary_csv_path)
    print(f"âœ… ìš”ì•½ í†µê³„ CSV ì €ì¥ ì™„ë£Œ: {summary_count}ê°œ ìŠ¤ë ˆë“œ")
    
    # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
    if thread_data:
        print("\nğŸ“Š ê¸°ë³¸ í†µê³„:")
        all_total_times = []
        all_rdb_times = []
        all_rdb_percentages = []
        
        for records in thread_data.values():
            for record in records:
                if 'total_time_ms' in record:
                    all_total_times.append(record['total_time_ms'])
                if 'rdb_time_ms' in record:
                    all_rdb_times.append(record['rdb_time_ms'])
                if 'rdb_percentage' in record:
                    all_rdb_percentages.append(record['rdb_percentage'])
        
        if all_total_times:
            print(f"   - í‰ê·  ì´ ì²˜ë¦¬ ì‹œê°„: {sum(all_total_times)/len(all_total_times):.2f}ms")
            print(f"   - ìµœì†Œ/ìµœëŒ€ ì´ ì²˜ë¦¬ ì‹œê°„: {min(all_total_times)}ms / {max(all_total_times)}ms")
        
        if all_rdb_times:
            print(f"   - í‰ê·  RDB ì¡°íšŒ ì‹œê°„: {sum(all_rdb_times)/len(all_rdb_times):.2f}ms")
            print(f"   - ìµœì†Œ/ìµœëŒ€ RDB ì¡°íšŒ ì‹œê°„: {min(all_rdb_times)}ms / {max(all_rdb_times)}ms")
        
        if all_rdb_percentages:
            print(f"   - í‰ê·  RDB ì‹œê°„ ë¹„ìœ¨: {sum(all_rdb_percentages)/len(all_rdb_percentages):.2f}%")
    
    print("\n" + "=" * 80)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)

if __name__ == "__main__":
    main()
