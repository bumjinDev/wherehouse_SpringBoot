# Oracle Buffer Reads 학습 문서

## 문서 개요

- **작성 목적**: Oracle Memory Architecture 중 Buffer Reads 메커니즘 학습
- **학습 기준 문서**: Oracle Database Concepts 19c - Memory Architecture 챕터
- **공식 문서 URL**: https://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/memory-architecture.html#GUID-1A40F9B9-EB2F-4060-9007-7B26C033A774
- **프로젝트 연관성**: Wherehouse 프로젝트 N+1 최적화 성능 테스트 결과 해석

---

# 1. Buffer Reads: 버퍼 캐시에서 데이터를 읽는 메커니즘

## 1.1 왜 Buffer Reads를 이해해야 하는가 (Why)

Buffer Reads는 Oracle이 클라이언트 요청에 응답하기 위해 데이터 블록을 어디서, 어떻게 가져오는지를 결정하는 핵심 메커니즘이다. 이 메커니즘을 이해해야 하는 이유는 Wherehouse 프로젝트의 성능 테스트 결과를 아키텍처 레벨에서 해석할 수 있기 때문이다.

테스트 데이터에서 "RDB 조회 시간"이라고 측정한 항목의 실체가 바로 이 Buffer Reads 과정에서 발생하는 Logical I/O와 Physical I/O의 합산이다. 1차 테스트에서 RDB 시간 비율이 6.2%에 불과했다는 것은, 실제 데이터 접근 시간보다 **그 외의 오버헤드**(Connection 획득 대기, 네트워크 왕복 등)가 훨씬 컸다는 의미다. 이 현상을 정확히 설명하려면 Buffer Reads의 내부 동작을 알아야 한다.

---

## 1.2 Buffer Reads의 동작 원리 (How)

### 1.2.1 핵심 개념: Logical I/O vs Physical I/O

Oracle에서 I/O는 두 가지 계층으로 구분된다:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        I/O 계층 구조                                      │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [Logical I/O]                                                          │
│      │                                                                  │
│      ├── Buffer Cache의 블록에 대한 모든 접근                            │
│      │   (db block gets + consistent gets의 합)                         │
│      │                                                                  │
│      │   ┌─────────────────────────────────────────────────────────┐   │
│      │   │ db block gets: Current Mode 블록 접근                    │   │
│      │   │   - DML 작업(UPDATE/DELETE) 시 수정 대상 블록 접근      │   │
│      │   │                                                         │   │
│      │   │ consistent gets: Consistent Read Mode 블록 접근         │   │
│      │   │   - SELECT, DML의 WHERE 절 평가 시                      │   │
│      │   └─────────────────────────────────────────────────────────┘   │
│      │                                                                  │
│      ├── 메모리 내 작업이므로 매우 빠름 (마이크로초 단위)                  │
│      └── V$SYSSTAT의 "session logical reads" 통계로 측정                 │
│                                                                         │
│  [Physical I/O]                                                         │
│      │                                                                  │
│      ├── 요청한 블록이 Buffer Cache에 없을 때 발생                       │
│      ├── 디스크 또는 Flash Cache에서 블록을 메모리로 복사                 │
│      ├── 디스크 접근이므로 느림 (밀리초 단위)                             │
│      └── V$SYSSTAT의 "physical reads" 통계로 측정                        │
│                                                                         │
│  [핵심 관계]                                                             │
│      Physical I/O 발생 후 → 반드시 Logical I/O가 뒤따름                  │
│      (디스크에서 읽어온 블록을 메모리에 올린 후, 그 블록을 다시 읽음)      │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

이 구분이 중요한 이유는 **Buffer Cache Hit Ratio**라는 핵심 성능 지표의 근거가 되기 때문이다:

```
Buffer Cache Hit Ratio = 1 - (Physical Reads Cache / Logical Reads)

여기서:
- Physical Reads Cache = physical reads 
                        - physical reads direct 
                        - physical reads direct (lob)
                        - physical reads direct temporary tablespace
- Logical Reads = db block gets + consistent gets
```

공식에서 `physical reads` 전체가 아닌 `Physical Reads Cache`를 사용하는 이유는, Direct Path Read(Temp File I/O, Parallel Query의 직접 읽기 등)가 Buffer Cache를 완전히 우회하기 때문이다. 우회하는 I/O는 Cache Hit/Miss 개념 자체가 적용되지 않으므로 Hit Ratio 계산에서 제외해야 한다. 이 점은 1.2.4절의 Temp File 읽기 특수성과 연결된다.

이 비율이 높을수록 디스크 접근 없이 메모리에서 데이터를 가져오는 비율이 높다는 의미다.

---

### 1.2.2 Buffer 검색 순서 (Search Order)

클라이언트가 데이터를 요청하면, Server Process는 다음 순서로 버퍼를 검색한다:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                     Buffer 검색 순서 (2단계)                             │
└─────────────────────────────────────────────────────────────────────────┘

  [Client Request: SELECT * FROM REVIEW_STATISTICS WHERE PROPERTY_ID = 'P001']
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  [1단계] Buffer Cache 검색                                               │
│                                                                         │
│      Server Process가 요청된 블록이 Buffer Cache에 있는지 확인           │
│      (내부적으로 Hash 기반 검색 → O(1) 수준의 빠른 접근)                 │
│                                                                         │
│      ┌─────────────────────────────────────────────────────────────┐    │
│      │  [Cache Hit] → 메모리에서 바로 읽음 (Logical Read) → 완료   │    │
│      │               → 마이크로초 단위, 매우 빠름                  │    │
│      │                                                             │    │
│      │  [Cache Miss] → 2단계로 진행                                │    │
│      └─────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼ (Cache Miss인 경우)
┌─────────────────────────────────────────────────────────────────────────┐
│  [2단계] Data File에서 Physical Read                                     │
│                                                                         │
│      Server Process가 OS에 I/O 요청                                      │
│      디스크에서 블록을 읽어 Buffer Cache로 복사한 후 Logical Read        │
│      → 밀리초 단위, Cache Hit 대비 100~1000배 느림                       │
│                                                                         │
│      이 과정에서 발생하는 Wait Event:                                    │
│      - db file sequential read (단일 블록, 인덱스 스캔 시)               │
│      - db file scattered read (다중 블록, Full Table Scan 시)            │
│                                                                         │
│      ※ 참고: Flash Cache(SSD 기반 2차 캐시)가 활성화된 특수 환경에서는   │
│              디스크 접근 전에 Flash Cache를 먼저 확인하는 단계가 추가됨   │
│              (Exadata 등 특정 환경 전용, 일반 환경에서는 해당 없음)       │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

### 1.2.3 Cache Hit vs Cache Miss의 성능 차이

공식 문서에서 **"accessing data through a cache hit is faster than through a cache miss"**라고 명시한 부분의 정량적 의미:

```
┌─────────────────────────────────────────────────────────────────────────┐
│           접근 방식별 지연 시간 비교 (일반적 벤치마크 기준)               │
│           ※ 실제 수치는 하드웨어, 부하, 블록 크기에 따라 변동            │
├───────────────────────┬─────────────────────┬───────────────────────────┤
│      접근 방식         │     지연 시간        │          비고             │
├───────────────────────┼─────────────────────┼───────────────────────────┤
│  Cache Hit            │   0.01 ~ 0.1 ms     │  메모리 접근만 발생        │
│  (Logical I/O only)   │                     │  CPU bound 작업           │
├───────────────────────┼─────────────────────┼───────────────────────────┤
│  Flash Cache Hit      │   0.1 ~ 1 ms        │  SSD 접근                 │
│  (Optimized Physical) │                     │  HDD 대비 10~100배 빠름   │
├───────────────────────┼─────────────────────┼───────────────────────────┤
│  Cache Miss           │   5 ~ 20 ms         │  HDD 접근                 │
│  (Full Physical I/O)  │                     │  I/O bound 작업           │
└───────────────────────┴─────────────────────┴───────────────────────────┘
```

이 차이가 **N+1 문제에서 증폭되는 메커니즘**:

```
[N+1 쿼리 25회 실행 시 Buffer Reads 시나리오]

시나리오 A: 모든 블록이 Cache Hit인 경우
    25회 × 0.05ms (Logical I/O) = 1.25ms

시나리오 B: 모든 블록이 Cache Miss인 경우 (Cold Start)
    25회 × 10ms (Physical I/O) = 250ms

시나리오 C: 현실적 혼합 (80% Hit, 20% Miss)
    20회 × 0.05ms + 5회 × 10ms = 51ms

→ 동일한 25회 쿼리라도 Buffer Cache 상태에 따라 
   1.25ms ~ 250ms까지 200배의 성능 차이 발생 가능
```

---

### 1.2.4 Temp File 읽기의 특수성

공식 문서에서 중요하게 언급한 예외 케이스:

> *"Reads from a temp file occur when insufficient memory forces the database to write data to a temporary table and read it back later. These physical reads bypass the buffer cache and do not incur a logical I/O."*

이것이 의미하는 바:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    Temp File I/O의 특수성                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [일반 Data File 읽기]                                                   │
│      Disk → Buffer Cache → Server Process                               │
│      Physical I/O 후 Logical I/O 발생                                   │
│      Buffer Cache에 캐싱되어 재사용 가능                                 │
│                                                                         │
│  [Temp File 읽기]                                                        │
│      Disk → Server Process (Direct Path Read)                           │
│      Buffer Cache를 우회 (bypass)                                        │
│      Logical I/O 통계에 포함되지 않음                                    │
│      재사용 불가 (일회성 데이터)                                         │
│                                                                         │
│  [Temp File 사용 발생 조건]                                              │
│      - PGA의 Sort Area 부족 시 (ORDER BY, GROUP BY)                     │
│      - Hash Area 부족 시 (Hash Join)                                    │
│      - Global Temporary Table 사용 시                                   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

**프로젝트 연관성**: Wherehouse의 주거지 추천 쿼리에서 ORDER BY나 복잡한 집계가 포함된 경우, PGA의 Sort Area가 부족하면 Temp File I/O가 발생할 수 있다. 이 경우 V$SYSSTAT의 "physical reads direct temporary" 통계가 증가한다.

---

#### [심화] Temp File 메커니즘 상세 (포트폴리오 범위 외, 추후 학습용 기록)

> ※ 이하 내용은 현재 포트폴리오 목적에는 필수가 아니나, Oracle 메모리 아키텍처의 완전한 이해를 위해 기록해둔다. DBA 심화 영역 또는 대용량 데이터 처리 최적화 시 참고.

**Temp File의 정의**

Temp File은 Oracle의 **Temporary Tablespace**에 속한 데이터 파일로, Server Process가 작업 중 PGA(Program Global Area) 메모리가 부족할 때 중간 결과를 임시 저장하는 용도로 사용된다. 일반 Data File(영구 데이터 저장)과 달리, Temp File은 **세션 종료 시 자동으로 내용이 무효화**되며 인스턴스 재시작 시 복구 대상이 아니다.

**아키텍처적 위치**

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    Oracle 메모리-디스크 구조에서 Temp File의 위치        │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [SGA - 공유 메모리 영역]                                                │
│      Buffer Cache ←→ Data Files (USERS.dbf, SYSTEM.dbf 등)             │
│                       └── 영구 데이터, Instance Recovery 복구 대상      │
│                                                                         │
│  [PGA - 프로세스 전용 메모리 영역]                                       │
│      Sort Area    ←→ Temp Files (temp01.dbf 등)                        │
│      Hash Area        └── 임시 데이터, 복구 대상 아님                   │
│                                                                         │
│  ※ 핵심 차이: Temp File I/O는 Buffer Cache를 경유하지 않음              │
│               Server Process가 직접 Disk와 통신 (Direct Path I/O)       │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

**발생 조건별 상세 메커니즘**

**(1) Sort Area 부족 시 (ORDER BY, GROUP BY, DISTINCT)**

```
[시나리오: 대용량 정렬]

SELECT * FROM PROPERTY ORDER BY PRICE DESC;
-- 100만 건, 평균 행 크기 500 bytes = 500MB 정렬 필요

PGA의 Sort Area 크기: 100MB (SORT_AREA_SIZE 또는 PGA_AGGREGATE_TARGET에 의해 결정)

[메모리 내 정렬 불가 → Temp File 사용]

1단계: 메모리에 100MB씩 읽어서 정렬
2단계: 정렬된 100MB 청크를 Temp File에 기록 (5회 반복)
3단계: Temp File의 5개 청크를 병합 정렬(Merge Sort)하며 결과 반환

→ 이 과정에서 V$SYSSTAT의 "physical reads direct temporary"와 
   "physical writes direct temporary" 통계가 증가
```

**(2) Hash Area 부족 시 (Hash Join)**

```sql
SELECT p.*, r.* 
FROM PROPERTY p 
JOIN REVIEW_STATISTICS r ON p.ID = r.PROPERTY_ID;
```

Hash Join은 작은 테이블(Build Input)을 메모리에 해시 테이블로 구축한 후, 큰 테이블(Probe Input)을 스캔하며 매칭한다. Build Input이 Hash Area보다 크면:

```
[In-Memory Hash Join 불가 → Temp File 사용]

1단계: Build Input을 파티션으로 분할
2단계: 메모리에 담기지 않는 파티션을 Temp File에 기록
3단계: Probe Input도 동일하게 파티션 분할 후 Temp File 기록
4단계: 파티션 단위로 메모리에 로드하며 Join 수행

→ "One-Pass" 또는 "Multi-Pass" Hash Join으로 전환됨
→ Pass 횟수가 증가할수록 Temp I/O 증가, 성능 저하
```

**(3) Global Temporary Table (GTT)**

```sql
CREATE GLOBAL TEMPORARY TABLE SESSION_CART (
    ITEM_ID NUMBER,
    QUANTITY NUMBER
) ON COMMIT PRESERVE ROWS;  -- 세션 종료까지 유지
```

GTT는 테이블 **구조(DDL)**는 Data Dictionary에 영구 저장되지만, **데이터(DML)**는 Temp File에 저장된다. 세션 간 데이터 격리가 필요한 중간 계산 결과 저장에 사용하며, 각 세션은 동일한 GTT 이름을 사용하더라도 자신만의 데이터를 본다.

**Buffer Cache를 우회(Direct Path I/O)하는 설계적 근거**

```
┌─────────────────────────────────────────────────────────────────────────┐
│         일반 Data File vs Temp File I/O 경로 비교                        │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [일반 Data File 읽기]                                                   │
│                                                                         │
│      Server Process → Buffer Cache 검색 → (Miss 시) Disk 읽기           │
│                              ↓                                          │
│                       Buffer Cache에 캐싱                               │
│                              ↓                                          │
│                       다른 세션도 재사용 가능                            │
│                                                                         │
│      → 공유 데이터이므로 캐싱의 이점이 있음                              │
│                                                                         │
│  [Temp File 읽기 - Direct Path]                                          │
│                                                                         │
│      Server Process → 직접 Disk 읽기 → PGA로 로드                       │
│                                                                         │
│      → Buffer Cache 완전 우회                                           │
│      → Logical I/O 통계에 포함되지 않음                                 │
│                                                                         │
│  [Direct Path를 사용하는 설계적 이유]                                    │
│                                                                         │
│      1. 재사용 불가: Temp 데이터는 해당 세션/작업에서만 유효             │
│         다른 세션이 캐시된 Temp 블록을 사용할 일이 없음                  │
│         → 캐싱해봐야 Hit가 발생하지 않으므로 무의미                      │
│                                                                         │
│      2. 캐시 오염 방지: 일회성 대용량 데이터가 Buffer Cache를            │
│         점령하면 Hot Block(자주 접근되는 영구 데이터 블록)이 밀려남      │
│         → 전체 시스템 Cache Hit Ratio 저하 유발                         │
│                                                                         │
│      3. 동기화 오버헤드 감소: Buffer Cache 접근 시 필요한                │
│         Latch 획득, LRU 리스트 관리, Cache Buffers Chains 탐색 등       │
│         공유 자원 동기화 비용을 회피                                     │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

**Buffer Cache Hit Ratio 계산에서 제외되는 이유**

1.2.1절의 Hit Ratio 공식에서 Temp File I/O를 제외하는 근거:

```
Physical Reads Cache = physical reads 
                      - physical reads direct 
                      - physical reads direct (lob)
                      - physical reads direct temporary tablespace  ← Temp File I/O
```

Temp File I/O는 **애초에 Cache를 사용할 의도가 없는 I/O**다. "Cache를 시도했으나 Miss"가 아니라 "Cache를 의도적으로 우회한 것"이므로, Hit/Miss 개념 자체가 적용되지 않는다. 이를 Hit Ratio 계산에 포함하면 지표가 왜곡된다.

**Temp File I/O 발생 여부 확인 방법**

```sql
-- 1. V$SYSSTAT에서 시스템 전체 Temp I/O 통계 확인
SELECT name, value 
FROM V$SYSSTAT 
WHERE name LIKE '%direct temporary%';

-- 2. 실행 계획에서 개별 쿼리의 Temp 사용 확인
-- EXPLAIN PLAN 결과에서 "SORT" 또는 "HASH JOIN" 연산에 
-- "TEMP" 또는 "DISK" 키워드가 있으면 Temp File 사용 중

-- 3. PGA 메모리 튜닝으로 Temp I/O 감소 유도
-- PGA_AGGREGATE_TARGET 증가 → Sort/Hash Area 확대 → Temp I/O 감소
```

**현재 프로젝트에서의 적용 가능성**

Wherehouse 테스트 데이터 규모(25건의 REVIEW_STATISTICS)에서는 Temp File I/O가 발생할 가능성이 낮다. 이 개념은 데이터가 수십만~수백만 건으로 증가하여 PGA 메모리를 초과하는 정렬/조인 작업이 발생할 때 성능 병목 분석에 필요하다.

---

### 1.2.5 Buffer 확보를 위한 Aging Out 메커니즘

Buffer Cache에 새 블록을 읽어와야 하는데 **Unused Buffer가 부족한 경우**, Oracle은 기존 버퍼를 Aging Out해야 한다. 공식 문서에서 설명한 두 가지 시나리오:

```
┌─────────────────────────────────────────────────────────────────────────┐
│              Flash Cache 비활성화 시 (일반적인 환경)                      │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  Clean Buffer 재사용:                                                    │
│      LRU의 Cold End에서 Clean Buffer를 찾음                              │
│      해당 Buffer의 내용을 새 블록으로 덮어씀 (overwrite)                 │
│      이전 블록 내용은 완전히 소실                                        │
│      → 나중에 필요하면 Disk에서 다시 읽어야 함                           │
│                                                                         │
│  Dirty Buffer 발견 시:                                                   │
│      DBW(Database Writer)가 Dirty Buffer를 Disk에 기록                   │
│      기록 완료 후 Clean 상태로 변경                                      │
│      그 후 재사용 가능                                                   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────┐
│              Flash Cache 활성화 시 (Oracle Linux/Solaris)                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  Clean Buffer 재사용:                                                    │
│      DBW가 Clean Buffer의 Body를 Flash Cache에 기록                      │
│      Buffer Header는 메인 메모리 LRU에 유지                              │
│      In-Memory Buffer는 새 블록으로 재사용                               │
│      → 나중에 필요하면 Flash Cache에서 읽음 (Disk보다 빠름)              │
│                                                                         │
│  이점:                                                                   │
│      Disk I/O 대신 Flash Cache I/O로 대체                                │
│      Physical Read 지연 시간 감소 (10ms → 0.5ms)                         │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 1.3 프로젝트 테스트 데이터와의 연결 (So What)

### 1.3.1 1차 테스트(N+1) 결과 재해석

```
┌─────────────────────────────────────────────────────────────────────────┐
│  1차 테스트 결과                                                         │
│  ─────────────────────────────────────────────────────────────────────  │
│  총 소요 시간: 5,531ms                                                   │
│  RDB 조회 시간: 343ms                                                    │
│  RDB 시간 비율: 6.2%                                                     │
│  쿼리 실행 횟수: 25회                                                    │
│  평균 쿼리당 시간: 343ms ÷ 25 = 13.7ms                                   │
└─────────────────────────────────────────────────────────────────────────┘

[Buffer Reads 관점에서의 해석]

쿼리당 13.7ms가 의미하는 것:
    - 순수 Physical I/O만 발생했다면: 10~20ms 범위 (일치)
    - Cache Hit가 많았다면: 1ms 미만이어야 함

→ 추론: REVIEW_STATISTICS 테이블의 블록들이 Buffer Cache에 
        충분히 캐싱되지 않은 상태였을 가능성 높음
        (Cold Start 또는 Buffer Cache 크기 부족)

[나머지 94%는 어디서 소요되었는가?]

5,531ms - 343ms = 5,188ms가 DB 외부에서 소요

이 시간의 구성 요소:
    1. 네트워크 왕복 시간 × 25회
    2. JDBC 드라이버 처리 시간 × 25회  
    3. Hibernate 영속성 컨텍스트 처리 × 25회
    4. HikariCP Connection 획득 대기 시간 (Waiting 최대 9건)
    5. Server Process의 Parse 시간 × 25회

→ Buffer Reads 자체보다 "Buffer Reads를 하기 위한 준비 과정"이 
   병목의 주요 원인
```

### 1.3.2 Buffer Cache Hit Ratio 추정

테스트 데이터로부터 역산 (계산 방법론 예시):

```
[가정 - 실측값이 아닌 계산 예시용 임의 설정]
- 단일 쿼리가 접근하는 평균 블록 수: 100개 (※ V$SQL 또는 SQL Trace로 실측 필요)
- Logical I/O 1회 시간: 0.05ms
- Physical I/O 1회 시간: 10ms

[1차 테스트 - 쿼리당 13.7ms]
만약 Hit Ratio = X라면:
    총 시간 = (Hit 블록 수 × Logical I/O 시간) + (Miss 블록 수 × Physical I/O 시간)
    
    100 × X × 0.05ms + 100 × (1-X) × 10ms = 13.7ms
    5X + 1000 - 1000X = 13.7
    1000 - 995X = 13.7
    -995X = -986.3
    X ≈ 0.991 (약 99%)

→ 위 가정 하에서 계산상 Hit Ratio가 99%인데도 13.7ms가 소요된다면,
   나머지 1%의 Physical I/O(1개 블록)가 전체 시간을 지배함
   (※ 실제 Hit Ratio 확인은 V$SYSSTAT 조회 필요)

[시사점 - 일반 원칙]
Buffer Cache Hit Ratio가 99%로 높아도, 
1%의 Physical I/O가 전체 응답 시간의 대부분을 차지할 수 있음.
이것이 "Buffer Cache Hit Ratio는 높은데 왜 느리지?"라는 
흔한 의문에 대한 아키텍처적 답변임.
```

### 1.3.3 면접 답변 구성

**질문: "N+1 쿼리가 왜 성능에 영향을 주나요?"**

```
[합격선 답변 구조]

1. Buffer Reads 관점에서의 영향:
   "N+1 쿼리는 동일한 데이터에 대해 25번의 개별 Buffer Read 요청을 
    발생시킵니다. 첫 번째 쿼리에서 Physical I/O가 발생하면 블록이 
    Buffer Cache에 올라가므로 이후 쿼리는 Cache Hit가 될 수 있습니다.
    
    그러나 문제는 Buffer Read 자체보다 그것을 수행하기 위한 
    오버헤드에 있습니다."

2. 오버헤드 구체화:
   "25번의 쿼리는 각각:
    - Parse 단계를 거쳐야 하고 (Library Cache 조회)
    - Buffer Cache 접근을 위해 cache buffers chains latch를 획득해야 하며
    - 결과를 클라이언트로 전송하는 네트워크 왕복이 필요합니다.
    
    제 테스트에서 RDB 시간 비율이 6.2%에 불과했던 것은,
    실제 Buffer Read 시간보다 이러한 부수적 오버헤드가 
    15배 이상 컸다는 의미입니다."

3. 본인 데이터 연결:
   "HikariCP Waiting이 최대 9건까지 발생한 것은,
    25번의 Buffer Read 사이클 동안 Connection이 계속 점유되어
    다른 요청들이 Connection을 획득하지 못했기 때문입니다."
```

---

## 1.4 추가 학습 포인트

Buffer Reads를 완전히 이해하려면 다음 연관 개념도 학습이 필요하다:

1. **Buffer States (Unused/Clean/Dirty)** - 버퍼가 재사용 가능한 조건
2. **LRU Algorithm** - 어떤 버퍼가 Aging Out 대상이 되는지
3. **Touch Count** - 버퍼의 "Hot/Cold" 판정 메커니즘
4. **db file sequential read vs db file scattered read** - Wait Event와의 연결

---

# 2. FLUSH BUFFER_CACHE: Buffer Cache 강제 비우기

## 2.1 정의와 목적 (Why)

`FLUSH BUFFER_CACHE`는 Oracle Buffer Cache에 있는 모든 버퍼를 강제로 비우는 명령어다. 정확한 구문은 다음과 같다:

```sql
ALTER SYSTEM FLUSH BUFFER_CACHE;
```

이 명령어가 존재하는 이유는 **성능 테스트의 재현성** 때문이다. Buffer Cache 상태에 따라 동일한 쿼리라도 응답 시간이 200배까지 차이날 수 있다고 앞서 설명했다. 테스트 결과를 비교하려면 매번 동일한 "Cold Start" 상태에서 시작해야 하는데, 이를 인위적으로 만들어주는 것이 FLUSH BUFFER_CACHE다.

---

## 2.2 동작 원리 (How)

### 2.2.1 내부 동작 메커니즘

```
┌─────────────────────────────────────────────────────────────────────────┐
│            ALTER SYSTEM FLUSH BUFFER_CACHE 실행 시 동작                  │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [핵심 특성] Dirty Buffer는 flush 대상이 아님                            │
│      이 명령어는 Clean Buffer만 무효화함                                 │
│      Dirty Buffer는 Buffer Cache에 그대로 유지됨                         │
│                                                                         │
│  [Clean Buffer 처리]                                                     │
│      Clean Buffer를 "Free" 상태로 전환                                   │
│      Buffer Header의 블록 매핑 정보 제거                                 │
│      LRU 리스트에서 Free List로 이동                                     │
│                                                                         │
│  [Dirty Buffer 처리]                                                     │
│      변경 없음 - Buffer Cache에 그대로 남아있음                          │
│      DBWn의 일반적인 Checkpoint 메커니즘에 의해서만 기록됨               │
│                                                                         │
│  [결과 상태]                                                             │
│      Clean Buffer만 무효화된 "Partial Cold" 상태                         │
│      Dirty Buffer가 있던 블록은 여전히 Cache Hit 가능                    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────┐
│            완전한 Cold Start 시뮬레이션을 위한 올바른 절차                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  -- 1단계: Dirty Buffer를 디스크에 기록하여 Clean 상태로 전환            │
│  ALTER SYSTEM CHECKPOINT;                                               │
│                                                                         │
│  -- 2단계: Clean Buffer 무효화                                           │
│  ALTER SYSTEM FLUSH BUFFER_CACHE;                                       │
│                                                                         │
│  이 순서로 실행해야 Buffer Cache가 완전히 비워진 상태가 됨               │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### 2.2.2 Shared Pool Flush와의 차이

Buffer Cache만 비우는 것과 Shared Pool까지 비우는 것은 다른 의미를 갖는다:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      Flush 명령어 비교                                   │
├────────────────────────────────┬────────────────────────────────────────┤
│  명령어                         │  영향 범위                              │
├────────────────────────────────┼────────────────────────────────────────┤
│  ALTER SYSTEM                  │  Buffer Cache만 비움                   │
│  FLUSH BUFFER_CACHE;           │  → 다음 쿼리에서 Physical I/O 발생     │
│                                │  → 실행 계획(Library Cache)은 유지     │
│                                │  → Parse는 Soft Parse 가능             │
├────────────────────────────────┼────────────────────────────────────────┤
│  ALTER SYSTEM                  │  Shared Pool 비움                      │
│  FLUSH SHARED_POOL;            │  → Library Cache의 실행 계획 제거      │
│                                │  → 다음 쿼리에서 Hard Parse 발생       │
│                                │  → Data Dictionary Cache도 비워짐      │
├────────────────────────────────┼────────────────────────────────────────┤
│  두 명령어 모두 실행            │  완전한 Cold Start 시뮬레이션          │
│                                │  → Physical I/O + Hard Parse 모두 발생 │
│                                │  → 인스턴스 재시작과 유사한 상태        │
└────────────────────────────────┴────────────────────────────────────────┘
```

---

## 2.3 프로젝트 테스트에서의 활용 (So What)

### 2.3.1 테스트 재현성 확보

Wherehouse 프로젝트의 Before/After 비교에서 이 명령어가 필요한 이유:

```
[문제 시나리오: FLUSH 없이 테스트]

테스트 1회차 (Origin Code):
    → 첫 실행이므로 Buffer Cache가 비어있음 (Cold)
    → Physical I/O 다수 발생
    → 응답 시간: 5,531ms

테스트 2회차 (Bulk Code):
    → 1회차에서 읽은 블록들이 Buffer Cache에 남아있음 (Warm)
    → Cache Hit 발생
    → 응답 시간: 3,200ms (실제보다 빠르게 측정됨)

테스트 3회차 (Chunk Code):
    → 2회차까지의 블록들이 더 많이 캐싱됨 (Hot)
    → 더 높은 Cache Hit
    → 응답 시간: 2,100ms (실제보다 더 빠르게 측정됨)

→ 결론: Buffer Cache 상태가 다르므로 공정한 비교 불가
```

```
[해결 시나리오: 매 테스트 전 CHECKPOINT + FLUSH 실행]

테스트 1회차 (Origin Code):
    ALTER SYSTEM CHECKPOINT;
    ALTER SYSTEM FLUSH BUFFER_CACHE;
    → Cold Start 상태
    → 응답 시간: 5,531ms

테스트 2회차 (Bulk Code):
    ALTER SYSTEM CHECKPOINT;
    ALTER SYSTEM FLUSH BUFFER_CACHE;
    → Cold Start 상태 (동일 조건)
    → 응답 시간: 6,001ms

테스트 3회차 (Chunk Code):
    ALTER SYSTEM CHECKPOINT;
    ALTER SYSTEM FLUSH BUFFER_CACHE;
    → Cold Start 상태 (동일 조건)
    → 응답 시간: 4,434ms

→ 결론: 동일한 Cache 상태에서 측정했으므로 공정한 비교 가능
```

### 2.3.2 테스트 시 권장 절차

```sql
-- 1. Dirty Buffer를 디스크에 기록 (Clean 상태로 전환)
ALTER SYSTEM CHECKPOINT;

-- 2. Buffer Cache 비우기 (Physical I/O 조건 동일화)
ALTER SYSTEM FLUSH BUFFER_CACHE;

-- 3. Shared Pool 비우기 (Parse 조건 동일화) - 선택사항
ALTER SYSTEM FLUSH SHARED_POOL;

-- 4. 시스템 통계 초기화 (측정 기준점 설정)
-- V$SYSSTAT 값을 기록해두거나, AWR 스냅샷 생성

-- 5. 테스트 실행
-- JMeter 또는 애플리케이션에서 부하 인가

-- 6. 결과 수집
-- V$SYSSTAT 변화량, V$SQL 통계 조회
```

### 2.3.3 주의사항: 운영 환경에서의 금기

```
┌─────────────────────────────────────────────────────────────────────────┐
│  ⚠️  경고: 운영 환경에서 FLUSH BUFFER_CACHE 실행 금지                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [발생하는 문제]                                                         │
│                                                                         │
│  1. 즉각적인 성능 저하                                                   │
│     - 모든 쿼리가 Physical I/O 발생                                     │
│     - 응답 시간 10~100배 증가                                            │
│     - 사용자 체감 지연 급증                                              │
│                                                                         │
│  2. I/O 폭주                                                             │
│     - 디스크 I/O 대역폭 포화                                             │
│     - 스토리지 병목 발생                                                 │
│     - 다른 인스턴스/서비스에도 영향                                      │
│                                                                         │
│  3. 연쇄적 장애 가능성                                                   │
│     - Connection Timeout 급증                                           │
│     - 애플리케이션 에러 발생                                             │
│     - 서비스 장애로 확대                                                 │
│                                                                         │
│  [허용되는 상황]                                                         │
│     - 개발/테스트 환경에서 성능 테스트 시                                │
│     - DBA가 특수한 목적으로 통제된 환경에서 실행                         │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 2.4 면접에서의 활용

**질문: "성능 테스트의 재현성을 어떻게 확보했나요?"**

```
[합격선 답변]

"동일한 조건에서 비교하기 위해 각 테스트 전에 
ALTER SYSTEM CHECKPOINT와 ALTER SYSTEM FLUSH BUFFER_CACHE를 
순차적으로 실행하여 Buffer Cache를 완전히 초기화했습니다.

CHECKPOINT는 Dirty Buffer를 디스크에 기록하여 Clean 상태로 만들고,
FLUSH BUFFER_CACHE는 Clean Buffer를 무효화합니다.
FLUSH만 실행하면 Dirty Buffer가 남아 완전한 Cold Start가 아닙니다.

이렇게 하지 않으면 이전 테스트에서 캐싱된 블록들이 
다음 테스트에 영향을 주어, Cache Hit Ratio가 달라지고 
공정한 비교가 불가능합니다.

다만 이 명령어들은 운영 환경에서는 절대 실행하면 안 됩니다.
모든 쿼리가 Physical I/O를 발생시켜 
즉각적인 성능 저하를 유발하기 때문입니다."
```

---

## 2.5 연관 개념

FLUSH BUFFER_CACHE를 이해했다면, 다음 개념들도 연결된다:

| 개념 | 연관성 |
|------|--------|
| **Checkpoint** | Dirty Buffer를 디스크에 기록하는 메커니즘. FLUSH 전에 실행해야 완전한 Cold Start 가능 |
| **Instance Recovery** | 인스턴스 재시작 시 Buffer Cache가 비어있는 상태로 시작하는 것과 동일한 효과 |
| **Warm-up 시간** | FLUSH 후 Cache가 다시 "Hot" 상태가 되기까지 걸리는 시간 |

테스트 문서에 이 명령어 실행 여부를 명시하면 피드백에서 요구한 **"테스트 환경과 조건 명시"** 항목을 충족할 수 있다.

---

# 3. 참고 자료

## 3.1 Oracle 공식 문서

- **Memory Architecture**: https://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/memory-architecture.html
- **Database Buffer Cache**: https://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/memory-architecture.html#GUID-4FF66585-E469-4631-9225-29D75594CD14
- **Buffer I/O**: https://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/memory-architecture.html#GUID-D1429BAA-6543-4B34-93DB-C8F33D497B53

## 3.2 관련 V$ 동적 성능 뷰

| 뷰 이름 | 용도 |
|---------|------|
| V$SYSSTAT | session logical reads, physical reads 통계 |
| V$BUFFER_POOL_STATISTICS | Buffer Pool별 Hit Ratio 계산 |
| V$BH | 개별 Buffer Header 상태 조회 |

## 3.3 프로젝트 연관 문서

- Oracle_아키텍처_학습_로드맵_v2.docx
- Oracle_아키텍처_집중학습_섹션_선정_가이드.docx
- 피드백_반영_학습_가이드.docx
- DBMS_섹션_누락사항_피드백.txt

---

# 4. 문서 이력

| 버전 | 일자 | 변경 내용 |
|------|------|-----------|
| 1.0 | 2024-12 | 초안 작성 - Buffer Reads, FLUSH BUFFER_CACHE 섹션 |
| 1.1 | 2024-12 | 기술 검토 반영 - FLUSH 동작 메커니즘 수정(Dirty Buffer 미처리 명시), Logical I/O 정의 명확화, 계산 전개 보완, Latch 표현 정확화, Flash Cache 적용 환경 명시, 테스트 절차에 CHECKPOINT 추가 |
| 1.2 | 2025-01 | 1.2.4 Temp File 섹션 심화 내용 추가 - 아키텍처적 위치, 발생 조건별 상세 메커니즘(Sort/Hash Join/GTT), Direct Path I/O 설계 근거, Hit Ratio 제외 이유 (포트폴리오 범위 외 추후 학습용 기록) |
