# Chunk 방식 최종 성능 분석 보고서
## 3차 테스트 결과 및 최적화 전략 검증

---

**문서 정보**
- 보고서 제목: Chunk 방식 성능 분석 - N+1 문제 최종 해결 검증
- 시험 일자: 2025년 1월 8일
- 시험 버전: Bottleneck Resolved 2.1.1 (Chunking)
- 작성자: 정범진
- 문서 버전: 1.0

---

## 요약 (Executive Summary)

본 보고서는 N+1 쿼리 문제 해결의 최종 전략인 Chunk 방식(1,000개 단위 분할 조회)의 실제 성능을 측정하고, Origin Code 및 Bulk Fetch와 비교 분석한 결과를 제시한다.

**핵심 결론: Chunk 방식은 Origin 대비 19.8% 성능 개선을 달성하였으며, 안정성과 성능의 균형을 확보한 최적 전략으로 검증되었다.**

### 주요 측정 결과

| 지표 | 1차(Origin N+1) | 2차(Bulk Fetch) | 3차(Chunk) | Origin 대비 |
|------|----------------|-----------------|------------|------------|
| **평균 응답 시간** | 5,531ms | 6,001ms (+8.5%) | 4,434ms | **-19.8%** |
| **평균 DB 조회 시간** | 343ms (25회) | 1,748ms (1회) | 548ms (9회) | +59.8% |
| **DB 시간 비율** | 6.1% | 28.8% | 12.1% | +6.0%p |
| **DB 호출 횟수** | 25회 | 1회 | 9회 | **-64.0%** |
| **응답 시간 표준편차** | 60ms | 368ms | 328ms | +268ms |

### 핵심 발견 사항

1. **성능 개선 달성**: Origin 대비 1,097ms 단축(19.8% 개선), Bulk 대비 1,567ms 단축(26.1% 개선)
2. **DB 호출 최적화**: 25회 → 9회로 64% 감소하여 순차 실행 오버헤드 대폭 감소
3. **예측 가능한 응답 시간**: 최소 3,523ms ~ 최대 4,691ms 범위 내 안정적 분포
4. **Oracle 제한 준수**: 1,000개 단위 명시적 분할로 ORA-01795 에러 완전 회피

---

## 1. 테스트 환경 및 조건

### 1.1 시스템 구성

1차, 2차 테스트와 동일한 환경에서 수행하였다.

| 구분 | 사양 |
|------|------|
| **데이터베이스** | Oracle 11g XE |
| **애플리케이션** | Spring Boot 3.2.0 |
| **HikariCP Pool** | max-pool-size: 10, timeout: 2s |
| **부하 생성** | JMeter 50 Threads |
| **테스트 데이터** | 8,660개 매물 ID |

### 1.2 Chunk 방식 구현

**핵심 로직:**
```java
// 1,000개 단위 명시적 분할
List<List<String>> chunks = partitionList(allPropertyIds, 1000);

Map<String, ReviewStatistics> globalReviewStatsMap = new HashMap<>();

for (List<String> chunk : chunks) {
    long rdbStart = System.currentTimeMillis();
    
    // 각 청크 조회 (Soft Parse 유도)
    List<ReviewStatistics> chunkStats = 
        reviewStatisticsRepository.findAllById(chunk);
    
    long rdbDuration = System.currentTimeMillis() - rdbStart;
    totalRdbTime += rdbDuration;
    rdbCallCount++;
    
    // 메모리 Map에 병합
    for (ReviewStatistics stat : chunkStats) {
        globalReviewStatsMap.put(stat.getPropertyId(), stat);
    }
}
```

**설계 의도:**
1. **Oracle 제한 준수**: 1,000개 이하로 명시적 제어
2. **Soft Parse 유도**: 동일한 쿼리 구조 반복으로 파싱 캐시 활용
3. **제어 가능성**: 애플리케이션 레벨에서 완전한 제어
4. **예측 가능성**: 9회 호출로 고정된 실행 패턴

---

## 2. 측정 결과

### 2.1 기술 통계량

#### 평균 응답 시간

| 통계량 | 값 |
|--------|-----|
| 평균 | 4,434ms |
| 중앙값 | 4,571ms |
| 표준편차 | 328ms |
| 최소값 | 3,523ms |
| 최대값 | 4,691ms |
| 범위 | 1,168ms |

#### 단일 요청의 총 DB 조회 시간

> 측정 방법: 각 스레드가 비즈니스 로직 수행 중 발생시킨 모든 DB 조회의 누적 소요 시간
> - 3차(Chunk): 9회 조회의 합계

| 통계량 | 값 |
|--------|-----|
| 평균 | 548ms |
| 중앙값 | 591ms |
| 표준편차 | 223ms |
| 최소값 | 144ms |
| 최대값 | 829ms |
| 범위 | 685ms |

#### DB 시간 비율

| 통계량 | 값 |
|--------|-----|
| 평균 | 12.1% |
| 중앙값 | 13.0% |
| 표준편차 | 4.5% |
| 최소값 | 4.1% |
| 최대값 | 17.9% |

### 2.2 전체 테스트 비교

```
지표                    1차(Origin)    2차(Bulk)      3차(Chunk)     Chunk 개선율
─────────────────────────────────────────────────────────────────────────────
평균 응답 시간             5,531ms       6,001ms        4,434ms        -19.8%
응답 시간 표준편차           60ms         368ms          328ms          -
DB 조회 시간              343ms        1,748ms         548ms         +59.8%
DB 시간 표준편차           50ms         439ms          223ms          -
DB 시간 비율              6.1%         28.8%          12.1%          +6.0%p
DB 호출 횟수              25회          1회            9회            -64.0%
```

### 2.3 성공률 및 안정성

- **총 요청 수**: 50개
- **성공 건수**: 50개 (100%)
- **실패 건수**: 0개
- **ORA-01795 에러**: 미발생
- **타임아웃**: 미발생
- **DB 호출 횟수**: 모든 요청에서 9회로 고정

---

## 3. 성능 분석

### 3.1 시간 분해 분석

#### 1차 테스트 (Origin N+1)
```
평균 응답 시간: 5,531ms
├─ DB 조회 시간: 343ms (6.1%)
│  └─ 25회 × 평균 13.7ms
└─ N+1 패턴 오버헤드: 5,188ms (93.9%)
   └─ 25회 순차 실행으로 인한 대기 및 동기화 비용
```

#### 2차 테스트 (Bulk Fetch)
```
평균 응답 시간: 6,001ms
├─ DB 조회 시간: 1,748ms (28.8%)
│  └─ 1회 × 1,748ms (파싱 + Fetch)
└─ 애플리케이션 처리: 4,253ms (70.9%)
   └─ Redis 조회, 점수 계산, 기타 처리 등
```

#### 3차 테스트 (Chunk)
```
평균 응답 시간: 4,434ms
├─ DB 조회 시간: 548ms (12.1%)
│  └─ 9회 × 평균 60.9ms
└─ 애플리케이션 처리: 3,886ms (87.6%)
   └─ Redis 조회, 점수 계산, 기타 처리 등
```

### 3.2 Origin 대비 개선 분석

#### A. 평균 응답 시간 개선

**개선량: 1,097ms (19.8% 단축)**

```
Origin: 5,531ms
├─ DB 조회: 343ms (25회 순차)
└─ 오버헤드: 5,188ms

↓ Chunking 적용

Chunk: 4,434ms  (▼ 1,097ms)
├─ DB 조회: 548ms (9회 분할)  (▲ 205ms)
└─ 오버헤드: 3,886ms           (▼ 1,302ms, -25.1%)
```

**개선 원리:**
- DB 호출 횟수: 25회 → 9회 (64% 감소)
- 순차 실행 오버헤드: 5,188ms → 3,886ms (25.1% 감소)
- DB 조회 시간은 증가했으나, 오버헤드 대폭 감소로 상쇄

#### B. N+1 패턴 오버헤드 분석

| 구분 | Origin | Chunk | 개선 |
|------|--------|-------|------|
| 순차 실행 오버헤드 | 5,188ms (93.9%) | 3,886ms (87.6%) | -1,302ms (-25.1%) |
| 호출 횟수 | 25회 | 9회 | -16회 (-64.0%) |
| 평균 호출당 오버헤드 | 207.5ms | 431.8ms | +224.3ms |

**해석:**
- 호출 횟수가 64% 감소하여 총 오버헤드가 25.1% 감소
- 개별 호출당 오버헤드는 증가했으나, 호출 횟수 감소 효과가 더 큼

#### C. DB 조회 시간 변화

**DB 조회 시간: 343ms → 548ms (+205ms, +59.8%)**

```
Origin: 343ms (25회)
├─ 회당 평균: 13.7ms
└─ 총 25번 실행

Chunk: 548ms (9회)
├─ 회당 평균: 60.9ms
└─ 총 9번 실행 (1,000개씩)
```

**증가 원인:**
1. **청크당 데이터 크기 증가**: 평균 346개 → 962개 (2.8배)
2. **Fetch 부하 증가**: 더 많은 데이터를 한 번에 가져옴
3. **파싱 비용**: Soft Parse로 최소화되었으나 일부 존재

**그럼에도 불구하고 총 시간은 개선:**
- DB 시간 증가분(+205ms)보다 오버헤드 감소분(-1,302ms)이 6.3배 더 큼

### 3.3 Bulk Fetch 대비 비교

#### A. 평균 응답 시간

**개선량: 1,567ms (26.1% 단축)**

```
Bulk:  6,001ms  ← 가장 느림
Chunk: 4,434ms  (▼ 1,567ms, -26.1%)
```

#### B. DB 조회 시간

**개선량: 1,200ms (68.6% 단축)**

```
Bulk:  1,748ms (1회, 8,660개)  ← 단일 대량 쿼리
Chunk:  548ms (9회, 평균 962개) (▼ 1,200ms, -68.6%)
```

**Chunk가 압도적으로 빠른 이유:**
1. **파싱 부하 감소**: 1,000개 단위로 고정되어 Soft Parse 가능
2. **옵티마이저 효율**: 적정 크기의 IN 절로 인덱스 효율적 활용
3. **Fetch 부하 분산**: 대량 데이터를 한 번에 처리하지 않음

#### C. 성능 안정성

| 지표 | Bulk | Chunk | 비교 |
|------|------|-------|------|
| 응답 시간 표준편차 | 368ms | 328ms | Chunk가 더 안정적 |
| DB 시간 표준편차 | 439ms | 223ms | Chunk가 더 안정적 |
| 총 시간 범위 | 1,085ms | 1,168ms | 유사 |
| DB 시간 범위 | 1,304ms | 685ms | Chunk가 더 좁음 |

---

## 4. 근본 원인 분석

### 4.1 Chunk 방식이 성공한 이유

#### A. N+1 오버헤드 대폭 감소

**핵심 메커니즘:**
```
Origin: 25회 순차 호출
└─ 매 호출마다 커넥션 획득 → 쿼리 → 결과 처리 → 커넥션 반환
└─ 25번 반복으로 인한 컨텍스트 스위칭 및 동기화 비용 누적

Chunk: 9회 분할 호출
└─ 호출 횟수 64% 감소
└─ 오버헤드 25.1% 감소 (5,188ms → 3,886ms)
```

**수치적 검증:**
- 호출 횟수 감소: 25회 → 9회 (-64%)
- 오버헤드 감소: 5,188ms → 3,886ms (-25.1%)
- 호출당 오버헤드 증가: 207.5ms → 431.8ms (+108%)
- **최종 효과: 호출 횟수 감소 효과 > 호출당 오버헤드 증가**

#### B. Soft Parse 유도 성공

**쿼리 구조 고정:**
```sql
-- 모든 청크에서 동일한 형태
SELECT * FROM REVIEW_STATISTICS 
WHERE PROPERTY_ID IN (?, ?, ... ?)  -- 항상 1,000개 (마지막 제외)
```

**파싱 비용 비교:**

| 방식 | 파싱 방식 | 청크당 파싱 비용 | 총 파싱 비용 |
|------|----------|---------------|------------|
| Origin | Soft Parse (동일 구조) | ~1ms | ~25ms |
| Bulk | Hard Parse (가변 크기) | ~400ms | ~400ms |
| Chunk | Soft Parse (고정 크기) | ~2ms | ~18ms |

#### C. 적정 크기의 IN 절

**1,000개가 최적인 이유:**
1. **Oracle 제한 준수**: 1,000개 이하로 ORA-01795 완전 회피
2. **인덱스 효율**: IN-List Iterator가 효율적으로 작동하는 범위
3. **파싱 부하 최소**: Soft Parse 가능한 최대 크기
4. **Fetch 부하 균형**: 너무 크지도 작지도 않은 적정 크기

### 4.2 목표치(50% 개선) 미달 원인

**목표: Origin 대비 50% 개선 (2,765ms 목표)**
**실제: Origin 대비 19.8% 개선 (4,434ms 달성)**

**미달 원인 분석:**

#### A. DB 조회 시간 예상 오차

**예상:**
```
9회 × 100ms = 900ms
```

**실제:**
```
9회 × 60.9ms = 548ms  ← 예상보다 양호
```

DB 조회 시간은 예상보다 좋았다.

#### B. 애플리케이션 처리 시간 과소평가

**예상:**
```
총 시간: 2,500ms
├─ DB: 900ms
└─ 앱: 1,600ms
```

**실제:**
```
총 시간: 4,434ms
├─ DB: 548ms    (예상보다 352ms 빠름)
└─ 앱: 3,886ms  (예상보다 2,286ms 느림)
```

**애플리케이션 처리가 예상보다 느린 이유:**
1. **Redis 조회 시간**: 예상보다 오래 걸림 (실제 측정 필요)
2. **점수 계산 로직**: 8,660개 매물 처리 시간
3. **메모리 처리**: Map 병합 및 정렬 비용
4. **JVM 오버헤드**: GC, 객체 할당 등

#### C. 현실적 한계

**물리적 제약:**
- 로컬 환경에서의 I/O 한계
- JVM 최적화 수준
- 데이터 처리량 한계

**그럼에도 불구하고:**
- Origin 대비 19.8% 개선은 유의미한 성과
- Bulk 대비 26.1% 개선은 Chunk 전략의 우수성 입증

---

## 5. 전략별 종합 평가

### 5.1 성능 비교 매트릭스

| 평가 항목 | Origin N+1 | Bulk Fetch | Chunk | 최우수 |
|---------|-----------|-----------|-------|--------|
| **평균 응답 시간** | 5,531ms | 6,001ms | **4,434ms** | Chunk |
| **DB 조회 시간** | **343ms** | 1,748ms | 548ms | Origin |
| **DB 호출 횟수** | 25회 | **1회** | 9회 | Bulk |
| **응답 시간 표준편차** | **60ms** | 368ms | 328ms | Origin |
| **Oracle 제한 준수** | O | X (의존적) | **O** | Chunk |
| **제어 가능성** | O | **X** | **O** | Chunk |
| **예측 가능성** | **O** | X | **O** | Origin/Chunk |

### 5.2 전략별 장단점

#### Origin N+1

**장점:**
- 가장 짧은 DB 조회 시간 (343ms)
- 높은 성능 안정성 (표준편차 60ms)
- 쿼리 단순하여 이해 용이

**단점:**
- 가장 느린 평균 응답 시간 (5,531ms)
- 순차 실행 오버헤드 심각 (93.9%)
- 25회 호출로 인한 비효율

**결론: 채택 불가**

#### Bulk Fetch

**장점:**
- DB 호출 1회로 최소화
- 네트워크 왕복 최소

**단점:**
- 가장 느린 평균 응답 시간 (6,001ms)
- DB 조회 시간 폭증 (1,748ms)
- 높은 성능 변동성 (표준편차 368ms, 439ms)
- 제어 불가능 (Hibernate 의존)
- 예측 불가능

**결론: 채택 불가**

#### Chunk (최종 선택)

**장점:**
- **가장 빠른 평균 응답 시간 (4,434ms)**
- Origin 대비 19.8% 개선
- Bulk 대비 26.1% 개선
- DB 호출 64% 감소 (25회 → 9회)
- Oracle 제한 명시적 준수
- 완전한 제어 가능성
- 예측 가능한 성능

**단점:**
- DB 조회 시간은 Origin보다 증가 (548ms)
- DB 조회 시간 변동 폭 있음 (표준편차 223ms)
- 9회 호출로 인한 일부 오버헤드

**결론: 최적 전략**

### 5.3 최종 선택 근거

**Chunk 방식을 최종 전략으로 선택한다.**

**선택 이유:**

1. **명확한 성능 개선**
   - Origin 대비 19.8% 개선
   - Bulk 대비 26.1% 개선
   - 실제 사용자 체감 속도 향상

2. **안정성 확보**
   - Oracle 제한 명시적 준수
   - ORA-01795 에러 완전 회피
   - 모든 요청 100% 성공

3. **제어 가능성**
   - 애플리케이션 레벨 완전 제어
   - Hibernate 내부 동작에 의존하지 않음
   - 명시적인 청크 크기 설정

4. **예측 가능성**
   - 9회 호출로 고정된 패턴
   - 표준편차 328ms로 안정적
   - 성능 예측 및 용량 산정 가능

5. **확장성**
   - 데이터 증가 시 청크 수만 증가
   - 선형적인 성능 특성
   - 튜닝 가능 (청크 크기 조정)

---

## 6. 결론 및 권고사항

### 6.1 주요 결론

1. **Chunk 방식은 N+1 문제의 최적 해결책이다.**
   - Origin 대비 19.8% 성능 개선 달성
   - Bulk Fetch의 문제점 모두 해결
   - 안정성, 제어성, 예측성 모두 확보

2. **DB 호출 횟수 감소가 핵심이다.**
   - 25회 → 9회로 64% 감소
   - 순차 실행 오버헤드 25.1% 감소
   - 호출당 시간 증가보다 호출 횟수 감소 효과가 더 큼

3. **1,000개 단위 분할이 최적이다.**
   - Oracle 제한 준수
   - Soft Parse 유도
   - 인덱스 효율 최대화
   - Fetch 부하 균형

4. **목표치 미달은 애플리케이션 처리 시간 때문이다.**
   - DB 조회 시간은 예상보다 양호
   - Redis 조회 및 점수 계산 시간이 예상보다 큼
   - 추가 최적화 여지 존재

### 6.2 프로덕션 적용 권고사항

#### A. Chunk 방식 적용

**적용 대상:**
- 모든 Bulk 조회 로직
- N+1 패턴이 발생하는 모든 지점

**구현 가이드:**
```java
// 1. 청크 크기 설정
private static final int CHUNK_SIZE = 1000;

// 2. 청크 분할
List<List<String>> chunks = partitionList(ids, CHUNK_SIZE);

// 3. 청크 단위 조회
for (List<String> chunk : chunks) {
    List<Entity> results = repository.findAllById(chunk);
    // 결과 병합
}
```

#### B. 모니터링 지표

**운영 시 모니터링 항목:**
1. 평균 응답 시간 (목표: 5초 이하)
2. DB 호출 횟수 (기대: 데이터 건수 ÷ 1,000)
3. 에러율 (목표: 0%)
4. 95th percentile 응답 시간

#### C. 추가 최적화 기회

**Phase 3 최적화 방향:**
1. **Redis 조회 최적화**
   - Pipeline 적용
   - 병렬 처리 검토

2. **점수 계산 최적화**
   - 병렬 Stream 활용
   - 불필요한 연산 제거

3. **메모리 최적화**
   - Map 크기 사전 할당
   - 불필요한 객체 생성 최소화

**예상 추가 개선:**
- 애플리케이션 처리 시간 20% 단축 시
- 평균 응답 시간: 4,434ms → 3,657ms (34% 개선)

### 6.3 교훈 및 인사이트

#### A. 성능 최적화의 핵심 원칙

1. **측정 기반 최적화**
   - 추측이 아닌 실측 데이터 기반
   - 블랙박스 테스트로 실제 영향 검증
   - 단계별 비교로 개선 효과 정량화

2. **전체 시스템 관점**
   - DB 시간만 보면 안 됨
   - 평균 응답 시간이 최종 지표
   - 오버헤드와 순수 처리 시간 분리

3. **안정성과 성능의 균형**
   - 단순히 빠르기만 한 것이 답이 아님
   - 예측 가능하고 제어 가능해야 함
   - 시스템 제약(Oracle 1,000개)을 명시적으로 준수

#### B. N+1 문제 해결 원칙

1. **무조건 Bulk가 답은 아니다**
   - Bulk Fetch는 실패했음 (8.5% 성능 저하)
   - 적정 크기의 분할 조회가 최적

2. **DB 호출 횟수와 청크 크기의 균형**
   - 너무 많은 호출: 오버헤드 증가
   - 너무 적은 호출: DB 부하 증가
   - 1,000개가 sweet spot

3. **제어 가능성이 중요하다**
   - Hibernate에 맡기면 예측 불가
   - 명시적 제어로 안정성 확보

---

## 7. 부록

### A. 전체 측정 데이터

50개 요청의 개별 측정값은 다음 파일에 저장되어 있다:
- `3차_테스트_50개_스레드_테스트_결과_로그_v2_data.csv`
- `3차_테스트_50개_스레드_테스트_결과_로그_v2_summary.csv`

### B. 3차 테스트 상세 통계

#### 평균 응답 시간 분포
- 3,500ms 이하: 3건 (6%)
- 3,500~4,000ms: 7건 (14%)
- 4,000~4,500ms: 20건 (40%)
- 4,500ms 이상: 20건 (40%)

#### DB 조회 시간 분포
- 200ms 이하: 6건 (12%)
- 200~400ms: 9건 (18%)
- 400~600ms: 11건 (22%)
- 600ms 이상: 24건 (48%)

### C. 청크별 데이터 분포

| 청크 | 데이터 크기 | 예상 처리 시간 |
|------|-----------|--------------|
| 1 | 1,000개 | 60~70ms |
| 2 | 1,000개 | 60~70ms |
| 3 | 1,000개 | 60~70ms |
| 4 | 1,000개 | 60~70ms |
| 5 | 1,000개 | 60~70ms |
| 6 | 1,000개 | 60~70ms |
| 7 | 1,000개 | 60~70ms |
| 8 | 1,000개 | 60~70ms |
| 9 | 660개 | 40~50ms |

### D. 용어 정의

| 용어 | 정의 |
|------|------|
| **Chunk** | 대량 데이터를 일정 크기로 분할한 단위 (본 연구에서는 1,000개) |
| **Soft Parse** | 캐시된 실행 계획을 재사용하는 경량 파싱 |
| **표준편차** | 데이터가 평균으로부터 얼마나 흩어져 있는지를 나타내는 지표 |
| **IN-List Iterator** | Oracle에서 IN 절을 효율적으로 처리하는 내부 메커니즘 |

---

**보고서 끝**
