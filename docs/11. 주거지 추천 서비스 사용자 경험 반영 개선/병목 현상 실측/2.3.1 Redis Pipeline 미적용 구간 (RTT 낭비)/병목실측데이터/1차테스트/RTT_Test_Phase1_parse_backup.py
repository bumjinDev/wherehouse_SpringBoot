#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Redis Pipeline ë³‘ëª© ì¸¡ì • ë¡œê·¸ íŒŒì„œ
==================================
Tomcat ë¡œê·¸ íŒŒì¼ì—ì„œ [Metrics-Sequential] ë° [Metrics-LoopSummary] ë¡œê·¸ë¥¼ 
íŒŒì‹±í•˜ì—¬ ë¶„ì„ìš© ë°ì´í„°ë¡œ ë³€í™˜í•œë‹¤.

ì‚¬ìš©ë²•:
    python parse_redis_metrics.py <log_file_path> [options]
    
ì˜ˆì‹œ:
    python parse_redis_metrics.py /var/log/tomcat/catalina.out
    python parse_redis_metrics.py ./spring.log --output csv
    python parse_redis_metrics.py ./spring.log --output json --export results.json
"""

import re
import sys
import json
import argparse
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional, Tuple
from statistics import mean, stdev, median
from collections import defaultdict


# =============================================================================
# ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜
# =============================================================================

@dataclass
class SequentialMetric:
    """[Metrics-Sequential] ë¡œê·¸ íŒŒì‹± ê²°ê³¼"""
    timestamp: Optional[str]
    thread_name: Optional[str]  # Tomcat ìŠ¤ë ˆë“œ ì´ë¦„ (ì˜ˆ: http-nio-8080-exec-1)
    district: str
    commands: int
    method_time_ms: float
    total_cmd_latency_ms: float
    io_ratio_pct: float
    non_io_time_ms: float
    cmd1_latency_ms: float
    cmd1_count: int
    cmd2_latency_ms: float
    cmd2_count: int
    cmd3_latency_ms: float
    cmd3_count: int
    status: str
    intersection_count: Optional[int] = None


@dataclass
class LoopSummaryMetric:
    """[Metrics-LoopSummary] ë¡œê·¸ íŒŒì‹± ê²°ê³¼"""
    timestamp: Optional[str]
    thread_name: Optional[str]  # Tomcat ìŠ¤ë ˆë“œ ì´ë¦„
    mode: str
    total_districts: int
    success_districts: int
    empty_districts: int
    total_properties: int
    loop_time_ms: float
    avg_per_district_ms: float


@dataclass
class AnalysisSummary:
    """ë¶„ì„ ìš”ì•½ ê²°ê³¼"""
    total_records: int
    avg_method_time_ms: float
    avg_cmd_latency_ms: float
    avg_io_ratio_pct: float
    min_method_time_ms: float
    max_method_time_ms: float
    std_method_time_ms: float
    avg_cmd1_ms: float
    avg_cmd2_ms: float
    avg_cmd3_ms: float
    success_rate_pct: float
    early_termination_rate_pct: float


# =============================================================================
# ì •ê·œì‹ íŒ¨í„´ ì •ì˜
# =============================================================================

# íƒ€ì„ìŠ¤íƒ¬í”„ íŒ¨í„´ (ë‹¤ì–‘í•œ ë¡œê·¸ í¬ë§· ëŒ€ì‘)
TIMESTAMP_PATTERNS = [
    r'(\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}[.,]?\d*)',  # ISO í˜•ì‹
    r'(\d{2}-\w{3}-\d{4} \d{2}:\d{2}:\d{2})',              # Tomcat ê¸°ë³¸
    r'(\d{2}:\d{2}:\d{2}[.,]\d+)',                          # ì‹œê°„ë§Œ
]

# ìŠ¤ë ˆë“œ ì´ë¦„ íŒ¨í„´ (ë‹¤ì–‘í•œ ë¡œê·¸ í¬ë§· ëŒ€ì‘)
# ì˜ˆ: [http-nio-8080-exec-1], [main], [scheduling-1], [pool-1-thread-1]
THREAD_PATTERNS = [
    r'\[([^\]]*exec[^\]]*)\]',           # http-nio-8080-exec-1, http-apr-8080-exec-3
    r'\[([^\]]*thread[^\]]*)\]',         # pool-1-thread-1
    r'\[(scheduling-\d+)\]',             # scheduling-1
    r'\[(main)\]',                       # main
    r'--- \[([^\]]+)\]',                 # Spring Boot í˜•ì‹: --- [thread-name]
    r'\] \[([^\]]+)\] [a-z]',            # ì¼ë°˜ í˜•ì‹: ] [thread-name] c.w.r
    r'\[([a-zA-Z]+-[a-zA-Z]+-\d+-[a-zA-Z]+-\d+)\]',  # ì¼ë°˜ì ì¸ ìŠ¤ë ˆë“œ íŒ¨í„´
]

# [Metrics-Sequential] ë¡œê·¸ íŒ¨í„´
SEQUENTIAL_PATTERN = re.compile(
    r'\[Metrics-Sequential\]\s*'
    r'district=([^,]+),\s*'
    r'commands=(-?\d+),\s*'
    r'methodTime=([\d.]+)\s*ms,\s*'
    r'totalCmdLatency=([\d.]+)\s*ms,\s*'
    r'ioRatio=([\d.]+)\s*%,\s*'
    r'nonIoTime=([\d.]+)\s*ms,\s*'
    r'cmd1=([\d.]+)\s*ms\s*\((\d+)ê±´\),\s*'
    r'cmd2=([\d.]+)\s*ms\s*\((\d+)ê±´\),\s*'
    r'cmd3=([\d.]+)\s*ms\s*\((\d+)ê±´\),\s*'
    r'status=(.+?)(?:\s*$|\s*\n)',
    re.UNICODE
)

# [Metrics-LoopSummary] ë¡œê·¸ íŒ¨í„´
LOOP_SUMMARY_PATTERN = re.compile(
    r'\[Metrics-LoopSummary\]\s*'
    r'mode=(\w+),\s*'
    r'totalDistricts=(\d+),\s*'
    r'successDistricts=(\d+),\s*'
    r'emptyDistricts=(\d+),\s*'
    r'totalProperties=(\d+),\s*'
    r'loopTime=([\d.]+)\s*ms,\s*'
    r'avgPerDistrict=([\d.]+)\s*ms',
    re.UNICODE
)


# =============================================================================
# íŒŒì‹± í•¨ìˆ˜
# =============================================================================

def extract_timestamp(line: str) -> Optional[str]:
    """ë¡œê·¸ ë¼ì¸ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ"""
    for pattern in TIMESTAMP_PATTERNS:
        match = re.search(pattern, line)
        if match:
            return match.group(1)
    return None


def extract_thread_name(line: str) -> Optional[str]:
    """ë¡œê·¸ ë¼ì¸ì—ì„œ Tomcat ìŠ¤ë ˆë“œ ì´ë¦„ ì¶”ì¶œ
    
    ì§€ì› í˜•ì‹:
    - [http-nio-8080-exec-1] 
    - [pool-1-thread-1]
    - --- [thread-name] (Spring Boot)
    """
    for pattern in THREAD_PATTERNS:
        match = re.search(pattern, line)
        if match:
            return match.group(1)
    return None


def parse_sequential_log(line: str) -> Optional[SequentialMetric]:
    """[Metrics-Sequential] ë¡œê·¸ íŒŒì‹±"""
    match = SEQUENTIAL_PATTERN.search(line)
    if not match:
        return None
    
    timestamp = extract_timestamp(line)
    thread_name = extract_thread_name(line)
    status = match.group(13).strip()
    
    # intersection ê°’ ì¶”ì¶œ
    intersection_count = None
    if 'intersection=' in status:
        try:
            intersection_count = int(re.search(r'intersection=(\d+)', status).group(1))
        except (AttributeError, ValueError):
            pass
    
    return SequentialMetric(
        timestamp=timestamp,
        thread_name=thread_name,
        district=match.group(1).strip(),
        commands=int(match.group(2)),
        method_time_ms=float(match.group(3)),
        total_cmd_latency_ms=float(match.group(4)),
        io_ratio_pct=float(match.group(5)),
        non_io_time_ms=float(match.group(6)),
        cmd1_latency_ms=float(match.group(7)),
        cmd1_count=int(match.group(8)),
        cmd2_latency_ms=float(match.group(9)),
        cmd2_count=int(match.group(10)),
        cmd3_latency_ms=float(match.group(11)),
        cmd3_count=int(match.group(12)),
        status=status,
        intersection_count=intersection_count
    )


def parse_loop_summary_log(line: str) -> Optional[LoopSummaryMetric]:
    """[Metrics-LoopSummary] ë¡œê·¸ íŒŒì‹±"""
    match = LOOP_SUMMARY_PATTERN.search(line)
    if not match:
        return None
    
    timestamp = extract_timestamp(line)
    thread_name = extract_thread_name(line)
    
    return LoopSummaryMetric(
        timestamp=timestamp,
        thread_name=thread_name,
        mode=match.group(1),
        total_districts=int(match.group(2)),
        success_districts=int(match.group(3)),
        empty_districts=int(match.group(4)),
        total_properties=int(match.group(5)),
        loop_time_ms=float(match.group(6)),
        avg_per_district_ms=float(match.group(7))
    )


def parse_log_file(filepath: str) -> Tuple[List[SequentialMetric], List[LoopSummaryMetric]]:
    """ë¡œê·¸ íŒŒì¼ ì „ì²´ íŒŒì‹±"""
    sequential_metrics = []
    loop_summary_metrics = []
    
    path = Path(filepath)
    if not path.exists():
        raise FileNotFoundError(f"ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
    
    # ì¸ì½”ë”© ìë™ ê°ì§€ ì‹œë„
    encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
    content = None
    
    for encoding in encodings:
        try:
            with open(filepath, 'r', encoding=encoding) as f:
                content = f.read()
            break
        except UnicodeDecodeError:
            continue
    
    if content is None:
        raise ValueError(f"ë¡œê·¸ íŒŒì¼ ì¸ì½”ë”©ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
    
    for line in content.splitlines():
        # Sequential ë©”íŠ¸ë¦­ íŒŒì‹±
        if '[Metrics-Sequential]' in line:
            metric = parse_sequential_log(line)
            if metric:
                sequential_metrics.append(metric)
        
        # LoopSummary ë©”íŠ¸ë¦­ íŒŒì‹±
        if '[Metrics-LoopSummary]' in line:
            metric = parse_loop_summary_log(line)
            if metric:
                loop_summary_metrics.append(metric)
    
    return sequential_metrics, loop_summary_metrics


# =============================================================================
# ë¶„ì„ í•¨ìˆ˜
# =============================================================================

def analyze_sequential_metrics(metrics: List[SequentialMetric]) -> Optional[AnalysisSummary]:
    """Sequential ë©”íŠ¸ë¦­ í†µê³„ ë¶„ì„"""
    if not metrics:
        return None
    
    method_times = [m.method_time_ms for m in metrics]
    cmd_latencies = [m.total_cmd_latency_ms for m in metrics]
    io_ratios = [m.io_ratio_pct for m in metrics]
    cmd1_times = [m.cmd1_latency_ms for m in metrics]
    cmd2_times = [m.cmd2_latency_ms for m in metrics if m.cmd2_latency_ms > 0]
    cmd3_times = [m.cmd3_latency_ms for m in metrics if m.cmd3_latency_ms > 0]
    
    success_count = sum(1 for m in metrics if 'SUCCESS' in m.status)
    early_term_count = sum(1 for m in metrics if 'EARLY_RETURN' in m.status)
    
    return AnalysisSummary(
        total_records=len(metrics),
        avg_method_time_ms=mean(method_times),
        avg_cmd_latency_ms=mean(cmd_latencies),
        avg_io_ratio_pct=mean(io_ratios),
        min_method_time_ms=min(method_times),
        max_method_time_ms=max(method_times),
        std_method_time_ms=stdev(method_times) if len(method_times) > 1 else 0,
        avg_cmd1_ms=mean(cmd1_times),
        avg_cmd2_ms=mean(cmd2_times) if cmd2_times else 0,
        avg_cmd3_ms=mean(cmd3_times) if cmd3_times else 0,
        success_rate_pct=(success_count / len(metrics)) * 100,
        early_termination_rate_pct=(early_term_count / len(metrics)) * 100
    )


def analyze_by_district(metrics: List[SequentialMetric]) -> Dict[str, AnalysisSummary]:
    """ì§€ì—­êµ¬ë³„ ë¶„ì„"""
    by_district = defaultdict(list)
    for m in metrics:
        by_district[m.district].append(m)
    
    results = {}
    for district, district_metrics in by_district.items():
        summary = analyze_sequential_metrics(district_metrics)
        if summary:
            results[district] = summary
    
    return results


def analyze_by_thread(metrics: List[SequentialMetric]) -> Dict[str, AnalysisSummary]:
    """ìŠ¤ë ˆë“œë³„ ë¶„ì„"""
    by_thread = defaultdict(list)
    for m in metrics:
        thread_key = m.thread_name if m.thread_name else "(unknown)"
        by_thread[thread_key].append(m)
    
    results = {}
    for thread_name, thread_metrics in by_thread.items():
        summary = analyze_sequential_metrics(thread_metrics)
        if summary:
            results[thread_name] = summary
    
    return results


def group_by_request(sequential: List[SequentialMetric], 
                     loop_summary: List[LoopSummaryMetric]) -> Dict[str, Dict]:
    """ìŠ¤ë ˆë“œ+íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ìœ¼ë¡œ ìš”ì²­(Request) ë‹¨ìœ„ ê·¸ë£¹í™”
    
    í•˜ë‚˜ì˜ API ìš”ì²­ì—ì„œ ë°œìƒí•œ 25ê°œ ì§€ì—­êµ¬ ì²˜ë¦¬ + 1ê°œ LoopSummaryë¥¼ ë¬¶ìŒ
    """
    requests = defaultdict(lambda: {'sequential': [], 'loop_summary': None})
    
    # LoopSummaryë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìš”ì²­ ì‹ë³„
    for ls in loop_summary:
        key = f"{ls.thread_name}|{ls.timestamp}" if ls.thread_name else f"(unknown)|{ls.timestamp}"
        requests[key]['loop_summary'] = ls
    
    # Sequential ë©”íŠ¸ë¦­ì„ í•´ë‹¹ ìš”ì²­ì— ë§¤í•‘
    for seq in sequential:
        # ê°€ì¥ ê°€ê¹Œìš´ LoopSummary ì°¾ê¸° (ê°™ì€ ìŠ¤ë ˆë“œ, ì‹œê°„ ê·¼ì ‘)
        thread = seq.thread_name if seq.thread_name else "(unknown)"
        
        # ë‹¨ìˆœ ë§¤í•‘: ê°™ì€ ìŠ¤ë ˆë“œì˜ ëª¨ë“  sequentialì„ í•´ë‹¹ ìŠ¤ë ˆë“œë¡œ ê·¸ë£¹í™”
        matched = False
        for key in requests:
            if key.startswith(thread + "|"):
                requests[key]['sequential'].append(seq)
                matched = True
                break
        
        if not matched:
            # LoopSummary ì—†ì´ ë‹¨ë… sequentialì¸ ê²½ìš°
            key = f"{thread}|{seq.timestamp}"
            requests[key]['sequential'].append(seq)
    
    return dict(requests)


# =============================================================================
# ì¶œë ¥ í•¨ìˆ˜
# =============================================================================

def print_sequential_table(metrics: List[SequentialMetric], limit: int = 50):
    """Sequential ë©”íŠ¸ë¦­ í…Œì´ë¸” ì¶œë ¥ (ìŠ¤ë ˆë“œ ì •ë³´ í¬í•¨)"""
    print("\n" + "=" * 140)
    print("[Metrics-Sequential] ìƒì„¸ ë°ì´í„°")
    print("=" * 140)
    
    header = f"{'ìŠ¤ë ˆë“œ':<25} {'ì§€ì—­êµ¬':<10} {'Cmd':>3} {'MethodTime':>12} {'CmdLatency':>12} {'I/O%':>8} {'Cmd1':>10} {'Cmd2':>10} {'Cmd3':>10} {'Status':<25}"
    print(header)
    print("-" * 140)
    
    for i, m in enumerate(metrics[:limit]):
        thread_display = (m.thread_name[:23] + "..") if m.thread_name and len(m.thread_name) > 25 else (m.thread_name or "(unknown)")
        status_display = m.status[:23] + ".." if len(m.status) > 25 else m.status
        print(f"{thread_display:<25} {m.district:<10} {m.commands:>3} "
              f"{m.method_time_ms:>10.4f}ms {m.total_cmd_latency_ms:>10.4f}ms "
              f"{m.io_ratio_pct:>6.2f}% "
              f"{m.cmd1_latency_ms:>8.4f}ms {m.cmd2_latency_ms:>8.4f}ms {m.cmd3_latency_ms:>8.4f}ms "
              f"{status_display:<25}")
    
    if len(metrics) > limit:
        print(f"\n... ì™¸ {len(metrics) - limit}ê±´ (--limit ì˜µì…˜ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥)")


def print_loop_summary_table(metrics: List[LoopSummaryMetric]):
    """LoopSummary ë©”íŠ¸ë¦­ í…Œì´ë¸” ì¶œë ¥ (ìŠ¤ë ˆë“œ ì •ë³´ í¬í•¨)"""
    print("\n" + "=" * 130)
    print("[Metrics-LoopSummary] ì „ì²´ ìˆœíšŒ ìš”ì•½")
    print("=" * 130)
    
    header = f"{'ìŠ¤ë ˆë“œ':<25} {'Mode':<12} {'ì´ì§€ì—­êµ¬':>8} {'ì„±ê³µ':>6} {'ë¹ˆê²°ê³¼':>6} {'ì´ë§¤ë¬¼':>8} {'LoopTime':>12} {'Avg/District':>14}"
    print(header)
    print("-" * 130)
    
    for m in metrics:
        thread_display = (m.thread_name[:23] + "..") if m.thread_name and len(m.thread_name) > 25 else (m.thread_name or "(unknown)")
        print(f"{thread_display:<25} {m.mode:<12} {m.total_districts:>8} {m.success_districts:>6} "
              f"{m.empty_districts:>6} {m.total_properties:>8} "
              f"{m.loop_time_ms:>10.4f}ms {m.avg_per_district_ms:>12.4f}ms")


def print_analysis_summary(summary: AnalysisSummary, title: str = "ì „ì²´"):
    """ë¶„ì„ ìš”ì•½ ì¶œë ¥"""
    print(f"\n{'â”€' * 60}")
    print(f"ğŸ“Š ë¶„ì„ ìš”ì•½ ({title})")
    print(f"{'â”€' * 60}")
    print(f"  ì´ ë ˆì½”ë“œ ìˆ˜        : {summary.total_records}ê±´")
    print(f"  í‰ê·  Method Time    : {summary.avg_method_time_ms:.4f} ms")
    print(f"  í‰ê·  Cmd Latency    : {summary.avg_cmd_latency_ms:.4f} ms")
    print(f"  í‰ê·  I/O ë¹„ìœ¨       : {summary.avg_io_ratio_pct:.2f} %")
    print(f"  ìµœì†Œ Method Time    : {summary.min_method_time_ms:.4f} ms")
    print(f"  ìµœëŒ€ Method Time    : {summary.max_method_time_ms:.4f} ms")
    print(f"  í‘œì¤€í¸ì°¨            : {summary.std_method_time_ms:.4f} ms")
    print(f"  í‰ê·  Cmd1 (ë³´ì¦ê¸ˆ)  : {summary.avg_cmd1_ms:.4f} ms")
    print(f"  í‰ê·  Cmd2 (ì›”ì„¸)    : {summary.avg_cmd2_ms:.4f} ms")
    print(f"  í‰ê·  Cmd3 (í‰ìˆ˜)    : {summary.avg_cmd3_ms:.4f} ms")
    print(f"  ì„±ê³µë¥               : {summary.success_rate_pct:.2f} %")
    print(f"  ì¡°ê¸°ì¢…ë£Œìœ¨          : {summary.early_termination_rate_pct:.2f} %")


def print_district_analysis(district_summaries: Dict[str, AnalysisSummary]):
    """ì§€ì—­êµ¬ë³„ ë¶„ì„ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("ğŸ“ ì§€ì—­êµ¬ë³„ ë¶„ì„")
    print("=" * 80)
    
    header = f"{'ì§€ì—­êµ¬':<10} {'ê±´ìˆ˜':>6} {'Avg Method':>12} {'Avg CmdLat':>12} {'I/O%':>8} {'ì„±ê³µë¥ ':>8}"
    print(header)
    print("-" * 80)
    
    # í‰ê·  Method Time ê¸°ì¤€ ì •ë ¬
    sorted_districts = sorted(
        district_summaries.items(), 
        key=lambda x: x[1].avg_method_time_ms, 
        reverse=True
    )
    
    for district, summary in sorted_districts:
        print(f"{district:<10} {summary.total_records:>6} "
              f"{summary.avg_method_time_ms:>10.4f}ms "
              f"{summary.avg_cmd_latency_ms:>10.4f}ms "
              f"{summary.avg_io_ratio_pct:>6.2f}% "
              f"{summary.success_rate_pct:>6.2f}%")


def print_thread_analysis(thread_summaries: Dict[str, AnalysisSummary]):
    """ìŠ¤ë ˆë“œë³„ ë¶„ì„ ì¶œë ¥"""
    print("\n" + "=" * 100)
    print("ğŸ§µ ìŠ¤ë ˆë“œë³„ ë¶„ì„")
    print("=" * 100)
    
    header = f"{'ìŠ¤ë ˆë“œ':<30} {'ê±´ìˆ˜':>6} {'Avg Method':>12} {'Avg CmdLat':>12} {'I/O%':>8} {'ì„±ê³µë¥ ':>8}"
    print(header)
    print("-" * 100)
    
    # ê±´ìˆ˜ ê¸°ì¤€ ì •ë ¬
    sorted_threads = sorted(
        thread_summaries.items(), 
        key=lambda x: x[1].total_records, 
        reverse=True
    )
    
    for thread_name, summary in sorted_threads:
        thread_display = (thread_name[:28] + "..") if len(thread_name) > 30 else thread_name
        print(f"{thread_display:<30} {summary.total_records:>6} "
              f"{summary.avg_method_time_ms:>10.4f}ms "
              f"{summary.avg_cmd_latency_ms:>10.4f}ms "
              f"{summary.avg_io_ratio_pct:>6.2f}% "
              f"{summary.success_rate_pct:>6.2f}%")


def print_request_analysis(requests: Dict[str, Dict]):
    """ìš”ì²­ ë‹¨ìœ„ ë¶„ì„ ì¶œë ¥ (ìŠ¤ë ˆë“œë³„ í•˜ë‚˜ì˜ ì™„ì „í•œ ìš”ì²­)"""
    print("\n" + "=" * 120)
    print("ğŸ“¦ ìš”ì²­(Request) ë‹¨ìœ„ ë¶„ì„ - ê° API í˜¸ì¶œë³„ ë©”íŠ¸ë¦­")
    print("=" * 120)
    
    header = f"{'ìŠ¤ë ˆë“œ':<25} {'Timestamp':<26} {'ì§€ì—­êµ¬':>6} {'LoopTime':>12} {'Avg/District':>14} {'ì´ë§¤ë¬¼':>8}"
    print(header)
    print("-" * 120)
    
    for key, data in requests.items():
        parts = key.split("|", 1)
        thread_name = parts[0] if len(parts) > 0 else "(unknown)"
        timestamp = parts[1] if len(parts) > 1 else "-"
        
        thread_display = (thread_name[:23] + "..") if len(thread_name) > 25 else thread_name
        
        seq_count = len(data['sequential'])
        ls = data['loop_summary']
        
        if ls:
            print(f"{thread_display:<25} {timestamp:<26} {seq_count:>6} "
                  f"{ls.loop_time_ms:>10.4f}ms {ls.avg_per_district_ms:>12.4f}ms "
                  f"{ls.total_properties:>8}")
        else:
            # LoopSummary ì—†ì´ Sequentialë§Œ ìˆëŠ” ê²½ìš°
            total_method_time = sum(m.method_time_ms for m in data['sequential'])
            avg_method_time = total_method_time / seq_count if seq_count > 0 else 0
            print(f"{thread_display:<25} {timestamp:<26} {seq_count:>6} "
                  f"{total_method_time:>10.4f}ms {avg_method_time:>12.4f}ms "
                  f"{'(N/A)':>8}")


def print_before_after_template(summary: AnalysisSummary):
    """Before/After ë¹„êµìš© í…œí”Œë¦¿ ì¶œë ¥"""
    print("\n" + "=" * 70)
    print("ğŸ“‹ Before/After ë¹„êµìš© ë°ì´í„° (ë³µì‚¬í•˜ì—¬ ì‚¬ìš©)")
    print("=" * 70)
    print(f"""
| ì§€í‘œ                  | Before (ìˆœì°¨)         | After (Pipeline)      | ê°œì„ ìœ¨      |
|-----------------------|-----------------------|-----------------------|-------------|
| í‰ê·  Method Time      | {summary.avg_method_time_ms:.4f} ms         | ___.___ ms            | __.___%     |
| í‰ê·  Cmd Latency      | {summary.avg_cmd_latency_ms:.4f} ms         | ___.___ ms            | __.___%     |
| í‰ê·  I/O ë¹„ìœ¨         | {summary.avg_io_ratio_pct:.2f} %           | __.___%               | -           |
| Cmd1 í‰ê·  (ë³´ì¦ê¸ˆ)    | {summary.avg_cmd1_ms:.4f} ms         | -                     | -           |
| Cmd2 í‰ê·  (ì›”ì„¸)      | {summary.avg_cmd2_ms:.4f} ms         | -                     | -           |
| Cmd3 í‰ê·  (í‰ìˆ˜)      | {summary.avg_cmd3_ms:.4f} ms         | -                     | -           |
| ì¸¡ì • ê±´ìˆ˜             | {summary.total_records}ê±´                | ___ê±´                 | -           |
| ì„±ê³µë¥                 | {summary.success_rate_pct:.2f} %           | __.___%               | -           |
| ì¡°ê¸°ì¢…ë£Œìœ¨            | {summary.early_termination_rate_pct:.2f} %           | 0.00% (ë¶ˆê°€)          | -           |
""")


def export_to_csv(sequential: List[SequentialMetric], 
                  loop_summary: List[LoopSummaryMetric], 
                  filepath: str):
    """CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    import csv
    
    # Sequential ë°ì´í„°
    seq_path = filepath.replace('.csv', '_sequential.csv')
    with open(seq_path, 'w', newline='', encoding='utf-8-sig') as f:
        if sequential:
            writer = csv.DictWriter(f, fieldnames=asdict(sequential[0]).keys())
            writer.writeheader()
            for m in sequential:
                writer.writerow(asdict(m))
    print(f"âœ… Sequential ë°ì´í„° ì €ì¥: {seq_path}")
    
    # LoopSummary ë°ì´í„°
    loop_path = filepath.replace('.csv', '_loop_summary.csv')
    with open(loop_path, 'w', newline='', encoding='utf-8-sig') as f:
        if loop_summary:
            writer = csv.DictWriter(f, fieldnames=asdict(loop_summary[0]).keys())
            writer.writeheader()
            for m in loop_summary:
                writer.writerow(asdict(m))
    print(f"âœ… LoopSummary ë°ì´í„° ì €ì¥: {loop_path}")


def export_to_xlsx(sequential: List[SequentialMetric],
                   loop_summary: List[LoopSummaryMetric],
                   summary: Optional[AnalysisSummary],
                   filepath: str):
    """Excel íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° - ë°ì´í„° ìœ í˜•ë³„ ì‹œíŠ¸ ë¶„ë¦¬"""
    from openpyxl import Workbook
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    from openpyxl.utils.dataframe import dataframe_to_rows
    
    wb = Workbook()
    
    # ìŠ¤íƒ€ì¼ ì •ì˜
    header_font = Font(bold=True, color='FFFFFF')
    header_fill = PatternFill('solid', fgColor='4472C4')
    header_alignment = Alignment(horizontal='center', vertical='center')
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    number_font = Font(name='Consolas')
    
    def apply_header_style(sheet, row_num, col_count):
        for col in range(1, col_count + 1):
            cell = sheet.cell(row=row_num, column=col)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
            cell.border = thin_border
    
    def apply_data_style(sheet, start_row, end_row, col_count):
        for row in range(start_row, end_row + 1):
            for col in range(1, col_count + 1):
                cell = sheet.cell(row=row, column=col)
                cell.border = thin_border
                cell.alignment = Alignment(horizontal='center')
    
    def auto_column_width(sheet):
        for column_cells in sheet.columns:
            max_length = 0
            column = column_cells[0].column_letter
            for cell in column_cells:
                try:
                    if cell.value:
                        max_length = max(max_length, len(str(cell.value)))
                except:
                    pass
            sheet.column_dimensions[column].width = min(max_length + 2, 50)
    
    # ========================================
    # Sheet 1: Sequential Metrics (ìƒì„¸ ë°ì´í„°)
    # ========================================
    ws1 = wb.active
    ws1.title = "Sequential_Metrics"
    
    if sequential:
        headers = ['Timestamp', 'Thread', 'District', 'Commands', 
                   'MethodTime(ms)', 'CmdLatency(ms)', 'IO_Ratio(%)', 'NonIO(ms)',
                   'Cmd1(ms)', 'Cmd1_Count', 'Cmd2(ms)', 'Cmd2_Count', 
                   'Cmd3(ms)', 'Cmd3_Count', 'Status', 'Intersection']
        ws1.append(headers)
        apply_header_style(ws1, 1, len(headers))
        
        for m in sequential:
            ws1.append([
                m.timestamp or '',
                m.thread_name or '',
                m.district,
                m.commands,
                round(m.method_time_ms, 4),
                round(m.total_cmd_latency_ms, 4),
                round(m.io_ratio_pct, 2),
                round(m.non_io_time_ms, 4),
                round(m.cmd1_latency_ms, 4),
                m.cmd1_count,
                round(m.cmd2_latency_ms, 4),
                m.cmd2_count,
                round(m.cmd3_latency_ms, 4),
                m.cmd3_count,
                m.status,
                m.intersection_count if m.intersection_count is not None else ''
            ])
        
        apply_data_style(ws1, 2, len(sequential) + 1, len(headers))
        auto_column_width(ws1)
    
    # ========================================
    # Sheet 2: LoopSummary Metrics (ìˆœíšŒ ìš”ì•½)
    # ========================================
    ws2 = wb.create_sheet("LoopSummary_Metrics")
    
    if loop_summary:
        headers = ['Timestamp', 'Thread', 'Mode', 'TotalDistricts', 
                   'SuccessDistricts', 'EmptyDistricts', 'TotalProperties',
                   'LoopTime(ms)', 'AvgPerDistrict(ms)']
        ws2.append(headers)
        apply_header_style(ws2, 1, len(headers))
        
        for m in loop_summary:
            ws2.append([
                m.timestamp or '',
                m.thread_name or '',
                m.mode,
                m.total_districts,
                m.success_districts,
                m.empty_districts,
                m.total_properties,
                round(m.loop_time_ms, 4),
                round(m.avg_per_district_ms, 4)
            ])
        
        apply_data_style(ws2, 2, len(loop_summary) + 1, len(headers))
        auto_column_width(ws2)
    
    # ========================================
    # Sheet 3: Analysis Summary (ë¶„ì„ ìš”ì•½)
    # ========================================
    ws3 = wb.create_sheet("Analysis_Summary")
    
    if summary:
        ws3.append(['ì§€í‘œ', 'ê°’', 'ë‹¨ìœ„'])
        apply_header_style(ws3, 1, 3)
        
        data = [
            ('ì´ ë ˆì½”ë“œ ìˆ˜', summary.total_records, 'ê±´'),
            ('í‰ê·  Method Time', round(summary.avg_method_time_ms, 4), 'ms'),
            ('í‰ê·  Cmd Latency', round(summary.avg_cmd_latency_ms, 4), 'ms'),
            ('í‰ê·  I/O ë¹„ìœ¨', round(summary.avg_io_ratio_pct, 2), '%'),
            ('ìµœì†Œ Method Time', round(summary.min_method_time_ms, 4), 'ms'),
            ('ìµœëŒ€ Method Time', round(summary.max_method_time_ms, 4), 'ms'),
            ('í‘œì¤€í¸ì°¨', round(summary.std_method_time_ms, 4), 'ms'),
            ('í‰ê·  Cmd1 (ë³´ì¦ê¸ˆ)', round(summary.avg_cmd1_ms, 4), 'ms'),
            ('í‰ê·  Cmd2 (ì›”ì„¸)', round(summary.avg_cmd2_ms, 4), 'ms'),
            ('í‰ê·  Cmd3 (í‰ìˆ˜)', round(summary.avg_cmd3_ms, 4), 'ms'),
            ('ì„±ê³µë¥ ', round(summary.success_rate_pct, 2), '%'),
            ('ì¡°ê¸°ì¢…ë£Œìœ¨', round(summary.early_termination_rate_pct, 2), '%'),
        ]
        
        for row in data:
            ws3.append(row)
        
        apply_data_style(ws3, 2, len(data) + 1, 3)
        auto_column_width(ws3)
    
    # ========================================
    # Sheet 4: District Analysis (ì§€ì—­êµ¬ë³„ ë¶„ì„)
    # ========================================
    ws4 = wb.create_sheet("District_Analysis")
    
    if sequential:
        district_summaries = analyze_by_district(sequential)
        
        headers = ['ì§€ì—­êµ¬', 'ê±´ìˆ˜', 'Avg_MethodTime(ms)', 'Avg_CmdLatency(ms)', 
                   'IO_Ratio(%)', 'ì„±ê³µë¥ (%)']
        ws4.append(headers)
        apply_header_style(ws4, 1, len(headers))
        
        sorted_districts = sorted(
            district_summaries.items(),
            key=lambda x: x[1].avg_method_time_ms,
            reverse=True
        )
        
        for district, s in sorted_districts:
            ws4.append([
                district,
                s.total_records,
                round(s.avg_method_time_ms, 4),
                round(s.avg_cmd_latency_ms, 4),
                round(s.avg_io_ratio_pct, 2),
                round(s.success_rate_pct, 2)
            ])
        
        apply_data_style(ws4, 2, len(sorted_districts) + 1, len(headers))
        auto_column_width(ws4)
    
    # ========================================
    # Sheet 5: Thread Analysis (ìŠ¤ë ˆë“œë³„ ë¶„ì„)
    # ========================================
    ws5 = wb.create_sheet("Thread_Analysis")
    
    if sequential:
        thread_summaries = analyze_by_thread(sequential)
        
        headers = ['ìŠ¤ë ˆë“œ', 'ê±´ìˆ˜', 'Avg_MethodTime(ms)', 'Avg_CmdLatency(ms)',
                   'IO_Ratio(%)', 'ì„±ê³µë¥ (%)']
        ws5.append(headers)
        apply_header_style(ws5, 1, len(headers))
        
        sorted_threads = sorted(
            thread_summaries.items(),
            key=lambda x: x[1].total_records,
            reverse=True
        )
        
        for thread_name, s in sorted_threads:
            ws5.append([
                thread_name,
                s.total_records,
                round(s.avg_method_time_ms, 4),
                round(s.avg_cmd_latency_ms, 4),
                round(s.avg_io_ratio_pct, 2),
                round(s.success_rate_pct, 2)
            ])
        
        apply_data_style(ws5, 2, len(sorted_threads) + 1, len(headers))
        auto_column_width(ws5)
    
    # ========================================
    # Sheet 6: Before/After Template (ë¹„êµ í…œí”Œë¦¿)
    # ========================================
    ws6 = wb.create_sheet("Before_After_Compare")
    
    if summary:
        headers = ['ì§€í‘œ', 'Before (ìˆœì°¨)', 'After (Pipeline)', 'ê°œì„ ìœ¨']
        ws6.append(headers)
        apply_header_style(ws6, 1, len(headers))
        
        template_data = [
            ('í‰ê·  Method Time (ms)', round(summary.avg_method_time_ms, 4), '', ''),
            ('í‰ê·  Cmd Latency (ms)', round(summary.avg_cmd_latency_ms, 4), '', ''),
            ('í‰ê·  I/O ë¹„ìœ¨ (%)', round(summary.avg_io_ratio_pct, 2), '', '-'),
            ('Cmd1 í‰ê·  - ë³´ì¦ê¸ˆ (ms)', round(summary.avg_cmd1_ms, 4), '-', '-'),
            ('Cmd2 í‰ê·  - ì›”ì„¸ (ms)', round(summary.avg_cmd2_ms, 4), '-', '-'),
            ('Cmd3 í‰ê·  - í‰ìˆ˜ (ms)', round(summary.avg_cmd3_ms, 4), '-', '-'),
            ('ì¸¡ì • ê±´ìˆ˜', summary.total_records, '', '-'),
            ('ì„±ê³µë¥  (%)', round(summary.success_rate_pct, 2), '', '-'),
            ('ì¡°ê¸°ì¢…ë£Œìœ¨ (%)', round(summary.early_termination_rate_pct, 2), '0.00 (ë¶ˆê°€)', '-'),
        ]
        
        for row in template_data:
            ws6.append(row)
        
        apply_data_style(ws6, 2, len(template_data) + 1, len(headers))
        
        # After, ê°œì„ ìœ¨ ì»¬ëŸ¼ ë…¸ë€ìƒ‰ ë°°ê²½ (ì…ë ¥ ëŒ€ê¸°)
        yellow_fill = PatternFill('solid', fgColor='FFFF00')
        for row in range(2, len(template_data) + 2):
            for col in [3, 4]:  # C, D ì»¬ëŸ¼
                cell = ws6.cell(row=row, column=col)
                if cell.value == '':
                    cell.fill = yellow_fill
        
        auto_column_width(ws6)
    
    # íŒŒì¼ ì €ì¥
    wb.save(filepath)
    print(f"âœ… Excel íŒŒì¼ ì €ì¥: {filepath}")
    print(f"   - Sequential_Metrics: {len(sequential)}ê±´")
    print(f"   - LoopSummary_Metrics: {len(loop_summary)}ê±´")
    print(f"   - Analysis_Summary: ë¶„ì„ ìš”ì•½")
    print(f"   - District_Analysis: ì§€ì—­êµ¬ë³„ ë¶„ì„")
    print(f"   - Thread_Analysis: ìŠ¤ë ˆë“œë³„ ë¶„ì„")
    print(f"   - Before_After_Compare: ë¹„êµ í…œí”Œë¦¿")


def export_to_json(sequential: List[SequentialMetric], 
                   loop_summary: List[LoopSummaryMetric],
                   summary: Optional[AnalysisSummary],
                   filepath: str):
    """JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    data = {
        'metadata': {
            'generated_at': datetime.now().isoformat(),
            'sequential_count': len(sequential),
            'loop_summary_count': len(loop_summary)
        },
        'analysis_summary': asdict(summary) if summary else None,
        'sequential_metrics': [asdict(m) for m in sequential],
        'loop_summary_metrics': [asdict(m) for m in loop_summary]
    }
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSON ë°ì´í„° ì €ì¥: {filepath}")


# =============================================================================
# ë©”ì¸ í•¨ìˆ˜
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='Redis Pipeline ë³‘ëª© ì¸¡ì • ë¡œê·¸ íŒŒì„œ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python parse_redis_metrics.py catalina.out
  python parse_redis_metrics.py spring.log --output csv --export results.csv
  python parse_redis_metrics.py spring.log --output xlsx --export results.xlsx
  python parse_redis_metrics.py app.log --district-analysis
  python parse_redis_metrics.py app.log --thread-analysis
  python parse_redis_metrics.py app.log --request-analysis
  python parse_redis_metrics.py app.log --limit 100 --template
        """
    )
    
    parser.add_argument('logfile', help='ë¶„ì„í•  ë¡œê·¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', choices=['table', 'csv', 'json', 'xlsx'], 
                        default='table', help='ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸: table)')
    parser.add_argument('--export', metavar='FILE', help='ê²°ê³¼ ë‚´ë³´ë‚´ê¸° íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--limit', type=int, default=50, 
                        help='í…Œì´ë¸” ì¶œë ¥ ì‹œ ìµœëŒ€ í–‰ ìˆ˜ (ê¸°ë³¸: 50)')
    parser.add_argument('--district-analysis', action='store_true',
                        help='ì§€ì—­êµ¬ë³„ ìƒì„¸ ë¶„ì„ ì¶œë ¥')
    parser.add_argument('--thread-analysis', action='store_true',
                        help='ìŠ¤ë ˆë“œë³„ ìƒì„¸ ë¶„ì„ ì¶œë ¥')
    parser.add_argument('--request-analysis', action='store_true',
                        help='ìš”ì²­(Request) ë‹¨ìœ„ ë¶„ì„ ì¶œë ¥')
    parser.add_argument('--template', action='store_true',
                        help='Before/After ë¹„êµ í…œí”Œë¦¿ ì¶œë ¥')
    parser.add_argument('--quiet', '-q', action='store_true',
                        help='ìƒì„¸ ë°ì´í„° ì¶œë ¥ ìƒëµ, ìš”ì•½ë§Œ ì¶œë ¥')
    parser.add_argument('--filter-thread', metavar='PATTERN',
                        help='íŠ¹ì • ìŠ¤ë ˆë“œë§Œ í•„í„°ë§ (ì˜ˆ: exec-1, exec-*)')
    
    args = parser.parse_args()
    
    try:
        print(f"\nğŸ” ë¡œê·¸ íŒŒì¼ ë¶„ì„ ì¤‘: {args.logfile}")
        sequential_metrics, loop_summary_metrics = parse_log_file(args.logfile)
        
        # ìŠ¤ë ˆë“œ í•„í„° ì ìš©
        if args.filter_thread:
            pattern = args.filter_thread.replace('*', '.*')
            sequential_metrics = [m for m in sequential_metrics 
                                  if m.thread_name and re.search(pattern, m.thread_name)]
            loop_summary_metrics = [m for m in loop_summary_metrics 
                                    if m.thread_name and re.search(pattern, m.thread_name)]
            print(f"   - ìŠ¤ë ˆë“œ í•„í„° ì ìš©: '{args.filter_thread}'")
        
        print(f"   - [Metrics-Sequential] ë°œê²¬: {len(sequential_metrics)}ê±´")
        print(f"   - [Metrics-LoopSummary] ë°œê²¬: {len(loop_summary_metrics)}ê±´")
        
        # ìŠ¤ë ˆë“œ ëª©ë¡ ì¶œë ¥
        threads = set(m.thread_name for m in sequential_metrics if m.thread_name)
        if threads:
            print(f"   - ê°ì§€ëœ ìŠ¤ë ˆë“œ: {len(threads)}ê°œ")
            for t in sorted(threads)[:5]:
                print(f"       â€¢ {t}")
            if len(threads) > 5:
                print(f"       ... ì™¸ {len(threads) - 5}ê°œ")
        
        if not sequential_metrics and not loop_summary_metrics:
            print("\nâš ï¸  ì¸¡ì • ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("    ë¡œê·¸ íŒŒì¼ì— [Metrics-Sequential] ë˜ëŠ” [Metrics-LoopSummary] íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            sys.exit(1)
        
        # ë¶„ì„ ìˆ˜í–‰
        summary = analyze_sequential_metrics(sequential_metrics)
        
        # xlsx ì¶œë ¥ì¸ ê²½ìš° ë°”ë¡œ íŒŒì¼ ìƒì„±
        if args.output == 'xlsx':
            if not args.export:
                # export ë¯¸ì§€ì • ì‹œ ê¸°ë³¸ íŒŒì¼ëª… ìƒì„±
                args.export = args.logfile.rsplit('.', 1)[0] + '_metrics.xlsx'
            export_to_xlsx(sequential_metrics, loop_summary_metrics, summary, args.export)
            print("\nâœ… ë¶„ì„ ì™„ë£Œ")
            return
        
        # ì¶œë ¥ í˜•ì‹ì— ë”°ë¥¸ ì²˜ë¦¬
        if args.output == 'table':
            if not args.quiet and sequential_metrics:
                print_sequential_table(sequential_metrics, args.limit)
            
            if not args.quiet and loop_summary_metrics:
                print_loop_summary_table(loop_summary_metrics)
            
            if summary:
                print_analysis_summary(summary)
            
            if args.district_analysis and sequential_metrics:
                district_summaries = analyze_by_district(sequential_metrics)
                print_district_analysis(district_summaries)
            
            if args.thread_analysis and sequential_metrics:
                thread_summaries = analyze_by_thread(sequential_metrics)
                print_thread_analysis(thread_summaries)
            
            if args.request_analysis:
                requests = group_by_request(sequential_metrics, loop_summary_metrics)
                print_request_analysis(requests)
            
            if args.template and summary:
                print_before_after_template(summary)
        
        # íŒŒì¼ ë‚´ë³´ë‚´ê¸°
        if args.export:
            if args.output == 'csv':
                export_to_csv(sequential_metrics, loop_summary_metrics, args.export)
            elif args.output == 'json':
                export_to_json(sequential_metrics, loop_summary_metrics, summary, args.export)
            else:
                # table ëª¨ë“œì—ì„œë„ export ì§€ì • ì‹œ JSONìœ¼ë¡œ ì €ì¥
                export_to_json(sequential_metrics, loop_summary_metrics, summary, args.export)
        
        print("\nâœ… ë¶„ì„ ì™„ë£Œ")
        
    except FileNotFoundError as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
