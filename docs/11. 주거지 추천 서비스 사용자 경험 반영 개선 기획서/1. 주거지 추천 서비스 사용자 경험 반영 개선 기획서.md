# 주거지 추천 서비스 사용자 경험 반영 개선 기획서

## 프로젝트 개요

**목표**: 실거주자 경험을 수집해서 추천 정확도를 높이면서, 대규모 리뷰 데이터가 쌓여도 실시간 추천 성능을 유지한다.

**핵심 질문**: "정량적 공공데이터만으로는 담을 수 없는 실제 거주 경험을, 추천 시스템에 어떻게 녹일 것인가?"

**접근 방식**: 매물별 리뷰 시스템을 만들어서 실거주자의 정성적 평가를 모으고, 키워드 추출 및 점수화로 기존 정량 데이터와 결합한다.

---

## 현재 상태 분석

### 기존의 구체적 문제점

| 구현 부분 | 현재 로직 | 문제점 | 비즈니스 영향 |
|-----------|-----------|--------|---------------|
| **데이터 기반 추천** | 서울시 공공데이터(CCTV, 범죄통계, 교통, 인구밀도)만으로 지역구 추천 | 실제 거주 경험 데이터 부재 | 사용자가 체감하는 실제 거주 환경과 추천 결과의 괴리 발생 |
| **평가 항목** | 안전성, 교통, 편의시설 점수만 산출 | 소음, 채광, 이웃 등 정성적 요소 반영 불가 | 실거주 만족도에 영향을 주는 핵심 요소들이 추천에서 누락됨 |
| **점수 산출** | 정량적 데이터만으로 점수 계산 후 사용자 우선순위 가중치 반영 | 데이터와 실제 체감의 괴리 | 추천 시스템에 대한 신뢰도 저하 및 사용자 만족도 감소 |

### 기존의 기술적 한계점

**데이터 유형의 제한**
- 정량적 공공데이터만 쓸 수 있는 구조
- 비정형 텍스트 데이터는 처리할 방법이 없음

**데이터 저장소의 구조적 한계**
- 국토부 실거래가 데이터를 Redis(In-Memory)에만 적재해서 데이터가 날아갈 위험이 있음
- 리뷰 같은 복잡한 관계형 데이터의 참조 무결성을 보장하기 어려운 구조
- 조회 성능과 데이터 안정성을 함께 잡을 메커니즘이 없음

**배치 처리 로직의 강결합**
- BatchScheduler 내에 데이터 수집 로직이 꽉 붙어있어서 확장하기 어려움
- 새로운 저장소 적재 로직을 추가하면 기존 배치 프로세스가 불안정해질 위험이 있음
- 관심사 분리 원칙을 적용하지 않은 구조

**피드백 루프 부재**
- 사용자의 실제 거주 경험이 시스템에 전혀 반영되지 않음
- 추천 결과를 검증하거나 개선할 메커니즘이 없음

**평가 차원의 단순성**
- 공공데이터로 측정할 수 있는 항목만 평가에 사용
- 실거주자가 중요하게 여기는 정성적 요소는 빠져있음

### 개선 목표

**1차 목표: 사용자 경험 데이터 수집 체계 구축**
- 매물별 리뷰 작성 기능 만들기
- 별점(1~5점) 평가 시스템 만들기
- 거주 기간 정보 모으기

**2차 목표: 리뷰 데이터 기반 추천 정확도 향상**
- 리뷰 텍스트에서 키워드 자동으로 뽑아내기
- 키워드 기반 점수 계산 로직 개발
- 기존 공공데이터 점수와 리뷰 점수 합치기

**3차 목표: 시스템 아키텍처 고도화**
- 하이브리드 데이터 저장소 전략 적용 (Redis + RDB)
- 이벤트 기반 파이프라인 만들어서 배치 로직 유연하게 만들기
- 대용량 데이터 환경에서 성능 최적화 및 동시성 제어

---

## 새로운 비즈니스 로직 설계

### 리뷰 기반 추천 점수 통합 상세 설명

**단계 1: 리뷰 데이터 수집**
매물에 대한 실거주자의 별점 평가(1~5점), 자유 형식 텍스트 리뷰, 거주 기간 정보를 모은다.

**결과 판단 기준**: 매물당 리뷰 5개 이상 쌓였는지

**성공 케이스 처리 (리뷰 5개 이상)**
리뷰 점수를 계산해서 기존 점수와 합친다. 최종 점수 = (기존 점수 × 70%) + (리뷰 점수 × 30%)

**실패 케이스 처리 (리뷰 5개 미만)**
소수 리뷰로 생기는 편향을 막기 위해 리뷰 점수는 추천에 반영하지 않고 기존 점수만 쓴다.

**단계 2: 키워드 추출 및 점수화**
리뷰 텍스트에서 교통, 소음, 채광, 편의시설 관련 키워드를 뽑아내서 긍정 키워드는 +1점, 부정 키워드는 -1점을 준다.

**결과 판단 기준**: 뽑힌 키워드가 미리 정의해둔 '평가 대상 키워드 셋(Traffic, Noise 등)'에 들어있는지 확인하고, 유효한 키워드가 1개 이상 있을 때만 점수를 매긴다.

**단계 3: 추천 점수 통합**
기존 검색 및 필터링 로직(예산, 평수, 지역 조건에 따른 1차 검색 및 2단계 폴백 검색)은 그대로 둔다. 필터링이 끝난 최종 후보 매물에만 점수 계산 방식을 바꾼다.

- AS-IS: `최종점수 = (가격점수 + 평수점수 + 안전점수)`
- TO-BE: `최종점수 = (기존 로직 결과 × 70%) + (리뷰 점수 × 30%)`

리뷰 점수 = (평균 별점 / 5) × 100 공식으로 계산한 점수를 기존 공공데이터 기반 점수와 합친다.

**결과 판단 기준**: 리뷰 5개 이상인지에 따라 리뷰 가중치 반영 여부 결정

### 핵심 비즈니스 규칙

**규칙 1: 최소 리뷰 수 기준 및 실시간 통계 갱신**
매물당 리뷰가 5개 미만이면 추천 점수에 반영하지 않고, 5개 이상일 때만 리뷰 점수를 30% 비율로 반영한다. 소수 리뷰로 생기는 편향을 막고 통계적 신뢰도를 확보하기 위해서다. 리뷰를 작성하면 평균 별점과 리뷰 개수가 실시간으로 업데이트되어야 하고, 여러 사용자가 동시에 리뷰를 남겨도 통계 데이터가 꼬이지 않아야 한다.

**규칙 2: 키워드 점수화 규칙**
긍정 키워드("조용하다", "밝다", "가깝다", "편리하다")는 +1점, 부정 키워드("시끄럽다", "어둡다", "불편하다", "멀다")는 -1점, 특정 키워드 없이 사실만 나열한 중립 리뷰는 0점이다.

**규칙 3: 리뷰 점수 산출 공식**
리뷰 점수 = (평균 별점 / 5) × 100으로 계산해서 0~100점 범위로 만든다.

**규칙 4: 최종 점수 통합 공식**
기존 추천 로직의 검증된 점수 계산 방식은 유지하면서 리뷰 점수를 제한적으로 합친다.

- AS-IS: `최종점수 = (가격점수 + 평수점수 + 안전점수)`
- TO-BE: `최종점수 = (기존 로직 결과 × 70%) + (리뷰 점수 × 30%)`

리뷰가 5개 미만이면 리뷰 가중치를 0으로 처리해서 기존 로직 점수를 100% 쓴다. 서비스 연속성을 지키기 위해서다. 리뷰 데이터가 부족한 초기 단계에도 기존 사용자 경험은 그대로 유지된다.

### 데이터 모델 설계

**Review (매물 리뷰)**
```json
{
  "reviewId": "리뷰 고유 ID",
  "propertyId": "매물 ID (외래키)",
  "userId": "작성자 ID",
  "rating": "별점 (1~5)",
  "reviewText": "텍스트 리뷰 내용",
  "residencePeriod": "거주 기간 (예: 2년)",
  "createdAt": "작성 시각",
  "keywords": {
    "traffic": "교통 관련 점수 (+1/-1/0)",
    "noise": "소음 관련 점수 (+1/-1/0)",
    "lighting": "채광 관련 점수 (+1/-1/0)",
    "convenience": "편의시설 관련 점수 (+1/-1/0)"
  }
}
```

**PropertyScore (매물별 통합 점수)**
```json
{
  "propertyId": "매물 ID",
  "baseScore": "공공데이터 기반 기존 점수",
  "reviewCount": "리뷰 개수",
  "averageRating": "평균 별점",
  "reviewScore": "리뷰 점수 ((평균 별점 / 5) × 100)",
  "finalScore": "최종 통합 점수",
  "isReviewApplied": "리뷰 점수 반영 여부 (리뷰 5개 이상 여부)"
}
```

### 시스템 아키텍처 전략

기존의 검증된 추천 로직은 그대로 두면서, 대규모 리뷰 데이터를 안정적이고 확장 가능하게 처리하기 위한 기술적 전략이다.

**하이브리드 데이터 저장소 전략 (Hybrid Persistence Strategy)**

조회 성능과 데이터 무결성, 이 두 가지 상충되는 요구사항을 함께 만족시키기 위해 Redis(Cache)와 Oracle RDB(Persistence)를 병행 운영하는 이원화 구조를 만들었다.

**Redis (Read-Optimized Layer)**
기존과 똑같이 실시간 추천 및 필터링 트래픽을 담당하면서 밀리초 단위 응답 속도를 낸다. 국토부 실거래가 데이터와 리뷰 통계 데이터(reviewCount, avgRating)를 캐싱해서 빈번한 조회 요청에 즉각 응답한다. 리뷰 통계 데이터는 비동기로 Redis에 동기화되어 조회 성능이 떨어지지 않는다.

**Oracle RDB (Write-Optimized Layer)**
데이터를 영구 저장하고, 리뷰 데이터와 매물 데이터 간의 참조 무결성을 관리한다. 리뷰 작성, 수정, 삭제 같은 트랜잭션 작업은 RDB에서 먼저 처리되어 ACID 속성을 지킨다. 데이터가 날아갈 위험을 없애고 복잡한 관계형 데이터의 정합성을 보장한다.

**이벤트 기반 데이터 파이프라인 (Event-Driven Data Pipeline)**

기존 배치 시스템(BatchScheduler)을 건드리지 않고 RDB 적재 로직을 추가하기 위해, 관심사 분리(SoC) 원칙에 따라 느슨한 결합 구조를 만들었다.

**배치 로직과 RDB 적재의 분리**
BatchScheduler는 데이터 수집과 Redis 적재를 끝내면 DataCollectionCompletedEvent를 발행하고 종료된다. RDB 적재 로직을 직접 호출하지 않아서 배치 로직의 의존성이 최소화되고, 기존 검증된 배치 프로세스는 안정적으로 유지된다.

**비동기 적재 처리**
별도의 이벤트 리스너(RdbSyncListener)가 DataCollectionCompletedEvent를 구독해서 RDB 적재(Upsert)를 비동기로 수행한다. 나중에 알림 발송이나 로그 적재 같은 후속 작업이 추가되어도 기존 배치 로직은 영향받지 않는다.

**기존 추천 로직과의 통합**

리뷰 시스템을 넣어도 기존의 복잡한 '2단계 폴백 검색'과 '필터링 로직'은 건드리지 않는다. 점수 계산 단계에서만 가중치를 적용하는 방식으로 제한적으로 합쳤다.

**검색 및 필터링 로직 유지**
사용자의 예산, 평수, 지역 조건에 따른 1차 검색과 매물 부족 시 작동하는 폴백(Fallback) 로직은 기존 Redis 인덱스를 그대로 써서 성능을 유지한다. 리뷰 시스템은 검색 및 필터링 단계에 끼어들지 않고, 필터링이 끝난 최종 후보 매물의 점수만 보정한다.

**최종 점수 산출식 고도화**
필터링이 끝난 최종 후보 매물에만 보정된 점수 계산식을 쓴다.
- AS-IS: `최종점수 = (가격점수 + 평수점수 + 안전점수)`
- TO-BE: `최종점수 = (기존 로직 결과 × 70%) + (리뷰 기반 점수 × 30%)`

**리뷰 데이터 부족 시 대응 방안**
리뷰가 없거나 부족한(5개 미만) 매물은 리뷰 가중치를 0으로 처리해서 기존 로직 점수를 100% 쓴다. 서비스 연속성을 지키기 위해서다. 리뷰 시스템을 막 도입한 초기에도 기존 사용자 경험은 그대로 유지된다.

**대용량 데이터 처리 최적화**

단순 기능만 구현하는 게 아니라, 데이터가 많이 쌓여도 안정적인 성능을 내는 것을 목표로 한다.

**배치 단위 데이터 적재 최적화**
100만 건 이상의 데이터를 RDB로 옮길 때 병목이 생기지 않도록, 개별 INSERT 쿼리 대신 배치 단위로 한 번에 적재해서 처리 시간을 줄인다. 네트워크 왕복 횟수와 트랜잭션 오버헤드가 최소화된다.

**DB 레벨 동시성 제어**
리뷰 작성처럼 빈번한 쓰기 작업이 발생할 때 데이터 오염(Lost Update)을 막기 위해, 애플리케이션 레벨이 아닌 DB 레벨에서 잠금(Lock) 메커니즘을 쓴다. 데이터 정합성을 확실하게 지킨다. 평균 별점과 리뷰 개수를 업데이트할 때 비관적 락(Pessimistic Lock) 또는 낙관적 락(Optimistic Lock)을 써서 동시성 문제를 원천 차단한다.

---

## UI/UX 연동 방식 및 정보 표시 전략

지도 기반의 직관적인 탐색 경험은 그대로 유지하면서, 리뷰 데이터 입력과 조회를 효율적으로 처리하도록 진입 경로를 이원화하고 모달 인터페이스와 독립 페이지를 적절히 섞어 썼다.

### 리뷰 작성 진입 경로 (이원화 전략)

사용자 편의성과 데이터 바인딩 정확도를 함께 잡기 위해 진입점을 두 가지로 나눴다.

| 구분 | 경로 및 동작 흐름 | 기술적 의의 및 구현 목표 |
|------|------------------|------------------------|
| **1. 지도 연동형 (Context-Aware)** | 지도 내 매물 상세 모달 → `[리뷰 작성]` 버튼 클릭 → URL 파라미터(`propertyId`)를 통해 매물 정보 자동 바인딩 | 사용자가 보고 있던 매물에 대해 즉시 리뷰를 작성할 수 있도록 문맥을 유지하며, 입력 오류를 시스템적으로 차단한다. |
| **2. 독립 탐색형 (Search-Driven)** | 리뷰 메인 페이지 → `[리뷰 작성]` 버튼 클릭 → 매물명 검색 모달 팝업 → 자동 완성(Autocomplete) 검색 후 선택 | 매물 데이터에 대한 고속 검색 인덱싱(Indexing) 및 자동 완성 API 구현 성능을 증명한다. |

### 리뷰 작성 프로세스 (Page-Based Writing)

리뷰 작성은 집중도가 필요한 작업이라서, 지도 화면의 방해 없이 쓸 수 있는 **독립 작성 페이지**를 만들었다. 기존 게시판 작성 UI 구조를 바탕으로 하되, 리뷰 데이터 특성에 맞춰 입력 필드를 최적화했다.

**상단 정보 영역 (Read-Only)**
URL 파라미터나 검색으로 선택된 매물 정보(아파트명, 평수, 층수)를 상단에 고정 표시해서 어떤 매물에 대한 리뷰인지 명확하게 보여준다.

**정량 평가 영역**
별점: 1~5점 척도로 만족도를 직관적으로 선택할 수 있다.

**정성 평가 영역 (Keyword Extraction Source)**
- 상세 리뷰: 실제 거주 경험을 자유롭게 쓸 수 있는 텍스트 에디터를 제공한다.
- 자동 분석 연동: 사용자가 작성한 텍스트 본문은 백엔드 키워드 추출 로직의 입력 데이터가 되어, '소음', '교통' 같은 핵심 키워드가 자동으로 분석되고 점수화된다. (사용자가 수동으로 태그를 선택할 필요 없음)

**저장 프로세스**
작성을 완료하면 RDB에 저장되고, 트랜잭션 안에서 `Property` 테이블의 통계 데이터(`reviewCount`, `avgRating`)를 즉시 업데이트한다.

### 리뷰 조회 시스템 (Modal Overlay)

지도 탐색 흐름을 끊지 않고 리뷰를 확인할 수 있도록, 페이지 이동 없이 모달 오버레이를 띄운다.

**진입**
지도의 매물 카드나 리스트에서 `[리뷰 보기]` 버튼을 클릭하면, 별도 페이지로 이동하지 않고 화면 위에 모달창이 즉각 뜬다. 모달 안에서는 선택한 매물의 리뷰만 보이고, 페이지네이션으로 리뷰 데이터를 효율적으로 탐색할 수 있다. 모달 내에서는 검색 같은 추가 기능은 제공하지 않는다.

**모달 구조**
- 헤더: 매물명, 평균 별점(4.5/5.0), 총 리뷰 수
- 키워드 배지: 리뷰 본문 분석으로 뽑힌 상위 대표 키워드(예: #조용함, #채광좋음)를 배지 형태로 보여줘서 매물 특징을 요약한다
- 리스트: 최신순으로 정렬된 개별 리뷰 카드 리스트
- 페이지네이션: 스크롤 압박을 줄이고 대용량 데이터 조회 성능을 보여주기 위해 **번호 기반 페이지네이션(1, 2, 3...)**을 쓴다

### 리뷰 시스템 메인 페이지 (Integrated Management)

서비스에 쌓인 모든 리뷰를 통합 조회하고 검색할 수 있는 독립 페이지다. 지도 탐색 외에 다른 방식으로도 정보에 접근할 수 있다.

**통합 목록 조회**
전체 리뷰를 최신순으로 나열하고, 게시판 형태의 페이지네이션을 제공해서 대량 데이터 처리 능력을 보여준다.

**통합 검색 기능**
제목, 내용, 또는 두 가지 조합 옵션을 선택해서 검색할 수 있다. 백엔드에서 `Property` 테이블과 `Review` 테이블 간의 조인(JOIN) 쿼리 최적화 역량을 증명하는 주요 기능이다.

---

## 기대 효과

### 서비스 개선 효과
- 실거주자 피드백을 반영해서 추천 시스템 신뢰도가 올라간다
- 정량 데이터와 정성 데이터를 통합해서 사용자가 더 나은 결정을 내릴 수 있다
- 데이터와 실제 체감의 괴리가 줄어든다
- 기존 검증된 추천 로직(2단계 폴백 검색, 필터링)은 그대로 둬서 시스템 안정성을 지킨다
- 리뷰 데이터가 부족해도 기존 로직을 100% 써서 사용자 경험이 나빠지지 않는다
- 매물별 리뷰 데이터베이스가 쌓여서 데이터 자산이 된다
- 향후 AI 분석에 쓸 수 있는 텍스트 데이터를 확보한다

### 기술적 효과

**대용량 데이터 처리 성능**
- 리뷰 데이터가 수백만 건 쌓여도 매물별 리뷰 조회는 200ms 안에 끝난다
- 배치 단위로 데이터를 적재해서 대량 이관 시 처리 시간이 짧아진다
- Redis 캐시 레이어와 RDB 영속성 레이어를 나눠서 조회 성능과 데이터 안정성을 함께 잡았다

**데이터 정합성 및 동시성 제어**
- 리뷰 작성(쓰기)과 조회(읽기) 트래픽이 동시에 몰려도 데이터 정합성이 지켜진다
- DB 레벨 Lock 메커니즘(비관적/낙관적)으로 동시성 문제를 해결한 경험을 쌓았다
- 실시간 통계를 업데이트할 때 데이터가 오염되지 않도록 트랜잭션을 관리한 경험을 쌓았다

**시스템 아키텍처 설계**
- 하이브리드 데이터 저장소 전략을 세우고 구현했다
- 이벤트 기반 파이프라인으로 느슨한 결합 구조를 설계했다
- 관심사 분리 원칙을 적용해서 확장 가능한 시스템을 만들었다

**복잡도 증가**
- N:M 관계 모델링과 비정형 데이터 처리 경험을 쌓았다
- 참조 무결성을 지키기 위해 외래키를 설계하고 관리했다

**성능 최적화**
- 읽기 성능을 개선하는 전략을 배우고 비동기 처리 경험을 쌓았다
- 대용량 데이터 인덱싱 전략을 세우고 쿼리 튜닝을 했다
- 캐시 무효화(Cache Invalidation) 전략을 세웠다

---

### 참고 자료
- 국토교통부 실거래가 공개시스템 API 가이드
- Oracle Database Performance Tuning Guide (Index & Concurrency)

### 작성자 정보
- 작성자: 정범진 (Back-end Engineer)
- 연락처: bumjin.dev@gmail.com