"""
R-03 Data Extractor - DB ì¡°íšŒ ë¡œê·¸ ì¶”ì¶œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” R-03 ë‹¨ê³„ì˜ ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ì—¬ ì¤‘ê°„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

ì²˜ë¦¬ ë‚´ìš©:
- R-02ì—ì„œ ìºì‹œ ë¯¸ìŠ¤ëœ ê²©ìì— ëŒ€í•œ DB ì¡°íšŒ
- B-Tree ì¸ë±ìŠ¤ í™œìš©í•œ WHERE geohash_id IN (...) ì¿¼ë¦¬
- ì¡°íšŒëœ ë°ì´í„°ì˜ L2 ìºì‹œ ì €ì¥

ë¶„ì„ í¬ì¸íŠ¸:
- DB ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ (queryExecutionTimeNs)
- ê²©ìë³„ ì¡°íšŒ í–‰ ìˆ˜ ë¶„í¬ (rowsPerGrid)
- ìºì‹œ ì“°ê¸° ì„±ê³µë¥  ë° ë°ì´í„° í¬ê¸°

ì…ë ¥: wherehouse.log (NDJSON í˜•ì‹)
ì¶œë ¥: r03_parsed_data.json

ì‹¤í–‰ ë°©ë²•:
    python r03_data_extractor.py

ì‘ì„±ì: ì •ë²”ì§„
ì‘ì„±ì¼: 2025-01-24
"""

import sys
import os
from pathlib import Path

# ê³µí†µ ìœ í‹¸ë¦¬í‹° import - ì ˆëŒ€ ê²½ë¡œ ë°©ì‹
# ê³µí†µ ìœ í‹¸ë¦¬í‹°ëŠ” ê°™ì€ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜
from extractor_utils import (
    parse_ndjson_log,
    clean_log_data,
    extract_result_data,
    create_metadata,
    save_to_json,
    validate_parsed_data
)


def main():
    """R-03 ë¡œê·¸ ì¶”ì¶œ ë©”ì¸ í•¨ìˆ˜"""
    
    # =========================================================================
    # ê²½ë¡œ ì„¤ì • - ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”
    # =========================================================================
    LOG_BASE_PATH = r'E:\devSpace\SpringBootProjects\wherehouse_SpringBoot-master\wherehouse\log'
    RESULT_BASE_PATH = r'E:\devSpace\results'
    
    # ì„¤ì •
    config = {
        'step': 'R-03',
        'log_file': os.path.join(LOG_BASE_PATH, 'wherehouse.log'),
        'output_dir': os.path.join(RESULT_BASE_PATH, 'r03'),
        'output_file': 'r03_parsed_data.json'
    }
    
    print("\n" + "=" * 70)
    print(f"R-03 Data Extractor ì‹œì‘")
    print("=" * 70)
    print(f"ë¡œê·¸ íŒŒì¼: {config['log_file']}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {config['output_dir']}")
    print("-" * 70)
    
    try:
        # 1. ë¡œê·¸ íŒŒì‹±
        print(f"\n[1/6] ë¡œê·¸ íŒŒì‹± ì¤‘...")
        logs = parse_ndjson_log(config['log_file'], config['step'])
        print(f"  âœ“ íŒŒì‹± ì™„ë£Œ: {len(logs)}ê°œ ë¡œê·¸")
        
        # 2. ë°ì´í„° ì •ì œ
        print(f"\n[2/6] ë°ì´í„° ì •ì œ ì¤‘...")
        logs = clean_log_data(logs)
        print(f"  âœ“ ì •ì œ ì™„ë£Œ: {len(logs)}ê°œ ë¡œê·¸")
        
        # 3. resultData ë¬´ì†ì‹¤ ë³´ì¡´
        print(f"\n[3/6] resultData ì¶”ì¶œ ì¤‘...")
        logs = extract_result_data(logs, config['step'])
        
        # END ë¡œê·¸ ê°œìˆ˜ í™•ì¸
        end_logs = [log for log in logs if log.get('status') == 'END']
        print(f"  âœ“ END ë¡œê·¸: {len(end_logs)}ê°œ")
        
        # resultData ìƒ˜í”Œ ì¶œë ¥
        if end_logs and 'resultData' in end_logs[0]:
            sample = end_logs[0]['resultData']
            
            # CCTV ì¿¼ë¦¬ ê²°ê³¼ í™•ì¸
            if 'cctvQueryResult' in sample and sample['cctvQueryResult']:
                query_result = sample['cctvQueryResult']
                print(f"  âœ“ CCTV ì¿¼ë¦¬ ëŒ€ìƒ ê²©ì: {len(query_result.get('queryGeohashIds', []))}ê°œ")
                print(f"  âœ“ CCTV ì¡°íšŒ í–‰ ìˆ˜: {query_result.get('totalRowsReturned', 0)}ê±´")
                
                query_time_ms = query_result.get('queryExecutionTimeNs', 0) / 1_000_000
                print(f"  âœ“ CCTV ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„: {query_time_ms:.3f}ms")
            
            # ìºì‹œ ì“°ê¸° ê²°ê³¼ í™•ì¸
            if 'cctvCacheWrites' in sample and sample['cctvCacheWrites']:
                cache_writes = sample['cctvCacheWrites']
                success_count = sum(1 for w in cache_writes if w.get('isSuccess', False))
                print(f"  âœ“ L2 ìºì‹œ ì“°ê¸°: {success_count}/{len(cache_writes)}ê°œ ì„±ê³µ")
        
        # 4. ë©”íƒ€ë°ì´í„° ìƒì„±
        print(f"\n[4/6] ë©”íƒ€ë°ì´í„° ìƒì„± ì¤‘...")
        metadata = create_metadata(config, logs)
        print(f"  âœ“ step: {metadata['step']}")
        print(f"  âœ“ total_logs: {metadata['total_logs']}")
        print(f"  âœ“ end_logs: {metadata['end_logs']}")
        
        # 5. ë°ì´í„° ê²€ì¦
        print(f"\n[5/6] ë°ì´í„° ê²€ì¦ ì¤‘...")
        data = {
            'metadata': metadata,
            'logs': logs
        }
        
        is_valid = validate_parsed_data(data)
        if not is_valid:
            raise ValueError("ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
        print(f"  âœ“ ê²€ì¦ í†µê³¼")
        
        # 6. JSON íŒŒì¼ ì €ì¥
        print(f"\n[6/6] JSON íŒŒì¼ ì €ì¥ ì¤‘...")
        output_path = Path(config['output_dir']) / config['output_file']
        save_to_json(data, output_path)
        
        print("\n" + "=" * 70)
        print(f"âœ… R-03 ì¶”ì¶œ ì™„ë£Œ!")
        print(f"âœ… ì¶œë ¥ íŒŒì¼: {output_path}")
        print("=" * 70)
        print("\nğŸ’¡ ë¶„ì„ í¬ì¸íŠ¸:")
        print("  - DB ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ (queryExecutionTimeNs)")
        print("  - ê²©ìë³„ ì¡°íšŒ ë°ì´í„° ë¶„í¬ (rowsPerGrid)")
        print("  - ìºì‹œ ì“°ê¸° ì„±ê³µë¥ \n")
        
    except FileNotFoundError as e:
        print("\n" + "=" * 70)
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("=" * 70)
        print("\nê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:")
        print(f"  - ë¡œê·¸ íŒŒì¼: {config['log_file']}")
        print("\nìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ì˜ ê²½ë¡œ ì„¤ì •ì„ ìˆ˜ì •í•˜ì„¸ìš”:")
        print(f"  LOG_BASE_PATH = r'...'")
        print(f"  RESULT_BASE_PATH = r'...'\n")
        sys.exit(1)
        
    except Exception as e:
        print("\n" + "=" * 70)
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("=" * 70)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()