# Report Generation Layer 설계서 v1.0

**문서 정보**
- 문서 유형: 상세 설계 문서 (Detailed Design Document)
- 작성일: 2025-01-24
- 작성자: 정범진
- 프로젝트: Wherehouse 상세지도 서비스 성능 최적화
- 상위 문서: 성능 로그 파싱 스크립트 설계 문서 v2.0
- 목적: Report Generation Layer (보고서 생성 계층) 구현 상세 명세

---

## 목차

1. [계층 개요](#1-계층-개요)
2. [Generator 아키텍처](#2-generator-아키텍처)
3. [공통 함수 라이브러리](#3-공통-함수-라이브러리)
4. [3-Sheet 생성 로직](#4-3-sheet-생성-로직)
5. [단계별 Generator 구현 가이드](#5-단계별-generator-구현-가이드)
6. [시각화 (선택사항)](#6-시각화-선택사항)
7. [성능 최적화](#7-성능-최적화)

---

## 1. 계층 개요

### 1.1. 책임 (Responsibility)

Report Generation Layer는 다음 작업을 담당한다:

1. **중간 파일 읽기**: Extractor가 생성한 JSON 파일 로드
2. **데이터 변환**: JSON → pandas DataFrame
3. **통계 계산**: 평균, 중앙값, 95th percentile, 최소, 최대, 표준편차
4. **Sheet 1 생성**: Step_Summary (거시적 병목)
5. **Sheet 2 생성**: Action_Breakdown (미시적 병목)
6. **Sheet 3 생성**: ResultData_Analysis (비즈니스 데이터) - 단계별 커스터마이징
7. **Excel 파일 저장**: 3-Sheet 구조의 .xlsx 파일 생성
8. **(선택) 시각화**: 막대 그래프, 파이 차트 등

### 1.2. 입력/출력

| 항목 | 내용 |
|------|------|
| **입력** | `results/r0X/r0X_parsed_data.json` (구조화된 JSON) |
| **출력** | `results/r0X/r0X_analysis.xlsx` (3-Sheet Excel) |
| **의존성** | Python 3.10+, pandas, openpyxl, matplotlib (선택) |

### 1.3. 실행 주기

- **초기 실행**: Extractor 실행 직후 1회 실행
- **재실행**: Excel 포맷 수정 시 여러 번 재실행 가능
- **주기**: Extractor와 독립적 (중간 파일만 있으면 실행 가능)

### 1.4. Extraction Layer와의 인터페이스

**계약 (Contract)**:
- Extractor가 생성한 **JSON 포맷을 정확히 준수**
- `metadata`와 `logs` 필드 존재 가정
- `logs` 배열의 각 요소는 필수 필드 포함

**인터페이스 검증**:
```python
def load_parsed_data(input_file: str) -> Dict:
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # 필수 필드 검증
    assert 'metadata' in data, "metadata 필드 없음"
    assert 'logs' in data, "logs 필드 없음"
    assert isinstance(data['logs'], list), "logs는 배열이어야 함"
    
    return data
```

---

## 2. Generator 아키텍처

### 2.1. 전체 처리 흐름

```
┌──────────────────────────────────────────┐
│ r0X_report_generator.py                  │
├──────────────────────────────────────────┤
│                                          │
│  1. 설정 초기화                           │
│     - 중간 파일 경로                      │
│     - 출력 파일 경로                      │
│     - step 정보                          │
│                                          │
│  2. 중간 파일 읽기                        │
│     load_parsed_data()                   │
│     ├─ JSON 파일 열기                    │
│     ├─ 필수 필드 검증                    │
│     └─ DataFrame 변환                    │
│                                          │
│  3. Sheet 1 생성: Step_Summary           │
│     create_step_summary()                │
│     ├─ END 로그 필터링                   │
│     ├─ 메인 루틴만 필터링                │
│     ├─ 통계 계산 (평균, 중앙, 95th)      │
│     └─ Excel Sheet 쓰기                  │
│                                          │
│  4. Sheet 2 생성: Action_Breakdown       │
│     create_action_breakdown()            │
│     ├─ END 로그 필터링                   │
│     ├─ 모든 Action 포함                  │
│     ├─ 통계 계산                         │
│     └─ Excel Sheet 쓰기                  │
│                                          │
│  5. Sheet 3 생성: ResultData_Analysis    │
│     create_resultdata_sheet()            │
│     ├─ END 로그 필터링                   │
│     ├─ resultData 필드 추출              │
│     ├─ 단계별 커스텀 지표 계산           │
│     └─ Excel Sheet 쓰기                  │
│                                          │
│  6. (선택) 시각화 차트 생성               │
│     generate_charts()                    │
│     ├─ 막대 그래프 (Step별 duration)     │
│     ├─ 파이 차트 (Action 비율)           │
│     └─ PNG 파일 저장                     │
│                                          │
└──────────────────────────────────────────┘
```

### 2.2. 모듈 구조

```python
# r01_report_generator.py

import json
import sys
from pathlib import Path
import pandas as pd
sys.path.append(str(Path(__file__).parent.parent / 'common'))

from generator_utils import (
    load_parsed_data,
    create_step_summary_sheet,
    create_action_breakdown_sheet,
    create_resultdata_sheet_base
)

def create_r01_resultdata_sheet(df: pd.DataFrame, writer):
    """
    R-01 전용 ResultData_Analysis 시트 생성
    """
    # R-01 특화 로직 (단계별로 다름)
    metrics_config = {
        'totalGridCount': {
            'path': 'totalGridCount',
            'description': '9-Block 그리드 개수 (항상 9)'
        },
        'success_rate': {
            'path': 'isSuccess',
            'description': '성공률 (%)',
            'transform': lambda x: 100.0 if x else 0.0
        }
    }
    
    create_resultdata_sheet_base(df, writer, metrics_config, 'ResultData_Analysis')

def main():
    # 1. 설정
    config = {
        'step': 'R-01',
        'input_file': 'results/r01/r01_parsed_data.json',
        'output_file': 'results/r01/r01_analysis.xlsx'
    }
    
    # 2. 중간 파일 로드
    print(f"[{config['step']}] 중간 파일 로드 중...")
    data = load_parsed_data(config['input_file'])
    df = pd.DataFrame(data['logs'])
    print(f"[{config['step']}] 로드 완료: {len(df)}개 로그")
    
    # 3-5. Excel 생성
    print(f"[{config['step']}] Excel 보고서 생성 중...")
    with pd.ExcelWriter(config['output_file'], engine='openpyxl') as writer:
        create_step_summary_sheet(df, writer, 'Step_Summary')
        create_action_breakdown_sheet(df, writer, 'Action_Breakdown')
        create_r01_resultdata_sheet(df, writer)
    
    print(f"[{config['step']}] 보고서 생성 완료: {config['output_file']}")

if __name__ == '__main__':
    main()
```

---

## 3. 공통 함수 라이브러리

### 3.1. generator_utils.py 구조

```python
# common/generator_utils.py

import json
import pandas as pd
from pathlib import Path
from typing import Dict, Any, Callable

def load_parsed_data(input_file: str) -> Dict:
    """
    Extractor가 생성한 JSON 파일 로드
    
    Args:
        input_file: 중간 파일 경로
    
    Returns:
        Dict: {'metadata': {...}, 'logs': [...]}
    
    Raises:
        FileNotFoundError: 파일이 없는 경우
        ValueError: JSON 포맷이 잘못된 경우
    """
    if not Path(input_file).exists():
        raise FileNotFoundError(f"중간 파일을 찾을 수 없습니다: {input_file}")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # 필수 필드 검증
    if 'metadata' not in data:
        raise ValueError("metadata 필드가 없습니다")
    if 'logs' not in data:
        raise ValueError("logs 필드가 없습니다")
    if not isinstance(data['logs'], list):
        raise ValueError("logs는 배열이어야 합니다")
    
    return data


def create_step_summary_sheet(df: pd.DataFrame, writer, sheet_name='Step_Summary'):
    """
    Sheet 1: Step_Summary 생성 (메인 루틴만)
    
    Args:
        df: 로그 DataFrame
        writer: pd.ExcelWriter 객체
        sheet_name: 시트 이름
    
    Note:
        메인 루틴 = layer가 'Service'인 로그
    """
    # END 로그 + Service 레이어만 필터링
    df_main = df[(df['status'] == 'END') & (df['layer'] == 'Service')].copy()
    
    if len(df_main) == 0:
        print(f"Warning: {sheet_name} - 메인 루틴 로그가 없습니다")
        return
    
    # 통계 계산
    summary = df_main.groupby(['step', 'action', 'layer', 'class', 'method']).agg(
        avg_ms=('duration_ms', 'mean'),
        median_ms=('duration_ms', 'median'),
        p95_ms=('duration_ms', lambda x: x.quantile(0.95)),
        min_ms=('duration_ms', 'min'),
        max_ms=('duration_ms', 'max'),
        std_ms=('duration_ms', 'std'),
        count=('duration_ms', 'count')
    ).round(3).reset_index()
    
    # Excel 쓰기
    summary.to_excel(writer, sheet_name=sheet_name, index=False)


def create_action_breakdown_sheet(df: pd.DataFrame, writer, sheet_name='Action_Breakdown'):
    """
    Sheet 2: Action_Breakdown 생성 (모든 Action)
    
    Args:
        df: 로그 DataFrame
        writer: pd.ExcelWriter 객체
        sheet_name: 시트 이름
    """
    # END 로그만 필터링
    df_end = df[df['status'] == 'END'].copy()
    
    if len(df_end) == 0:
        print(f"Warning: {sheet_name} - END 로그가 없습니다")
        return
    
    # 통계 계산
    breakdown = df_end.groupby(['step', 'layer', 'class', 'method', 'action']).agg(
        avg_ms=('duration_ms', 'mean'),
        median_ms=('duration_ms', 'median'),
        p95_ms=('duration_ms', lambda x: x.quantile(0.95)),
        min_ms=('duration_ms', 'min'),
        max_ms=('duration_ms', 'max'),
        std_ms=('duration_ms', 'std'),
        count=('duration_ms', 'count')
    ).round(3).reset_index()
    
    # Excel 쓰기
    breakdown.to_excel(writer, sheet_name=sheet_name, index=False)


def create_resultdata_sheet_base(df: pd.DataFrame, 
                                  writer, 
                                  metrics_config: Dict[str, Dict], 
                                  sheet_name='ResultData_Analysis'):
    """
    Sheet 3: ResultData_Analysis 생성 (단계별 커스터마이징 가능)
    
    Args:
        df: 로그 DataFrame
        writer: pd.ExcelWriter 객체
        metrics_config: 추출할 지표 설정
        sheet_name: 시트 이름
    
    metrics_config 예시:
    {
        'totalGridCount': {
            'path': 'totalGridCount',
            'description': '9-Block 개수',
            'transform': None  # 또는 lambda x: ...
        }
    }
    """
    # END 로그만 필터링
    df_end = df[df['status'] == 'END'].copy()
    
    if len(df_end) == 0:
        print(f"Warning: {sheet_name} - END 로그가 없습니다")
        return
    
    # resultData 필드가 있는지 확인
    if 'resultData' not in df_end.columns:
        print(f"Warning: {sheet_name} - resultData 필드가 없습니다")
        return
    
    # 지표 추출
    metrics = []
    for metric_name, config in metrics_config.items():
        path = config['path']
        description = config.get('description', '')
        transform = config.get('transform', None)
        
        # resultData에서 필드 추출 (중첩 지원: 'a.b.c')
        values = df_end['resultData'].apply(
            lambda x: extract_nested_field(x, path) if isinstance(x, dict) else None
        ).dropna()
        
        if len(values) == 0:
            continue
        
        # 변환 함수 적용
        if transform:
            values = values.apply(transform)
        
        # 숫자 타입인 경우에만 통계 계산
        if pd.api.types.is_numeric_dtype(values):
            metrics.append({
                'metric_name': metric_name,
                'avg': values.mean(),
                'median': values.median(),
                'p95': values.quantile(0.95),
                'min': values.min(),
                'max': values.max(),
                'description': description
            })
        else:
            # 비숫자 타입 (예: success_rate = 100%)
            metrics.append({
                'metric_name': metric_name,
                'avg': values.iloc[0] if len(values) > 0 else None,
                'median': None,
                'p95': None,
                'min': None,
                'max': None,
                'description': description
            })
    
    if len(metrics) == 0:
        print(f"Warning: {sheet_name} - 추출된 지표가 없습니다")
        return
    
    metrics_df = pd.DataFrame(metrics).round(3)
    metrics_df.to_excel(writer, sheet_name=sheet_name, index=False)


def extract_nested_field(data: Dict, path: str) -> Any:
    """
    중첩된 딕셔너리에서 필드 추출
    
    Args:
        data: 딕셔너리
        path: 필드 경로 (점으로 구분, 예: 'a.b.c')
    
    Returns:
        추출된 값 또는 None
    
    Example:
        data = {'a': {'b': {'c': 123}}}
        extract_nested_field(data, 'a.b.c')  # → 123
    """
    keys = path.split('.')
    value = data
    
    for key in keys:
        if isinstance(value, dict) and key in value:
            value = value[key]
        else:
            return None
    
    return value
```

### 3.2. 함수별 책임

| 함수명 | 입력 | 출력 | 책임 |
|--------|------|------|------|
| `load_parsed_data()` | 파일 경로 | Dict | JSON 로드 + 검증 |
| `create_step_summary_sheet()` | DataFrame, writer | None | Sheet 1 생성 |
| `create_action_breakdown_sheet()` | DataFrame, writer | None | Sheet 2 생성 |
| `create_resultdata_sheet_base()` | DataFrame, writer, config | None | Sheet 3 생성 (베이스) |
| `extract_nested_field()` | Dict, path | Any | 중첩 필드 추출 |

---

## 4. 3-Sheet 생성 로직

### 4.1. Sheet 1: Step_Summary

**필터링**:
```python
df_main = df[(df['status'] == 'END') & (df['layer'] == 'Service')]
```

**그룹핑**:
```python
.groupby(['step', 'action', 'layer', 'class', 'method'])
```

**집계**:
```python
.agg(
    avg_ms=('duration_ms', 'mean'),
    median_ms=('duration_ms', 'median'),
    p95_ms=('duration_ms', lambda x: x.quantile(0.95)),
    min_ms=('duration_ms', 'min'),
    max_ms=('duration_ms', 'max'),
    std_ms=('duration_ms', 'std'),
    count=('duration_ms', 'count')
)
```

**결과 예시**:

| step | action | layer | class | method | avg_ms | median_ms | p95_ms | min_ms | max_ms | std_ms | count |
|------|--------|-------|-------|--------|--------|-----------|--------|--------|--------|--------|-------|
| R-01 | calculate9BlockGrid | Service | LocationAnalysisServiceImpl | calculate9BlockGrid | 3.245 | 3.100 | 4.500 | 2.800 | 5.100 | 0.523 | 50 |

### 4.2. Sheet 2: Action_Breakdown

**필터링**:
```python
df_end = df[df['status'] == 'END']  # 모든 END 로그
```

**그룹핑**:
```python
.groupby(['step', 'layer', 'class', 'method', 'action'])
```

**집계**: Sheet 1과 동일

**결과 예시** (R-01):

| step | layer | class | method | action | avg_ms | median_ms | p95_ms | count |
|------|-------|-------|--------|--------|--------|-----------|--------|-------|
| R-01 | Service | LocationAnalysisServiceImpl | calculate9BlockGrid | calculate9BlockGrid | 3.245 | 3.100 | 4.500 | 50 |
| R-01 | Utility | GeohashService | calculate9BlockGeohashes | calculate9BlockGeohashes | 3.001 | 2.900 | 4.300 | 50 |

### 4.3. Sheet 3: ResultData_Analysis

**단계별 커스터마이징 필수**

**R-01 예시**:
```python
metrics_config = {
    'totalGridCount': {
        'path': 'totalGridCount',
        'description': '9-Block 그리드 개수 (항상 9)'
    },
    'success_rate': {
        'path': 'isSuccess',
        'description': '성공률 (%)',
        'transform': lambda x: 100.0 if x else 0.0
    }
}
```

**R-02 예시** (중첩 필드 추출):
```python
metrics_config = {
    'l1_hit_rate': {
        'path': 'l1CacheHit',
        'description': 'L1 캐시 히트율 (%)',
        'transform': lambda x: 100.0 if x else 0.0
    },
    'l2_cache_total_duration_ms': {
        'path': 'l2CacheTotalDurationNs',
        'description': 'B-03 병목 핵심 지표',
        'transform': lambda x: x / 1_000_000  # ns → ms
    },
    'police_query_duration_ms': {
        'path': 'policeQuery.queryDurationNs',  # 중첩 필드
        'description': 'B-01 병목 (파출소 쿼리)',
        'transform': lambda x: x / 1_000_000
    }
}
```

---

## 5. 단계별 Generator 구현 가이드

### 5.1. R-01 ~ R-07 공통 템플릿

```python
# r0X_report_generator.py

import json
import sys
from pathlib import Path
import pandas as pd
sys.path.append(str(Path(__file__).parent.parent / 'common'))

from generator_utils import (
    load_parsed_data,
    create_step_summary_sheet,
    create_action_breakdown_sheet,
    create_resultdata_sheet_base
)

def create_r0X_resultdata_sheet(df: pd.DataFrame, writer):
    """
    R-0X 전용 ResultData_Analysis 시트 생성
    """
    metrics_config = {
        # ← 단계별로 여기만 변경
    }
    
    create_resultdata_sheet_base(df, writer, metrics_config, 'ResultData_Analysis')

def main():
    config = {
        'step': 'R-0X',  # ← 변경
        'input_file': 'results/r0X/r0X_parsed_data.json',  # ← 변경
        'output_file': 'results/r0X/r0X_analysis.xlsx'  # ← 변경
    }
    
    print(f"[{config['step']}] 중간 파일 로드 중...")
    data = load_parsed_data(config['input_file'])
    df = pd.DataFrame(data['logs'])
    print(f"[{config['step']}] 로드 완료: {len(df)}개 로그")
    
    print(f"[{config['step']}] Excel 보고서 생성 중...")
    with pd.ExcelWriter(config['output_file'], engine='openpyxl') as writer:
        create_step_summary_sheet(df, writer, 'Step_Summary')
        create_action_breakdown_sheet(df, writer, 'Action_Breakdown')
        create_r0X_resultdata_sheet(df, writer)
    
    print(f"[{config['step']}] 보고서 생성 완료: {config['output_file']}")

if __name__ == '__main__':
    main()
```

### 5.2. 단계별 차이점: metrics_config만 변경

**R-01**:
```python
metrics_config = {
    'totalGridCount': {
        'path': 'totalGridCount',
        'description': '9-Block 그리드 개수'
    },
    'success_rate': {
        'path': 'isSuccess',
        'description': '성공률 (%)',
        'transform': lambda x: 100.0 if x else 0.0
    }
}
```

**R-02**:
```python
metrics_config = {
    'l1_hit_rate': {
        'path': 'l1CacheHit',
        'description': 'L1 캐시 히트율 (%)',
        'transform': lambda x: 100.0 if x else 0.0
    },
    'l2_cache_total_duration_ms': {
        'path': 'l2CacheTotalDurationNs',
        'description': 'B-03 병목 핵심 지표',
        'transform': lambda x: x / 1_000_000
    }
}
```

**R-05**:
```python
metrics_config = {
    'police_query_duration_ms': {
        'path': 'policeQuery.queryDurationNs',  # 중첩
        'description': 'B-01 병목 (파출소 쿼리)',
        'transform': lambda x: x / 1_000_000
    },
    'cctv_filter_rate': {
        'path': 'cctvFilter.filterRate',
        'description': 'CCTV 필터율 (%)',
        'transform': lambda x: x * 100
    }
}
```

---

## 6. 시각화 (선택사항)

### 6.1. 막대 그래프: Step별 평균 시간

```python
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

def generate_step_duration_chart(df: pd.DataFrame, output_path: str):
    """
    Step별 평균 duration 막대 그래프 생성
    """
    # 한글 폰트 설정 (Windows)
    plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False
    
    # 데이터 준비
    df_end = df[df['status'] == 'END']
    step_avg = df_end.groupby('step')['duration_ms'].mean().sort_index()
    
    # 그래프 생성
    fig, ax = plt.subplots(figsize=(10, 6))
    step_avg.plot(kind='bar', ax=ax, color='steelblue')
    
    ax.set_xlabel('Step', fontsize=12)
    ax.set_ylabel('평균 실행 시간 (ms)', fontsize=12)
    ax.set_title('Step별 평균 실행 시간', fontsize=14, fontweight='bold')
    ax.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300)
    plt.close()
```

### 6.2. 파이 차트: Action 비율

```python
def generate_action_ratio_chart(df: pd.DataFrame, output_path: str):
    """
    Action별 실행 시간 비율 파이 차트
    """
    df_end = df[df['status'] == 'END']
    action_sum = df_end.groupby('action')['duration_ms'].sum()
    
    fig, ax = plt.subplots(figsize=(10, 8))
    action_sum.plot(kind='pie', ax=ax, autopct='%1.1f%%', startangle=90)
    
    ax.set_ylabel('')
    ax.set_title('Action별 실행 시간 비율', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300)
    plt.close()
```

---

## 7. 성능 최적화

### 7.1. pandas 연산 최적화

**현재 성능** (예상):
- 로그 1,000개: ~0.2초
- 로그 10,000개: ~2초
- 로그 100,000개: ~20초

**병목**: `groupby().agg()` 연산

**최적화 불필요 이유**:
- Generator는 중간 파일만 읽으므로 I/O 병목 없음
- Excel 생성은 수 초 이내 완료
- 재실행 빈도가 높으므로 현재 성능으로 충분

### 7.2. 메모리 효율과 데이터 무손실 원칙

**중요 원칙**: Extractor는 resultData를 **절대 손실 없이 전체 보존**해야 함

**이유**:
- 중간 파일은 **원본 데이터의 완전한 복사본** 역할
- Generator에서 Sheet 3에 넣을 지표를 선택하되, 원본은 항상 유지
- 나중에 다른 분석이 필요하면 중간 파일에서 재추출 가능

**예시: R-04 (편의시설 수백 개)**

Extractor는 amenityResults 배열 전체를 저장:
```json
{
  "resultData": {
    "amenityResults": [
      {"name": "GS25 역삼점", "category": "편의점", "distance": 50},
      {"name": "세븐일레븐 강남점", "category": "편의점", "distance": 120},
      // ... 수백 개 전체
    ],
    "amenityExecutionTimeNs": 300000000
  }
}
```

Generator는 Sheet 3에 요약 지표만 표시:
```python
metrics_config = {
    'amenity_total_count': {
        'path': 'amenityResults',
        'description': '전체 편의시설 개수',
        'transform': lambda x: len(x) if isinstance(x, list) else 0
    },
    'amenity_execution_time_ms': {
        'path': 'amenityExecutionTimeNs',
        'description': '편의시설 API 실행 시간',
        'transform': lambda x: x / 1_000_000
    }
}
```

**필요 시 원본 데이터 접근**:
```python
# 중간 파일에서 전체 amenityResults 재추출
with open('results/r04/r04_parsed_data.json') as f:
    data = json.load(f)

for log in data['logs']:
    amenities = log['resultData']['amenityResults']  # 전체 데이터
    # 개별 분석 수행
```

**메모리 최적화는 Generator에서만**:
- pandas DataFrame에 전체 resultData를 로드하되
- Sheet 3에는 집계된 지표만 쓰기
- 개별 amenity 데이터는 Sheet에 넣지 않음 (필요 시 별도 분석 스크립트 작성)

---

## 8. 검증 방법

### 8.1. Excel 파일 검증

```bash
# 1. 파일 생성 확인
ls -lh results/r01/r01_analysis.xlsx

# 2. 시트 개수 확인 (3개여야 함)
python -c "import openpyxl; wb = openpyxl.load_workbook('results/r01/r01_analysis.xlsx'); print(wb.sheetnames)"

# 3. Sheet 1 행 개수 확인
python -c "import pandas as pd; df = pd.read_excel('results/r01/r01_analysis.xlsx', sheet_name='Step_Summary'); print(len(df))"
```

### 8.2. 데이터 일관성 검증

```python
# tests/test_generator.py

import pandas as pd

def test_step_summary_consistency():
    """Sheet 1의 count가 실제 로그 개수와 일치하는지 확인"""
    df_raw = pd.read_json('results/r01/r01_parsed_data.json')
    df_summary = pd.read_excel('results/r01/r01_analysis.xlsx', sheet_name='Step_Summary')
    
    # 실제 END 로그 개수
    actual_count = len(df_raw['logs'])
    
    # Sheet 1의 count 합계
    summary_count = df_summary['count'].sum()
    
    assert actual_count == summary_count, f"로그 개수 불일치: {actual_count} vs {summary_count}"
```

---

## 9. 변경 이력

| 버전 | 날짜 | 작성자 | 변경 내역 |
|------|------|--------|----------|
| 1.0 | 2025-01-24 | 정범진 | 초안 작성 - Report Generation Layer 상세 설계 |

---

**문서 종료**
