# 성능 로그 파싱 스크립트 설계 문서 v2.0

**문서 정보**
- 문서 유형: 기술 설계 문서 (Technical Design Document)
- 작성일: 2025-01-24
- 최종 수정일: 2025-01-24
- 작성자: 정범진
- 프로젝트: Wherehouse 상세지도 서비스 성능 최적화
- 목적: R-01 ~ R-07 단계별 Python 로그 파싱 스크립트 표준 구조 정의

---

## 목차

1. [문서 개요](#1-문서-개요)
2. [v2.0 주요 변경사항](#2-v20-주요-변경사항)
3. [2-Step 아키텍처 개요](#3-2-step-아키텍처-개요)
4. [표준 3-Sheet 구조](#4-표준-3-sheet-구조)
5. [단계별 적용 명세](#5-단계별-적용-명세)
6. [파일 명명 규칙](#6-파일-명명-규칙)
7. [산출물 목록](#7-산출물-목록)
8. [연관 문서](#8-연관-문서)

---

## 1. 문서 개요

### 1.1. 배경

Wherehouse 상세지도 서비스의 `POST /api/location-analysis` API는 R-01부터 R-07까지 7개의 처리 단계로 구성되어 있다. 각 단계는 PerformanceLogger를 통해 JSON 형식의 구조화된 로그를 출력하며, 각 로그는 다음을 포함한다:

- **기본 정보**: timestamp, traceId, step, action, layer, class, method
- **성능 지표**: duration_ns, duration_ms
- **비즈니스 데이터**: resultData (각 단계별 Result DTO)

본 문서는 이러한 로그를 파싱하여 성능 병목을 식별하고 개선 효과를 측정하기 위한 Python 스크립트의 표준 설계 구조를 정의한다.

### 1.2. 목표

- **관심사 분리**: 데이터 추출 계층과 보고서 생성 계층을 명확히 분리
- **재실행 효율성**: Excel 포맷 변경 시 로그 파싱 없이 보고서만 재생성
- **디버깅 용이성**: 각 계층을 독립적으로 테스트 및 검증 가능
- **일관성**: 모든 R-01 ~ R-07 단계에 동일한 2-Step 구조 적용
- **재사용성**: 파싱된 중간 데이터를 다른 분석에 활용 가능

### 1.3. 적용 범위

본 문서는 다음 7개 단계에 대한 개별 파싱 스크립트 작성에 적용된다:

| 단계 | Extractor | Generator | 주요 측정 대상 | 예상 병목 |
|------|-----------|-----------|--------------|-----------|
| R-01 | `r01_data_extractor.py` | `r01_report_generator.py` | Geohash 9-Block 계산 | 없음 (~3ms) |
| R-02 | `r02_data_extractor.py` | `r02_report_generator.py` | L1/L2 캐시 조회 | **B-03: L2 N+1 조회** |
| R-03 | `r03_data_extractor.py` | `r03_report_generator.py` | DB 쿼리 실행 | DB 인덱스 효율 |
| R-04 | `r04_data_extractor.py` | `r04_report_generator.py` | 외부 API 호출 | 편의시설 API (~300ms) |
| R-05 | `r05_data_extractor.py` | `r05_report_generator.py` | 데이터 필터링, 파출소 조회 | **B-01: 파출소 Native Query** |
| R-06 | `r06_data_extractor.py` | `r06_report_generator.py` | 점수 계산 | 없음 (CPU 연산) |
| R-07 | `r07_data_extractor.py` | `r07_report_generator.py` | 응답 생성 및 L1 캐싱 | 없음 |

---

## 2. v2.0 주요 변경사항

### 2.1. v1.0 → v2.0 변경 이력

| 항목 | v1.0 | v2.0 |
|------|------|------|
| **아키텍처** | 1-Step (단일 스크립트) | **2-Step (Extractor + Generator)** |
| **스크립트 개수** | 단계당 1개 (총 7개) | 단계당 2개 (총 14개) |
| **중간 파일** | 없음 | **JSON 파일로 파싱 결과 저장** |
| **재실행 효율** | Excel 수정 시에도 로그 재파싱 | **중간 파일 재사용 가능** |
| **디버깅** | 파싱/생성 오류 구분 어려움 | **계층별 독립 검증 가능** |
| **데이터 재사용** | 불가능 | **다른 분석 스크립트에서 활용** |

### 2.2. 변경 이유

**기존 설계의 문제점**:
```python
# v1.0: r01_performance_analyzer.py (단일 스크립트)
def main():
    df = parse_log(log_file)           # 로그 파싱
    create_sheet1(df, writer)          # Excel Sheet 1
    create_sheet2(df, writer)          # Excel Sheet 2
    create_sheet3(df, writer)          # Excel Sheet 3
```

- Excel 포맷만 수정해도 **로그 파싱부터 재실행** (비효율)
- 파싱 오류와 Excel 생성 오류 **구분 불가** (디버깅 어려움)
- 파싱된 데이터를 **다른 분석에 재사용 불가**

**개선된 설계**:
```python
# v2.0: Step 1 - r01_data_extractor.py
def main():
    df = parse_log(log_file)           # 로그 파싱
    save_to_json(df, output_file)      # 중간 파일 저장

# v2.0: Step 2 - r01_report_generator.py
def main():
    df = load_from_json(input_file)    # 중간 파일 로드
    create_sheet1(df, writer)          # Excel Sheet 1
    create_sheet2(df, writer)          # Excel Sheet 2
    create_sheet3(df, writer)          # Excel Sheet 3
```

- Excel 수정 시 **Extractor 스킵 가능** (효율적)
- 각 계층을 **독립적으로 테스트** (디버깅 용이)
- 중간 파일을 **다른 스크립트에서 재사용** (확장성)

---

## 3. 2-Step 아키텍처 개요

### 3.1. 전체 처리 흐름

```
┌─────────────────┐
│ wherehouse.log  │  (원본 로그 파일)
└────────┬────────┘
         │
         ▼
┌──────────────────────────────────┐
│  Step 1: Data Extraction Layer   │  (데이터 추출 계층)
│  r0X_data_extractor.py            │
├──────────────────────────────────┤
│ 1. NDJSON 로그 파싱               │
│ 2. step 필터링                    │
│ 3. resultData 필드 추출           │
│ 4. 중간 JSON 파일 저장            │
└────────┬─────────────────────────┘
         │
         ▼
┌─────────────────┐
│ r0X_parsed_     │  (중간 데이터 파일)
│ data.json       │
└────────┬────────┘
         │
         ▼
┌──────────────────────────────────┐
│ Step 2: Report Generation Layer  │  (보고서 생성 계층)
│ r0X_report_generator.py           │
├──────────────────────────────────┤
│ 1. 중간 JSON 파일 로드            │
│ 2. 통계 계산                      │
│ 3. 3-Sheet Excel 생성             │
│ 4. (선택) 시각화 차트 생성        │
└────────┬─────────────────────────┘
         │
         ▼
┌─────────────────┐
│ r0X_analysis.   │  (최종 보고서)
│ xlsx            │
└─────────────────┘
```

### 3.2. 계층별 책임

| 계층 | 책임 | 입력 | 출력 |
|------|------|------|------|
| **Extraction Layer** | 로그 파싱, 데이터 정제 | `wherehouse.log` | `r0X_parsed_data.json` |
| **Generation Layer** | 통계 계산, 보고서 생성 | `r0X_parsed_data.json` | `r0X_analysis.xlsx` |

### 3.3. 중간 파일 포맷 (JSON)

**선택 이유**:
- **가독성**: 사람이 직접 읽고 검증 가능 (디버깅 용이)
- **범용성**: Python 외 다른 언어/도구에서도 사용 가능
- **Git 추적**: diff로 변경사항 확인 가능
- **적절한 크기**: 로그 1,000개 기준 ~5MB (허용 범위)

**포맷 구조**:
```json
{
  "metadata": {
    "step": "R-01",
    "log_file": "wherehouse.log",
    "extraction_time": "2025-01-24T10:30:00Z",
    "total_logs": 150,
    "end_logs": 75,
    "extractor_version": "1.0"
  },
  "logs": [
    {
      "timestamp": "2025-10-23T07:36:55.257Z",
      "traceId": "27ec5af0",
      "step": "R-01",
      "action": "calculate9BlockGrid",
      "layer": "Service",
      "class": "LocationAnalysisServiceImpl",
      "method": "calculate9BlockGrid",
      "status": "END",
      "duration_ns": 3245000,
      "duration_ms": 3.245,
      "resultData": {
        "requestLatitude": 37.5663,
        "requestLongitude": 126.9779,
        "centerGeohashId": "wydm9qw",
        "nineBlockGeohashes": ["wydm9qw", "..."],
        "totalGridCount": 9,
        "isSuccess": true,
        "errorMessage": null
      }
    }
  ]
}
```

### 3.4. 실행 시나리오

**시나리오 1: 전체 분석 (초기 실행)**
```bash
# Step 1: 로그 파싱 (1회만 실행)
python r01_data_extractor.py

# Step 2: 보고서 생성
python r01_report_generator.py
```

**시나리오 2: Excel 포맷만 수정**
```bash
# Step 1 스킵 (중간 파일 재사용)
# Step 2만 재실행
python r01_report_generator.py
```

**시나리오 3: 커스텀 분석**
```python
# 파싱된 데이터를 활용한 별도 분석
import json

with open('results/r01/r01_parsed_data.json') as f:
    data = json.load(f)
    
# 예: traceId별 시간 추적
for log in data['logs']:
    print(f"{log['traceId']}: {log['duration_ms']}ms")
```

**시나리오 4: 병렬 처리**
```bash
# 모든 단계 데이터 동시 추출
python r01_data_extractor.py &
python r02_data_extractor.py &
python r03_data_extractor.py &
wait

# 이후 순차적으로 보고서 생성
for i in {1..7}; do
    python r0${i}_report_generator.py
done
```

---

## 4. 표준 3-Sheet 구조

### 4.1. Sheet 구성 (v1.0과 동일)

모든 단계(R-01 ~ R-07)는 **동일한 3개 Sheet 구조**를 갖는다:

```
r0X_analysis.xlsx
├─ [Sheet 1] Step_Summary           # 거시적: Step 전체 duration 통계
├─ [Sheet 2] Action_Breakdown       # 미시적: Step 내부 Action별 duration 통계
└─ [Sheet 3] ResultData_Analysis    # 비즈니스: resultData 필드 추출 지표
```

**핵심 철학**:
- **Sheet 1 = "어디가 느린가?"** (Step 단위 병목 식별)
- **Sheet 2 = "왜 느린가?"** (Action 단위 원인 규명)
- **Sheet 3 = "무엇이 영향을 주는가?"** (비즈니스 데이터 분석)

*상세한 Sheet 구조는 v1.0 문서와 동일하므로 생략*

---

## 5. 단계별 적용 명세

### 5.1. 단계별 핵심 측정 지표 (v1.0과 동일)

| 단계 | Sheet 3 핵심 지표 | 병목 여부 |
|------|------------------|-----------|
| **R-01** | `totalGridCount`, `success_rate` | 없음 |
| **R-02** | **`l2_cache_total_duration_ns`** (B-03 병목) | **병목** |
| **R-03** | `cctv_query_duration_ns`, `cctv_total_rows` | 조건부 |
| **R-04** | `amenity_execution_time_ns` (가장 느림) | 보통 |
| **R-05** | **`police_query_duration_ns`** (B-01 병목) | **병목** |
| **R-06** | `safety_score`, `convenience_score` | 없음 |
| **R-07** | `response_size_bytes`, `cache_write_success` | 없음 |

*상세 내용은 v1.0 문서 참조*

---

## 6. 파일 명명 규칙

### 6.1. 스크립트 파일

| 계층 | 파일명 규칙 | 예시 |
|------|-----------|------|
| **Extraction** | `r0X_data_extractor.py` | `r01_data_extractor.py` |
| **Generation** | `r0X_report_generator.py` | `r01_report_generator.py` |

### 6.2. 데이터 파일

| 파일 타입 | 파일명 규칙 | 예시 |
|----------|-----------|------|
| **중간 데이터** | `r0X_parsed_data.json` | `r01_parsed_data.json` |
| **최종 보고서** | `r0X_analysis.xlsx` | `r01_analysis.xlsx` |

### 6.3. 디렉토리 구조

```
project_root/
├── logs/
│   └── wherehouse.log                      # 원본 로그 파일
│
├── scripts/
│   ├── common/
│   │   ├── extractor_utils.py              # Extractor 공통 함수
│   │   └── generator_utils.py              # Generator 공통 함수
│   │
│   ├── extractors/
│   │   ├── r01_data_extractor.py
│   │   ├── r02_data_extractor.py
│   │   ├── ...
│   │   └── r07_data_extractor.py
│   │
│   └── generators/
│       ├── r01_report_generator.py
│       ├── r02_report_generator.py
│       ├── ...
│       └── r07_report_generator.py
│
└── results/
    ├── r01/
    │   ├── r01_parsed_data.json            # 중간 데이터
    │   └── r01_analysis.xlsx               # 최종 보고서
    ├── r02/
    │   ├── r02_parsed_data.json
    │   └── r02_analysis.xlsx
    ├── ...
    └── r07/
        ├── r07_parsed_data.json
        └── r07_analysis.xlsx
```

---

## 7. 산출물 목록

### 7.1. 스크립트 (총 16개)

**공통 라이브러리 (2개)**:
- `common/extractor_utils.py`: Extractor 공통 함수
- `common/generator_utils.py`: Generator 공통 함수

**Extractors (7개)**:
- `r01_data_extractor.py` ~ `r07_data_extractor.py`

**Generators (7개)**:
- `r01_report_generator.py` ~ `r07_report_generator.py`

### 7.2. 데이터 파일 (총 14개)

**중간 데이터 (7개)**:
- `r01_parsed_data.json` ~ `r07_parsed_data.json`

**최종 보고서 (7개)**:
- `r01_analysis.xlsx` ~ `r07_analysis.xlsx` (각 3 Sheets)

---

## 8. 연관 문서

본 메인 문서(v2.0)는 전체 아키텍처 개요를 제공하며, 각 계층의 상세 설계는 별도 문서에서 다룬다:

### 8.1. Data Extraction Layer 문서

**문서명**: `Data_Extraction_Layer_설계서.md`

**내용**:
- Extractor 스크립트 상세 구조
- NDJSON 파싱 로직
- resultData 필드 추출 방법
- 중간 JSON 파일 포맷 상세
- 에러 핸들링 전략
- 단계별 Extractor 구현 가이드

**연계 방식**: 
- 본 문서(v2.0)에서 정의한 중간 파일 포맷을 준수
- Generator와의 인터페이스 계약 명시

### 8.2. Report Generation Layer 문서

**문서명**: `Report_Generation_Layer_설계서.md`

**내용**:
- Generator 스크립트 상세 구조
- 통계 계산 알고리즘 (평균, 중앙값, 95th)
- 3-Sheet Excel 생성 로직
- 시각화 차트 생성 (선택)
- 단계별 ResultData 파싱 로직
- 단계별 Generator 구현 가이드

**연계 방식**: 
- 본 문서(v2.0)에서 정의한 3-Sheet 구조를 준수
- Extractor가 생성한 중간 파일을 입력으로 사용

### 8.3. 문서 간 의존 관계

```
┌──────────────────────────────────────┐
│ 메인 문서 (v2.0)                      │
│ - 전체 아키텍처                       │
│ - 2-Step 흐름                         │
│ - 중간 파일 포맷 정의                 │
│ - 3-Sheet 구조 정의                   │
└────────┬─────────────────────────────┘
         │
         ├─────────────────┬─────────────────┐
         │                 │                 │
         ▼                 ▼                 ▼
┌────────────────┐ ┌────────────────┐ ┌────────────────┐
│ Extraction     │ │ Generation     │ │ 구현 예시      │
│ Layer 문서     │ │ Layer 문서     │ │ (코드 샘플)    │
│                │ │                │ │                │
│ - 파싱 로직    │ │ - 통계 계산    │ │ - r01 예제     │
│ - JSON 생성    │ │ - Excel 생성   │ │ - r02 예제     │
└────────────────┘ └────────────────┘ └────────────────┘
```

---

## 9. 구현 순서 (권장)

### 9.1. 공통 라이브러리 우선

```
1. extractor_utils.py 작성 (공통 파싱 함수)
2. generator_utils.py 작성 (공통 Excel 생성 함수)
```

### 9.2. 단계별 순서

```
3. R-01 (가장 단순) → 템플릿 확립
   - r01_data_extractor.py
   - r01_report_generator.py
   
4. R-02 (B-03 병목) → 핵심 병목 측정
   - r02_data_extractor.py
   - r02_report_generator.py
   
5. R-05 (B-01 병목) → 두 번째 병목 측정
   - r05_data_extractor.py
   - r05_report_generator.py
   
6. R-03, R-04, R-06, R-07 → 나머지 단계
```

---

## 10. 변경 이력

| 버전 | 날짜 | 작성자 | 변경 내역 |
|------|------|--------|----------|
| 1.0 | 2025-01-24 | 정범진 | 초안 작성 - 표준 3-Sheet 구조 정의 |
| **2.0** | **2025-01-24** | **정범진** | **2-Step 아키텍처로 전면 개편** - Extractor/Generator 분리 |

---

**문서 종료**
