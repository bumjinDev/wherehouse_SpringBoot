# wherehouse 성능 로그 분석 자동화 시스템 설계서 v2.1

**작성일**: 2025-01-24  
**작성자**: 정범진  
**버전**: 2.1 (Sheet 4: Raw_Data 추가)

---

## 📋 목차

1. [개요](#1-개요)
2. [시스템 아키텍처](#2-시스템-아키텍처)
3. [디렉토리 구조](#3-디렉토리-구조)
4. [공통 라이브러리 (Common Layer)](#4-공통-라이브러리-common-layer)
5. [데이터 추출 계층 (Extractor Layer)](#5-데이터-추출-계층-extractor-layer)
6. [보고서 생성 계층 (Generator Layer)](#6-보고서-생성-계층-generator-layer)
7. [Excel 보고서 구조 (4-Sheet)](#7-excel-보고서-구조-4-sheet)
8. [단계별 구현 명세](#8-단계별-구현-명세)
9. [실행 방법](#9-실행-방법)
10. [트러블슈팅](#10-트러블슈팅)

---

## 1. 개요

### 1.1 목적
wherehouse 프로젝트의 PERFORMANCE 로그를 자동 분석하여 병목 지점을 식별하고, Excel 보고서를 생성하는 시스템입니다.

### 1.2 주요 기능
- **NDJSON 로그 파싱**: 7단계 (R-01 ~ R-07) 로그 자동 추출
- **무손실 데이터 보존**: resultData 필드 완전 보존
- **4-Sheet Excel 보고서 생성**:
  - Sheet 1: Step_Summary (메인 루틴 통계)
  - Sheet 2: Action_Breakdown (전체 Action 통계)
  - Sheet 3: ResultData_Analysis (비즈니스 지표)
  - **Sheet 4: Raw_Data (원본 JSON 데이터)** ← v2.1 추가
- **병목 분석**: 평균/중앙값/P95 기반 성능 분석

### 1.3 변경 이력

| 버전 | 날짜 | 변경 내용 |
|------|------|-----------|
| v1.0 | 2025-01-23 | 초기 설계 (3-Sheet 구조) |
| v2.0 | 2025-01-24 | 무손실 보존 원칙 추가, 설계서 개선 |
| **v2.1** | **2025-01-24** | **Sheet 4: Raw_Data 추가** |

---

## 2. 시스템 아키텍처

### 2.1 2-Layer 아키텍처

```
┌─────────────────────────────────────────────────────────────┐
│                    wherehouse.log (NDJSON)                  │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│              Layer 1: Data Extractor (파싱/정제)            │
│  - r01_data_extractor.py ~ r07_data_extractor.py            │
│  - 공통: extractor_utils.py                                 │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│             중간 파일 (JSON) - 무손실 보존                   │
│  - r01_parsed_data.json ~ r07_parsed_data.json              │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│           Layer 2: Report Generator (보고서 생성)           │
│  - r01_report_generator.py ~ r07_report_generator.py        │
│  - 공통: generator_utils.py                                 │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│              Excel 보고서 (4-Sheet) ← v2.1 변경             │
│  - r01_analysis.xlsx ~ r07_analysis.xlsx                    │
│  - Sheet 1~3: 통계 / Sheet 4: 원본 데이터                  │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 핵심 설계 원칙

| 원칙 | 설명 |
|------|------|
| **무손실 보존** | resultData 필드 전체 보존 (중간 파일) |
| **선택적 추출** | Generator에서 필요한 지표만 선택 (Sheet 3) |
| **원본 보기** | Sheet 4에서 JSON 데이터 직접 확인 가능 ← v2.1 |
| **단계별 독립성** | 각 R-0X 단계는 독립적으로 실행 가능 |
| **재사용성** | 공통 함수는 common/ 디렉토리에 집중 |

---

## 3. 디렉토리 구조

```
E:\devSpace\
├── SpringBootProjects\
│   └── wherehouse_SpringBoot-master\
│       └── wherehouse\
│           └── log\
│               └── wherehouse.log          # 입력 로그 파일
│
├── results\                                # 출력 디렉토리
│   ├── r01\
│   │   ├── r01_parsed_data.json           # 중간 파일
│   │   └── r01_analysis.xlsx              # 최종 보고서 (4-Sheet)
│   ├── r02\
│   ├── r03\
│   ├── r04\
│   ├── r05\
│   ├── r06\
│   └── r07\
│
└── scripts\
    ├── common\
    │   ├── extractor_utils.py             # 공통 Extractor 함수
    │   └── generator_utils.py             # 공통 Generator 함수
    ├── extractors\
    │   ├── r01_data_extractor.py          # R-01 추출 스크립트
    │   ├── r02_data_extractor.py
    │   ├── r03_data_extractor.py
    │   ├── r04_data_extractor.py
    │   ├── r05_data_extractor.py
    │   ├── r06_data_extractor.py
    │   └── r07_data_extractor.py
    └── generators\
        ├── r01_report_generator.py        # R-01 보고서 생성
        ├── r02_report_generator.py
        ├── r03_report_generator.py
        ├── r04_report_generator.py
        ├── r05_report_generator.py
        ├── r06_report_generator.py
        └── r07_report_generator.py
```

---

## 4. 공통 라이브러리 (Common Layer)

### 4.1 extractor_utils.py

추출 계층의 공통 함수 모음

| 함수명 | 설명 | 반환값 |
|--------|------|--------|
| `parse_ndjson_log()` | NDJSON 로그 파싱 | List[Dict] |
| `clean_log_data()` | 중복 제거, duration_ms 계산 | List[Dict] |
| `extract_result_data()` | resultData 무손실 보존 | List[Dict] |
| `create_metadata()` | 메타데이터 생성 | Dict |
| `save_to_json()` | JSON 파일 저장 | None |
| `validate_parsed_data()` | 데이터 유효성 검증 | bool |

**핵심 코드 예시**:
```python
def extract_result_data(logs: List[Dict], step: str) -> List[Dict]:
    """
    resultData 필드 추출 (무손실 보존 원칙)
    
    CRITICAL 원칙:
    - resultData의 모든 필드를 있는 그대로 보존
    - 평탄화, 필터링, 변환 일체 금지
    """
    # 아무것도 하지 않음 - 원본 그대로 반환
    return logs
```

---

### 4.2 generator_utils.py

보고서 생성 계층의 공통 함수 모음

| 함수명 | 설명 | 반환값 |
|--------|------|--------|
| `load_parsed_data()` | 중간 JSON 로드 | Dict |
| `create_step_summary_sheet()` | Sheet 1 생성 | None |
| `create_action_breakdown_sheet()` | Sheet 2 생성 | None |
| `create_resultdata_sheet_base()` | Sheet 3 생성 베이스 | None |
| **`create_raw_data_sheet()`** ← v2.1 | **Sheet 4 생성** | **None** |
| `extract_nested_field()` | 중첩 필드 추출 | Any |
| `validate_excel_output()` | Excel 검증 (3+1 Sheet) | bool |

**v2.1 추가 함수**:
```python
def create_raw_data_sheet(df: pd.DataFrame, 
                          writer, 
                          sheet_name='Raw_Data',
                          include_json_string=True):
    """
    Sheet 4: Raw_Data 생성 - END 로그의 원본 데이터 저장
    
    Args:
        include_json_string: 
            - True: resultData를 JSON 문자열로 저장 (기본)
            - False: resultData를 평탄화하여 개별 컬럼 저장
    
    컬럼:
        - 기본: traceId, timestamp, step, layer, class, method, action, status
        - 성능: duration_ms
        - 원본: resultData_JSON (JSON 문자열)
    """
```

**v2.1 수정 함수**:
```python
def validate_excel_output(output_file: str, strict_mode: bool = False) -> bool:
    """
    생성된 Excel 파일 유효성 검증
    
    Args:
        strict_mode: 
            - False: 3개 필수 시트만 검증 (기본, 하위 호환)
            - True: 4개 시트 모두 검증
    
    검증:
        - 필수: Step_Summary, Action_Breakdown, ResultData_Analysis
        - 선택: Raw_Data (strict_mode=True인 경우)
    """
```

---

## 5. 데이터 추출 계층 (Extractor Layer)

### 5.1 r0X_data_extractor.py 템플릿

```python
"""
R-0X Data Extractor
"""
import sys
import os
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent / 'common'))
from extractor_utils import (
    parse_ndjson_log,
    clean_log_data,
    extract_result_data,
    create_metadata,
    save_to_json,
    validate_parsed_data
)

def main():
    # 경로 설정
    LOG_BASE_PATH = r'E:\devSpace\...\log'
    RESULT_BASE_PATH = r'E:\devSpace\results'
    
    config = {
        'step': 'R-0X',
        'log_file': os.path.join(LOG_BASE_PATH, 'wherehouse.log'),
        'output_dir': os.path.join(RESULT_BASE_PATH, 'r0X'),
        'output_file': 'r0X_parsed_data.json'
    }
    
    # 1. 로그 파싱
    logs = parse_ndjson_log(config['log_file'], config['step'])
    
    # 2. 데이터 정제
    logs = clean_log_data(logs)
    
    # 3. resultData 무손실 보존
    logs = extract_result_data(logs, config['step'])
    
    # 4. 메타데이터 생성
    metadata = create_metadata(config, logs)
    
    # 5. 검증
    data = {'metadata': metadata, 'logs': logs}
    validate_parsed_data(data)
    
    # 6. 저장
    output_path = Path(config['output_dir']) / config['output_file']
    save_to_json(data, output_path)

if __name__ == '__main__':
    main()
```

---

## 6. 보고서 생성 계층 (Generator Layer)

### 6.1 r0X_report_generator.py 템플릿

```python
"""
R-0X Report Generator
"""
import sys
import os
from pathlib import Path
import pandas as pd

sys.path.append(str(Path(__file__).parent.parent / 'common'))
from generator_utils import (
    load_parsed_data,
    create_step_summary_sheet,
    create_action_breakdown_sheet,
    create_resultdata_sheet_base,
    create_raw_data_sheet,  # ← v2.1 추가
    validate_excel_output
)

def create_r0X_resultdata_sheet(df: pd.DataFrame, writer):
    """R-0X 전용 ResultData_Analysis 시트"""
    metrics_config = {
        # 단계별 지표 정의
    }
    create_resultdata_sheet_base(df, writer, metrics_config, 'ResultData_Analysis')

def main():
    RESULT_BASE_PATH = r'E:\devSpace\results'
    
    config = {
        'step': 'R-0X',
        'input_file': os.path.join(RESULT_BASE_PATH, 'r0X', 'r0X_parsed_data.json'),
        'output_file': os.path.join(RESULT_BASE_PATH, 'r0X', 'r0X_analysis.xlsx')
    }
    
    # 1. 로드
    data = load_parsed_data(config['input_file'])
    df = pd.DataFrame(data['logs'])
    
    # 2. Excel 생성 (4-Sheet) ← v2.1 변경
    with pd.ExcelWriter(config['output_file'], engine='openpyxl') as writer:
        create_step_summary_sheet(df, writer, 'Step_Summary')
        create_action_breakdown_sheet(df, writer, 'Action_Breakdown')
        create_r0X_resultdata_sheet(df, writer)
        create_raw_data_sheet(df, writer, 'Raw_Data')  # ← v2.1 추가
    
    # 3. 검증
    validate_excel_output(config['output_file'])

if __name__ == '__main__':
    main()
```

---

## 7. Excel 보고서 구조 (4-Sheet)

### 7.1 Sheet 1: Step_Summary

**목적**: 메인 루틴 (Service 레이어) 성능 요약

| 컬럼 | 설명 | 예시 |
|------|------|------|
| step | 단계 | R-01 |
| action | 액션명 | calculate9BlockGrid |
| layer | 레이어 | Service |
| class | 클래스명 | LocationAnalysisServiceImpl |
| method | 메서드명 | calculate9BlockGrid |
| avg_ms | 평균 (ms) | 24.5 |
| median_ms | 중앙값 (ms) | 23.0 |
| p95_ms | 95 퍼센타일 (ms) | 30.0 |
| min_ms | 최소 (ms) | 20.0 |
| max_ms | 최대 (ms) | 35.0 |
| std_ms | 표준편차 (ms) | 3.2 |
| count | 호출 횟수 | 150 |

**병목 식별**: avg_ms, p95_ms가 높은 순으로 정렬

---

### 7.2 Sheet 2: Action_Breakdown

**목적**: 모든 레이어의 Action 성능 분해

| 컬럼 | 설명 |
|------|------|
| step | 단계 |
| layer | 레이어 (Service, Repository, Utility 등) |
| class | 클래스명 |
| method | 메서드명 |
| action | 액션명 |
| avg_ms ~ count | Sheet 1과 동일 |

**용도**: 
- Service → Repository 호출 관계 추적
- Utility 계층 성능 측정

---

### 7.3 Sheet 3: ResultData_Analysis

**목적**: 비즈니스 지표 분석 (단계별 커스터마이징)

| 컬럼 | 설명 | 예시 |
|------|------|------|
| metric_name | 지표명 | totalGridCount |
| avg | 평균 | 9.0 |
| median | 중앙값 | 9.0 |
| p95 | 95 퍼센타일 | 9.0 |
| min | 최소 | 9 |
| max | 최대 | 9 |
| description | 지표 설명 | 9-Block 개수 (항상 9) |

**단계별 지표 예시**:
- R-01: totalGridCount, success_rate
- R-02: l1CacheHit, l2TotalHits, l2TotalMisses
- R-04: amenityResults 개수, API 호출 횟수
- R-05: cctvFilter, policeQuery 통계

---

### 7.4 Sheet 4: Raw_Data ← v2.1 추가

**목적**: 원본 JSON 데이터 보기 및 검증

| 컬럼 | 설명 | 예시 |
|------|------|------|
| traceId | 요청 추적 ID | 27ec5af0 |
| timestamp | 로그 시각 | 2025-10-23T07:36:55.267940Z |
| step | 단계 | R-01 |
| layer | 레이어 | Service |
| class | 클래스명 | LocationAnalysisServiceImpl |
| method | 메서드명 | calculate9BlockGrid |
| action | 액션명 | calculate9BlockGrid |
| status | 상태 | END |
| duration_ms | 실행 시간 (ms) | 24 |
| **resultData_JSON** | **원본 JSON 문자열** | {"requestLatitude":37.5663,...} |

**특징**:
- ✅ END 로그만 포함 (START 제외)
- ✅ resultData를 JSON 문자열로 저장 (기본 옵션)
- ✅ Excel에서 필터/정렬 가능
- ✅ 원본 데이터 직접 확인 가능

**옵션 2 - 평탄화**:
```python
create_raw_data_sheet(df, writer, 'Raw_Data', include_json_string=False)
```
→ `resultData.latitude`, `resultData.longitude` 등 개별 컬럼으로 분리

---

## 8. 단계별 구현 명세

### 8.1 R-01: 9-Block 그리드 계산

**병목**: 없음 (단순 계산)

**Sheet 3 지표**:
```python
metrics_config = {
    'totalGridCount': {
        'path': 'totalGridCount',
        'description': '9-Block 그리드 개수 (항상 9)'
    },
    'nineBlockGeohashes_count': {
        'path': 'nineBlockGeohashes',
        'description': 'Geohash 배열 길이',
        'transform': lambda x: len(x) if isinstance(x, list) else 0
    },
    'success_rate': {
        'path': 'success',
        'description': '성공률 (%)',
        'transform': lambda x: 100.0 if x else 0.0
    }
}
```

**Sheet 4**: 2개 로그 (Service + Utility)

---

### 8.2 R-02: 캐시 조회 (B-03 병목)

**병목**: L2 캐시 N+1 쿼리

**Sheet 3 지표**:
```python
metrics_config = {
    'l1CacheHit': {
        'path': 'l1CacheHit',
        'description': 'L1 캐시 히트 여부 (%)',
        'transform': lambda x: 100.0 if x else 0.0
    },
    'l2TotalHits': {
        'path': 'l2TotalHits',
        'description': 'L2 캐시 히트 수 (평균)'
    },
    'l2TotalMisses': {
        'path': 'l2TotalMisses',
        'description': 'L2 캐시 미스 수 (평균)'
    },
    'l2CacheTotalDurationNs': {
        'path': 'l2CacheTotalDurationNs',
        'description': 'L2 캐시 총 소요 시간 (ns)',
        'transform': lambda x: x / 1_000_000  # ns → ms 변환
    }
}
```

**Sheet 4**: L2 캐시 9번 조회 상세 (l2CacheResults 배열)

---

### 8.3 R-03: DB 쿼리

**Sheet 3 지표**:
```python
metrics_config = {
    'cctvTotalRowsReturned': {
        'path': 'cctvQueryResult.totalRowsReturned',
        'description': 'CCTV DB 조회 결과 개수'
    },
    'cctvQueryExecutionTimeMs': {
        'path': 'cctvQueryResult.queryExecutionTimeNs',
        'description': 'CCTV 쿼리 실행 시간 (ms)',
        'transform': lambda x: x / 1_000_000
    }
}
```

**Sheet 4**: DB 쿼리 결과 및 캐시 쓰기 상세

---

### 8.4 R-04: 외부 API 호출 (B-02 병목)

**병목**: Amenity API 순차 호출

**Sheet 3 지표**:
```python
metrics_config = {
    'totalSequentialTasks': {
        'path': 'totalSequentialTasks',
        'description': '순차 작업 개수 (항상 3)'
    },
    'totalExecutionTimeMs': {
        'path': 'totalExecutionTimeNs',
        'description': '전체 실행 시간 (ms)',
        'transform': lambda x: x / 1_000_000
    },
    'amenityTotalPlaces': {
        'path': 'amenityApiResult.totalPlaces',
        'description': 'Amenity API 결과 개수'
    },
    'amenityExecutionTimeMs': {
        'path': 'amenityApiResult.executionTimeNs',
        'description': 'Amenity API 소요 시간 (ms)',
        'transform': lambda x: x / 1_000_000
    }
}
```

**Sheet 4**: 3개 API (주소, 검거율, 편의시설) 상세 결과

---

### 8.5 R-05: 데이터 통합 및 필터링 (B-01 병목)

**병목**: 파출소 Native Query (221ms)

**Sheet 3 지표**:
```python
metrics_config = {
    'cctvFilterRate': {
        'path': 'cctvFilter.filterRate',
        'description': 'CCTV 필터링 비율 (%)',
        'transform': lambda x: x * 100
    },
    'policeQueryDurationMs': {
        'path': 'policeQuery.queryDurationNs',
        'description': '파출소 쿼리 소요 시간 (ms)',
        'transform': lambda x: x / 1_000_000
    },
    'policeNearestDistance': {
        'path': 'policeQuery.nearestDistance',
        'description': '가장 가까운 파출소 거리 (m)'
    }
}
```

**Sheet 4**: CCTV 필터링, 파출소 쿼리, 편의시설 필터링 상세

---

### 8.6 R-06: 점수 계산

**Sheet 3 지표**:
```python
metrics_config = {
    'safetyScore': {
        'path': 'safetyScore.finalScore',
        'description': '안전 점수'
    },
    'convenienceScore': {
        'path': 'convenienceScore.finalScore',
        'description': '편의 점수'
    },
    'overallScore': {
        'path': 'overallScore',
        'description': '종합 점수'
    }
}
```

**Sheet 4**: 점수 계산 상세 (가중치, 개별 점수 등)

---

### 8.7 R-07: 최종 응답 생성

**Sheet 3 지표**:
```python
metrics_config = {
    'responseSizeBytes': {
        'path': 'responseSizeBytes',
        'description': '응답 크기 (bytes)'
    },
    'cacheWriteSuccess': {
        'path': 'cacheWrite.success',
        'description': '캐시 쓰기 성공률 (%)',
        'transform': lambda x: 100.0 if x else 0.0
    }
}
```

**Sheet 4**: 캐시 쓰기 결과 및 최종 응답 상세

---

## 9. 실행 방법

### 9.1 전체 파이프라인 실행

```bash
# 1. R-01 추출
cd E:\devSpace\scripts\extractors
python r01_data_extractor.py

# 출력 예시:
# ======================================================================
# R-01 Data Extractor 시작
# ======================================================================
# 로그 파일: E:\devSpace\...\wherehouse.log
# 출력 디렉토리: E:\devSpace\results\r01
# ----------------------------------------------------------------------
# 
# [1/6] 로그 파싱 중...
#   - 로그 파일 읽는 중: E:\devSpace\...\wherehouse.log
#   ✓ 파싱 완료: 4개 로그
# 
# [2/6] 데이터 정제 중...
#   ✓ 정제 완료: 4개 로그
# 
# [3/6] resultData 추출 중...
#   ✓ END 로그: 2개
#   ✓ resultData 필드: latitude, longitude, precision, centerHash, ...
# 
# [4/6] 메타데이터 생성 중...
#   ✓ step: R-01
#   ✓ total_logs: 4
#   ✓ end_logs: 2
# 
# [5/6] 데이터 검증 중...
#   ✓ 검증 통과
# 
# [6/6] JSON 파일 저장 중...
#   - 파일 크기: 0.00 MB
# 
# ======================================================================
# ✅ R-01 추출 완료!
# ✅ 출력 파일: E:\devSpace\results\r01\r01_parsed_data.json
# ======================================================================

# 2. R-01 보고서 생성
cd E:\devSpace\scripts\generators
python r01_report_generator.py

# 출력 예시:
# ======================================================================
# R-01 Report Generator 시작
# ======================================================================
# 입력 파일: E:\devSpace\results\r01\r01_parsed_data.json
# 출력 파일: E:\devSpace\results\r01\r01_analysis.xlsx
# ----------------------------------------------------------------------
# 
# [1/4] 중간 파일 로드 중...
#   - 메타데이터: R-01, 총 4개 로그, END 2개
#   ✓ 로드 완료: 4개 로그
# 
# [2/4] 데이터 확인 중...
#   ✓ START 로그: 2개
#   ✓ END 로그: 2개
#   ✓ 레이어 분포:
#       - Service: 2개
#       - Utility: 2개
# 
# [3/4] Excel 보고서 생성 중...
#   - Sheet 1: Step_Summary
#   - Step_Summary: 1개 메인 루틴
#   - Sheet 2: Action_Breakdown
#   - Action_Breakdown: 2개 Action
#   - Sheet 3: ResultData_Analysis
#   - ResultData_Analysis: 3개 지표
#   - Sheet 4: Raw_Data
#   - Raw_Data: 2개 로그 (resultData는 JSON 문자열)
#   ✓ Excel 생성 완료
# 
# [4/4] Excel 파일 검증 중...
#   ✓ Excel 검증 완료: 4개 시트
# 
# ======================================================================
# ✅ R-01 보고서 생성 완료!
# ✅ 출력 파일: E:\devSpace\results\r01\r01_analysis.xlsx
# ======================================================================

# 3. 결과 확인
start E:\devSpace\results\r01\r01_analysis.xlsx
```

### 9.2 모든 단계 일괄 실행 (배치 스크립트)

**run_all_analysis.bat**:
```batch
@echo off
cd /d E:\devSpace\scripts

echo [1/7] R-01 분석 시작...
python extractors\r01_data_extractor.py
python generators\r01_report_generator.py

echo [2/7] R-02 분석 시작...
python extractors\r02_data_extractor.py
python generators\r02_report_generator.py

REM ... R-03 ~ R-07 반복 ...

echo 모든 분석 완료!
pause
```

---

## 10. 트러블슈팅

### 10.1 로그 파일을 찾을 수 없습니다

**증상**:
```
❌ 파일을 찾을 수 없습니다: E:\devSpace\...\wherehouse.log
```

**해결**:
1. 스크립트 상단의 `LOG_BASE_PATH` 경로 확인
2. wherehouse.log 파일 존재 여부 확인
3. 경로에 한글이나 특수문자가 있는지 확인

---

### 10.2 중간 파일을 찾을 수 없습니다

**증상**:
```
❌ 파일을 찾을 수 없습니다: E:\devSpace\results\r01\r01_parsed_data.json
```

**해결**:
1. 먼저 Extractor를 실행했는지 확인
2. `RESULT_BASE_PATH` 경로 확인
3. 수동으로 디렉토리 생성: `mkdir E:\devSpace\results\r01`

---

### 10.3 Sheet 4에 데이터가 없습니다

**증상**:
Sheet 4가 비어있거나 로그가 없음

**해결**:
1. END 로그가 있는지 확인 (START만 있으면 Sheet 4 생성 안 됨)
2. 중간 파일(JSON)에서 `"status": "END"` 로그 확인
3. 로그 파일에서 해당 step의 PERFORMANCE 로그 확인

---

### 10.4 resultData_JSON이 잘립니다

**증상**:
Excel에서 JSON 문자열이 너무 길어서 잘림

**원인**:
- Excel 셀 표시 제한 (32,767자)
- R-04처럼 amenityResults가 큰 경우 JSON이 매우 길어짐

**해결 방법 1**: 평탄화 옵션 사용 (권장)
```python
# r0X_report_generator.py 수정
create_raw_data_sheet(df, writer, 'Raw_Data', include_json_string=False)
```
→ `resultData.latitude`, `resultData.longitude` 등 개별 컬럼으로 분리

**해결 방법 2**: Excel에서 컬럼 너비 조정
- Sheet 4 → resultData_JSON 컬럼 더블클릭 (자동 조정)
- 단, 32,767자를 초과하면 여전히 잘림

**해결 방법 3**: JSON 파일 직접 확인 (제한 없음)
- `r0X_parsed_data.json` 파일을 VS Code 등으로 열기
- 전체 JSON 데이터를 온전히 확인 가능

**참고**: Sheet 4는 "보기 편의" 목적이므로, 완전한 데이터는 항상 JSON 파일에 보존됨

---

## 11. 부록

### 11.1 의존성 패키지

```
pandas
openpyxl
```

**설치**:
```bash
pip install pandas openpyxl
```

---

### 11.2 로그 구조 예시

```json
{
  "timestamp": "2025-10-23T07:36:55.280938900Z",
  "nanoTime": 21466984472500,
  "traceId": "27ec5af0",
  "thread": "http-nio-8185-exec-2",
  "eventType": "PERFORMANCE",
  "step": "R-01",
  "layer": "Service",
  "class": "LocationAnalysisServiceImpl",
  "method": "calculate9BlockGrid",
  "action": "calculate9BlockGrid",
  "status": "END",
  "duration_ns": 24653800,
  "duration_ms": 24,
  "resultData": {
    "requestLatitude": 37.5663,
    "requestLongitude": 126.9779,
    "requestRadius": 500,
    "centerGeohashId": "wydm9qw",
    "nineBlockGeohashes": ["wydm9qw", "wydm9qy", ...],
    "totalGridCount": 9,
    "errorMessage": null,
    "success": true
  }
}
```

---

### 11.3 주요 변경 사항 (v2.0 → v2.1)

| 항목 | v2.0 | v2.1 |
|------|------|------|
| Sheet 개수 | 3개 (필수) | **4개 (3개 필수 + 1개 선택)** |
| 원본 데이터 확인 | JSON 파일만 | **Excel Sheet 4에서 직접 확인 가능** |
| generator_utils 함수 | 6개 | **7개 (`create_raw_data_sheet` 추가)** |
| validate_excel_output | 3-Sheet 검증 | **3+1 Sheet 검증 (strict_mode 지원)** |
| Excel 사용성 | 통계만 확인 | **통계 + 원본 데이터 확인 가능** |

**업그레이드 가이드**:

1. **generator_utils.py 교체** (필수)
   - `create_raw_data_sheet()` 함수 추가됨
   - `validate_excel_output()` 함수 수정됨

2. **각 r0X_report_generator.py 수정** (선택)
   ```python
   # import 추가
   from generator_utils import (
       ...,
       create_raw_data_sheet,  # ← 추가
       ...
   )
   
   # Excel 생성 부분에 Sheet 4 추가
   with pd.ExcelWriter(config['output_file'], engine='openpyxl') as writer:
       create_step_summary_sheet(df, writer, 'Step_Summary')
       create_action_breakdown_sheet(df, writer, 'Action_Breakdown')
       create_r0X_resultdata_sheet(df, writer)
       create_raw_data_sheet(df, writer, 'Raw_Data')  # ← 추가
   ```

3. **기존 Excel 파일 재생성** (선택)
   - Extractor는 재실행 불필요 (JSON 파일 그대로 사용)
   - Generator만 재실행하면 Sheet 4 포함된 새 Excel 생성

**하위 호환성**:
- Sheet 4는 **선택사항**이므로 추가하지 않아도 정상 동작
- `validate_excel_output()`은 기본적으로 3개 시트만 검증 (strict_mode=False)
- 기존 3-Sheet Excel도 계속 사용 가능

---

**문서 끝**
