# 위치 분석 서비스 성능 테스트 분석 보고서

**문서 버전**: 1.0  
**작성일**: 2025-01-21  
**작성자**: 정범진  
**프로젝트**: Wherehouse 위치 기반 정보 분석 서비스 성능 최적화

---

## 목차

1. [개요](#1-개요)
2. [테스트 준비 및 환경 구성](#2-테스트-준비-및-환경-구성)
3. [테스트 시나리오](#3-테스트-시나리오)
4. [로깅 및 데이터 수집](#4-로깅-및-데이터-수집)
5. [성능 계측 전략](#5-성능-계측-전략)
6. [병목 구간 식별](#6-병목-구간-식별)
7. [개선 방안](#7-개선-방안)
8. [결론 및 권고사항](#8-결론-및-권고사항)

---

## 1. 개요

### 1.1 테스트 배경

Wherehouse 위치 분석 서비스의 핵심 API인 `POST /api/location-analysis` 엔드포인트의 성능 병목을 식별하고 개선 작업을 진행한다. 현재 사용자 체감 응답 시간이 1-2초 수준으로 관찰되어 실시간 지도 상호작용 서비스의 사용자 경험(UX) 목표치를 하회하는 문제가 식별되었다.

### 1.2 테스트 목적

- 성능 병목을 식별하기 위한 효과적인 계측 방법론 구성
- 1단계: 위치 분석 서비스 성능 테스트 계획 명세서에 따른 아키텍처 구성 검증
- 2단계: 병목 식별 방법론(Instrumentation Probes) 적용 및 전략 수립

### 1.3 성능 목표 (Success Criteria)

| 지표 | 목표치 | 설명 |
|------|--------|------|
| 평균 응답 시간 | 500ms 이하 | 위치 분석 서비스 성능 테스트 계획서에 명시된 바와 같이, API 평균 응답 시간 500ms 이하 달성 |
| 95th Percentile 응답 시간 | 1,000ms 이하 | 95% 사용자가 1초 이내에 응답 |
| 병목 식별 목표 (Threshold) | 200ms 초과 구간 | R-Step이 200ms를 초과하거나, 단일 action이 100ms를 초과하는 모든 구간을 핵심 병목 구간으로 정의 |

---

## 2. 테스트 준비 및 환경 구성

### 2.1 성능 계측 프레임워크 구축

정확한 측정을 위해 다음 계측 도구를 활용한다:

- **PerformanceLogger**: 비즈니스 로직(`LocationAnalysisServiceImpl`)의 가독성을 해치지 않도록, 로깅을 전담하는 별도의 유틸리티 클래스 구현
- **구조화된 로깅 (JSON)**: 모든 성능 로그는 위치 분석 서비스 성능 테스트 계획 명세서에 명시된 JSON 포맷으로 기록
- **트랜잭션 추적 (Traceability)**: SLF4J의 MDC(Mapped Diagnostic Context)를 활용하여 HTTP 요청 전 사이클에 고유 `traceId`를 발급하고, 이 traceId는 해당 스레드에서 발생하는 모든 로그(step, action)에 자동으로 포함되어 동시성 환경에서의 요청 추적을 완벽하게 지원
- **정밀한 시간 측정 (Precision)**: 모든 경과 시간(`duration_ns`)은 OS 시간에 영향을 받지 않고 단조 증가(monotonic)하는 `System.nanoTime()`을 기준으로 측정하여 ms 미만의 정밀도를 확보

### 2.2 테스트 도구

- **부하 생성**: JMeter 5.4
- **성능 계측**: PerformanceLogger (자체 구현), MDC
- **시버 모니터링**: VisualVM, htop

---

## 3. 테스트 시나리오

### 3.1 시나리오 1: Cache Miss (Worst-Case) 스트레스 테스트

- **설정**: 캐시가 비워진(Cold Start) 상태에서 단일 사용자가 API를 호출하는 시나리오 (B-01 - B-05 병목 측정의 핵심)
- **부하 설정**: 1 VUser, 10회 반복 (반복 시마다 캐시 비움)
- **목적**: 캐시 미스 상황에서의 최악의 응답 시간 측정 및 병목 구간 식별

### 3.2 시나리오 2: Cache Hit (Best-Case) 스트레스 테스트

- **설정**: L1/L2 캐시가 채워진(Warm State) 상태에서 API를 호출하는 시나리오
- **부하 설정**: 1 VUser, 10회 반복 (캐시 유지)
- **목적**: 캐시 히트 상황에서의 최선의 응답 시간 측정

### 3.3 시나리오 3: 실제 부하(Load) 테스트

- **설정**: 정의된 성능 목표(500ms)를 만족하는 최대 TPS를 확인
- **부하 설정**: 50 VUs, Ramp-up 1분, Duration 5분
- **목적**: 실제 운영 환경에서의 안정적인 서비스 가능 여부 검증

---

## 4. 로깅 및 데이터 수집

### 4.1 로깅 프레임워크

- **PerformanceLogger** 유틸리티 및 **MDC**를 통한 `traceId` 발급
- **System.nanoTime()** 기반 정밀 시간 측정

### 4.2 로그 포맷 정의

성능 계측 로그는 아래 위치 분석 서비스 성능 테스트 계획서의 표준 JSON 로그 포맷 명세를 산업한다.

```json
{
    "timestamp": "2025-01-21T10:30:01.123Z",
    "nanoTime": 1578394726583100,
    "traceId": "a1b2c3d4",
    "thread": "http-nio-8080-exec-1",
    "eventType": "PERFORMANCE",
    "step": "R-03",
    "layer": "Service",
    "class": "LocationAnalysisServiceImpl",
    "method": "performDatabaseQuery",
    "action": "DB_findCctvByGeohashIdIn",
    "status": "END",
    "duration_ns": 123000000,
    "duration_ms": 123
}
```

### 4.3 병목 식별 기준

- **Step (R-Step)**: 200ms 초과 시 1차 병목으로 정의
- **Action (하위 동작)**: 100ms 초과 시 1차 병목으로 정의
- 전체 응답 시간의 20% 이상을 차지하는 구간을 핵심 병목으로 식별

---

## 5. 성능 계측 전략 (Instrumentation Strategy)

본 성능 분석의 핵심은 `LocationAnalysisServiceImpl`의 `analyzeLocation` 메서드 전반에 걸친 **계층적 계측(Instrumentation Probes)** 을 전략적으로 삽입하는 것이다. 이 전략은 두 가지 계층으로 구성된다.

### 5.1 계측 계층 정의

- **Step (Macro-level)**: R-01부터 R-07까지의 주요 비즈니스 단계를 의미하며, 각 단계의 전체 소요 시간을 측정
- **Action (Micro-level)**: 각 Step 내부에서 발생하는 특정 DB 쿼리, API 호출, 캐시 작업 등 세분화된 작업 동작을 의미

### 5.2 R-01: 9-Block 그리드 범위 계산

```
Step: R-01 | Action: calculate9BlockGeohashes
```

계측은 `calculate9BlockGrid` 메서드는 전체를 래핑(wrapping)하는 것에서 시작한다. 이 Step은 순수 CPU 연산으로 예상되므로, ch.hsr.geohash 라이브러리의 연산 오버헤드를 측정하는 Baseline 역할을 한다.

### 5.3 R-02: 단계별 캐시 조회

```
Step: R-02 | Action: performCacheLookup, L1_Cache_Get, L2_Cache_MGet
```

`performCacheLookup` 메서드는 2단계 캐시 전략의 핵심으로, I/O 병목을 식별하기 위해 세분화된 Action 프로브가 필요하다.

- **L1_Cache_Get**: 1단계(L1) 캐시인 `redisSingleDataService.getSingleData(level1CacheKey)` 호출을 직접 계측하여 단일 DTO 조회에 대한 Redis RTT(Round Trip Time)를 측정한다.
- **L2_Cache_MGet**: L1 미스 시, 9개 격자의 L2 캐시를 조회하는 `for (String geohashId : nineBlockGeohashes)` 루프 전체를 계측한다. 이는 B-03 (Redis N+1 조회) 병목을 정량화하기 위한 핵심 지표다.

### 5.4 R-03: 선택된 데이터베이스 조회

```
Step: R-03 | Action: performDatabaseQuery, DB_findCctvByGeohashIdIn, L2_Cache_MSet
```

`performDatabaseQuery` 메서드는 L2 캐시 미스 시 DB I/O와 L2 캐시 쓰기(Write)를 담당한다.

- **DB_findCctvByGeohashIdIn**: `cctvGeoRepository.findByGeohashIdIn(cctvMisses)` JPA 호출을 계측한다. 이는 B-Tree 인덱스를 활용한 9-Block 쿼리의 실제 성능을 검증한다.
- **L2_Cache_MSet**: 조회된 CCTV 결과를 다시 L2 캐시에 저장하는 `cacheGeohashData` 호출 `for` 루프를 계측한다. 이는 B-04 (Redis N+1 쓰기) 병목을 식별한다.

### 5.5 R-04: 외부 API 호출 및 병렬 처리

```
Step: R-04 | Action: performExternalApiCalls, Async_Kakao_Address_DB_ArrestRate, Async_Kakao_Amenity, Async_AllOf_Join
```

`performExternalApiCalls` 메서드는 `CompletableFuture`를 사용한 복합 I/O 단계이다.

- **Async_Kakao_Address_DB_ArrestRate**: 주소 변환(Kakao API)와 검거율 조회(DB) 조회를 조합하는 첫 번째 `CompletableFuture` 내부 로직 계측한다. 이는 R-02 (블럭요원 직렬 대기) 문제 개선 효과를 검증하는 데 사용된다.
- **Async_Kakao_Amenity**: 편의시설(Kakao API)을 조회하는 두 번째 `CompletableFuture` 내부 로직을 계측한다.
- **Async_AllOf_Join**: `CompletableFuture.allOf(...).join()` 호출 자체를 계측한다. 이 Action의 `duration_ns`는 두 비동기 작업 중 더 오래 걸린 작업의 시간과 거의 일치해야 하며, 이는 병렬 처리가 의도대로 동작했는지 검증한다.

### 5.6 R-05: 데이터 통합 및 필터링

```
Step: R-05 | Action: integrateAndFilterData, Filter_CCTV, DB_findNearestPoliceStation, Filter_Amenity
```

`integrateAndFilterData` 메서드는 현재 시스템에서 가장 지연적인 B-01 (Full Table Scan) 병목을 포함하는 핵심 분석 대상이다.

- **DB_findNearestPoliceStation**: `policeOfficeGeoRepository.findNearestPoliceStations` 네이티브 쿼리 호출을 정밀하게 계측한다. 이 프로브는 B-01 병목의 심각성을 수치로 입증하는 (e.g., `duration_ms: 2156`) 가장 중요한 로그를 생성할 것이다.
- **Filter_CCTV**: 9개 격자의 CCTV 리스트를 `allCctvList.addAll`로 통합하고, `for` 루프를 통해 거리를 계산 및 필터링하는 로직 전체를 계측한다. 이는 **B-05 (비효율적 In-Memory 필터링)** 의 CPU 및 메모리 오버헤드를 측정한다.
- **Filter_Amenity**: 외부 API로부터 받은 편의시설 목록을 DTO로 변환하고 거리를 계산하는 `for` 루프를 계측한다.

### 5.7 R-06: 최종 점수 계산

```
Step: R-06 | Action: calculateScores, calculateSafetyScore, calculateConvenienceScore
```

`calculateScores` 메서드 내의 `calculateSafetyScore` 및 `calculateConvenienceScore` 호출을 각각 계측한다. 이는 기준 JavaScript 로직을 Java로 포팅한 것의 순수 CPU 연산 비용을 평가한다.

### 5.8 R-07: 최종 응답 생성 및 캐싱

```
Step: R-07 | Action: buildFinalResponse, L1_Cache_Set
```

`buildFinalResponse` 메서드 내부의 `recommendations` 및 `warnings` 생성 로직과 DTO 조립 시간을 측정한다.

- **L1_Cache_Set**: 최종 응답 DTO를 L1 캐시에 저장하는 `redisSingleDataService.setSingleData(cacheKey, ...)` 호출을 계측하여, 응답 직전의 캐시 쓰기(Write) RTT를 측정한다.

---

## 6. 병목 구간 식별

### 6.1 예상 병목 구간 (가설)

테스트 계획서 및 코드 분석을 기반으로 다음 구간을 주요 병목 후보로 식별:

1. **R-05 파출소 조회 (B-01)**: Native Query를 사용한 공간 거리 계산 - 예상 2000ms+
2. **R-03 캐시 미스 시 DB 조회 (B-03)**: 9-Block 그리드 DB 조회 - 예상 200ms+
3. **R-04 외부 API 호출 (B-02)**: 카카오맵 API 동기 호출 - 예상 300ms+
4. **R-02 L2 캐시 N+1 조회 (B-04)**: Redis 9회 개별 조회 - 예상 100ms+

### 6.2 실제 측정 결과

**(추가 기술 필요)**

실제 부하 테스트를 통한 측정 결과를 기록할 예정.

---

## 7. 개선 방안

### 7.1 B-01 파출소 조회 개선

**문제**: Native Query를 통한 전체 테이블 스캔 및 거리 계산
**해결 방안**:
- PostGIS 확장 설치 및 공간 인덱스 생성
- ST_DWithin 함수를 활용한 효율적인 공간 쿼리
- 예상 개선 효과: 2000ms → 50ms (40배 개선)

### 7.2 B-03/B-04 Redis 접근 패턴 개선

**문제**: N+1 쿼리 패턴으로 인한 RTT 누적
**해결 방안**:
- Pipeline 또는 MGET/MSET 명령 활용
- Spring Data Redis의 `multiGet` 메서드 사용
- 예상 개선 효과: 100ms → 20ms (5배 개선)

### 7.3 B-02 외부 API 병렬화 강화

**문제**: 일부 로직의 순차 실행
**해결 방안**:
- 검거율 조회를 독립적인 CompletableFuture로 분리
- 예상 개선 효과: 전체 대기 시간을 최장 API 호출 시간으로 단축

---

## 8. 결론 및 권고사항

### 8.1 핵심 발견사항

1. **계층적 계측 전략의 중요성**: Step과 Action 두 단계의 계측을 통해 거시적/미시적 병목을 동시에 식별
2. **병목 구간의 정량적 식별**: 가설이 아닌 측정 데이터 기반의 개선 우선순위 결정
3. **캐싱 전략의 효과성**: L1/L2 캐시 히트 시 성능 목표 달성 가능성 확인

### 8.2 향후 진행 계획

1. **Phase 1**: 본 보고서의 계측 전략을 코드에 적용
2. **Phase 2**: 시나리오별 부하 테스트 수행 및 데이터 수집
3. **Phase 3**: 수집된 데이터 분석 및 병목 구간 확정
4. **Phase 4**: 우선순위에 따른 개선 작업 수행
5. **Phase 5**: 개선 효과 검증 테스트

### 8.3 리스크 및 제약사항

- **외부 API 의존성**: 카카오맵 API 응답 시간은 통제 불가
- **데이터베이스 제약**: Oracle에서 PostGIS 대체 솔루션 검토 필요
- **캐시 일관성**: 실시간 데이터 변경 시 캐시 무효화 전략 필요

---

**문서 종료**