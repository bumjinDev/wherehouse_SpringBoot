# 위치 분석 서비스 성능 테스트 계획서 (Performance Test Plan)

- **문서 버전**: 1.0
- **작성일**: 2025-10-20
- **작성자**: 정병진
- **프로젝트**: Wherehouse 위치 기반 정보 분석 서비스 성능 최적화

## 1. 개요 (Overview)

### 1.1. 테스트 배경 및 목적
`POST /api/location-analysis` API는 사용자가 지도상의 임의 지점을 클릭했을 때, 해당 위치의 안전 및 편의시설 정보를 실시간으로 분석하여 제공하는 핵심 기능이다. 현재 해당 API의 사용자 체감 응답 시간이 1-2초 수준으로 관찰되어, 실시간 지도 상호작용 서비스의 사용자 경험(UX) 목표치를 하회하는 문제가 식별되었다.

본 테스트의 목적은 해당 API의 성능 저하를 유발하는 병목 구간을 데이터 기반으로 정밀하게 식별하고, 아키텍처 및 코드 수준의 개선 작업을 적용한 후, 사전에 정의된 성능 목표(Success Criteria)를 만족하는지 정량적으로 검증하는 데 있다.

### 1.2. 테스트 범위 (Scope)

#### 1.2.1. 범위 내 (In-Scope)
- **대상 시스템**: `wherehouse` 백엔드 애플리케이션 서버
- **대상 API**: `POST /api/location-analysis` 엔드포인트
- **주요 분석 컴포넌트**:
  - `LocationAnalysisServiceImpl`의 전체 비즈니스 로직 (R-01 ~ R-07)
  - 데이터베이스 조회 로직 (`CctvGeoRepository`, `PoliceOfficeGeoRepository`, `ArrestRateRepository`)
  - 외부 시스템 연동 로직 (`KakaoApiService`)
  - 캐시 시스템 연동 로직 (`RedisSingleDataService`)

#### 1.2.2. 범위 외 (Out-of-Scope)
- 프론트엔드(JSP, JavaScript)의 렌더링 및 스크립트 실행 시간
- 외부 시스템(카카오맵 API) 자체의 내부 응답 시간 (단, 외부 API 호출로 인한 대기 시간은 전체 응답 시간에 포함하여 측정)
- `/api/police-offices` 등 본 테스트 대상이 아닌 다른 API 엔드포인트의 성능
- 백지 프로세스(`GeohashIndexingEtiProcessor`)의 성능

## 2. 테스트 목표 (Test Objectives)

### 2.1. Baseline 성능 측정
현재 시스템(As-is)의 성능 수준을 정량적으로 측정하여 기록한다. 이는 향후 개선 효과를 비교하기 위한 명확한 기준 데이터를 확보하는 것을 목표로 한다.

### 2.2. 병목 구간 식별
코드 계측(Instrumentation) 및 DB 실행 계획 분석을 통해 `LocationAnalysisServiceImpl`의 처리 단계 중 가장 많은 시간을 소요하는 핵심 병목 구간을 특정한다.

### 2.3. 성능 목표 검증 (Success Criteria)
부하 시나리오(합루 정의) 조건 하에서, 개선된 시스템(To-Be)은 다음의 성능 목표를 반드시 만족해야 한다.

| 지표 (Metric) | 목표치 (Target) | 설명 |
|--------------|----------------|------|
| 평균 응답 시간 | 500ms 이하 | 전체 요청의 평균적인 처리 시간 |
| 95th Percentile 응답 시간 | 1,000ms 이하 | 95%의 사용자가 1초 이내에 응답을 받는 것을 보장 |
| 처리량 (Throughput) | 50 TPS 이상 | 시스템이 초당 처리할 수 있는 최소 요청 수 |
| 에러율 (Error Rate) | 0.1% 미만 | 부하 상황에서의 시스템 안정성 |

### 2.4. 개선 효과 검증
병목 개선 후 동일한 부하 시나리오를 재수행하여, 2.3에서 정의한 성능 목표를 달성했는지 확인하고, 개선 전/후 성능 지표를 비교하여 개선 효과를 정량화로 증명한다.

## 3. 병목 식별을 위한 통합 절차 (Recommended Workflow)

실무에서 사용하는 표준적인 병목 식별 절차는 두 접근법을 다음과 같은 2단계로 통합하여 적용한다.

### 3.1. 1단계: Top-Down 프로파일링 (거시 분석)
데이터 기반 분석을 통해 시스템의 전체적인 성능 특성을 파악하고 핵심 병목 구간을 식별하는 단계이다.

1. **계측(Instrumentation)**: 분석 대상 트랜잭션(`analyzeLocation`) 전체를 구성하는 모든 주요 기능 단위(예: R-01 ~ R-07 에 해당하는 각 메서드)의 시작과 끝에 `StopWatch` 등을 이용한 시간 측정 로깅을 적용한다.

2. **측정**: 부하 테스트 또는 수동 API 호출을 통해 시스템을 동작시키고, 각 기능 단위별 실행 시간 로그를 수집한다.

3. **병목 식별**: 수집된 데이터를 분석하여, 전체 응답 시간 대비 가장 높은 비율을 차지하는 1~2개의 기능 단위를 핵심 병목 구간으로 확정한다.

### 3.2. 2단계: Drill-Down 분석 (미시 분석)
1단계에서 식별된 핵심 병목 구간의 내부를 상세히 분석하여 근본 원인을 규명하는 단계이다. 이 단계에서 비로소 데이터에 기반한 정교한 '가설'이 설정된다.

- **CPU-bound 병목의 경우**: 병목 메서드 내부의 복잡한 반복문, 데이터 변환 로직 등 특정 코드 블록의 실행 시간을 추가로 측정하여 문제 지점을 세분화한다.

- **I/O-bound 병목의 경우**:
  - **DB**: 해당 구간에서 호출되는 쿼리의 실행 계획(Execution Plan)을 분석하여 Full Table Scan, 비효율적인 조인, 인덱스 미사용 등의 문제를 진단한다.
  - **외부 API**: API 호출의 평균 응답 시간, 타임아웃 발생 빈도 등을 확인한다.

**성능 병목 식별은 추측이 아닌 측정에서 시작한다. Top-Down 접근법은 전체 시스템 동작을 데이터로 파악한 후 문제 영역을 좁혀가는 방법을 사용한다.**

## 4. 동일 표준 적용 방식: 계층적 정보 추가

동일한 JSON 포맷을 사용하되, 각 컴포넌트의 특성을 나타내는 계층적 정보를 필드로 추가하여 구분한다. 이를 통해 분석 시 원하는 계층의 데이터만 필터링하거나 그룹화할 수 있다.

이전 제안에 `layer`와 `class` 필드를 추가하여 이를 구체화할 수 있다.

### 4.1. LocationAnalysisServiceImpl (서비스 계층)의 로그 예시
- R-03 단계 전체의 시작과 끝을 기록한다. 이는 거시적인(Macro) 성능 지표이다.

```json
// R-03 시작 로그
{
    "traceId": "a1b2c3d4",
    "eventType": "PERFORMANCE",
    "step": "R-03",
    "layer": "Service",
    "class": "LocationAnalysisServiceImpl",
    "method": "performDatabaseQuery",
    "status": "START"
}

// R-03 종료 로그
{
    "traceId": "a1b2c3d4",
    "eventType": "PERFORMANCE",
    "step": "R-03",
    "layer": "Service",
    "class": "LocationAnalysisServiceImpl",
    "method": "performDatabaseQuery",
    "status": "END",
    "duration_ms": 850
}
```

### 4.2. CctvGeoRepository (데이터 접근 계층)의 로그 예시
- R-03 단계 내부에서 발생하는 구체적인 DB I/O 작업의 시간을 기록한다. 이는 미시적인(Micro) 성능 지표이다. 이 로그는 AOP 등을 통해 자동으로 남겨질 수 있다.

```json
{
    "traceId": "a1b2c3d4",
    "eventType": "PERFORMANCE",
    "step": "R-03",  // 상위 컨텍스트(step)를 그대로 유지하는 것이 중요
    "layer": "Repository",
    "class": "CctvGeoRepository",
    "method": "findByGeohashIdIn",
    "status": "END",
    "duration_ms": 820
}
```

### 4.3. 분석 관점에서의 구조적 이점

위와 같이 동일한 포맷으로 로그를 남겼을 때, Python 분석 스크립트는 다음과 같은 강력한 계층적 분석을 수행할 수 있다.

1. **전체 트랜잭션 재구성**: `traceId`가 `"a1b2c3d4"`인 모든 로그를 시간순으로 정렬하면, 단일 요청이 어떤 컴포넌트를 어떤 순서로, 얼마나 오래 호출했는지 전체 호출을 완벽하게 재구성할 수 있다.

2. **병목의 근본 원인 규명**: 위 예시에서 `R-03` 단계 전체는 850ms가 걸렸는데, 그 내부에서 호출된 `findByGeohashIdIn` 메서드가 820ms를 차지했음을 알 수 있다. 이를 통해 "R-03이 느린 이유는 서비스 로직(30ms)이 아니라, 순수 DB 쿼리 시간(820ms) 때문이다"라는 명확한 결론을 내릴 수 있다. 이것이 바로 병목 분석의 핵심이다.

3. **단일 분석 스크립트**: 모든 로그가 동일한 JSON 구조를 가지므로, 단 하나의 Python 스크립트만으로 모든 계층의 로그를 파싱하고 분석할 수 있다. 분석가는 단순히 `layer` 필드 값을 기준으로 데이터를 필터링(`df[df['layer'] == 'Repository']`)하여 원하는 분석을 수행하면 된다.

## 5. 성능 계측 로그 분석 방법론

### 5.1. 시간 측정의 두 가지 종류: currentTimeMillis vs. nanoTime

Java에서 시간은 두 가지 다른 방식으로 측정된다. 이 차이를 이해하는 것이 정밀한 로깅 분석 설계의 핵심이다.

- `System.currentTimeMillis()`:
  - **목적**: 현재 시각 (Wall-Clock Time)을 얻겨한다. UTC 1970년 1월 1일 0시부터 현재까지 경과한 시간을 밀리초 단위로 반환한다.
  - **특징**: 시스템의 시계에 의존하므로, 사용자가 시간을 수동으로 변경하거나 NTP(Network Time Protocol) 동기화로 인해 시간이 뒤로 갈 수 있다.
  - **용도**: "언제" 이벤트가 발생했는지 기록하는 데 적합하다. (`"timestamp": "2025-10-21T10:30:01.246Z"`)

- `System.nanoTime()`:
  - **목적**: 두 시점 사이의 **경과 시간(Elapsed Time)**을 정밀하게 측정하기 위해 존재한다.
  - **특징**: JVM이 시작될 때의 임의의 시점을 0으로 하는 나노초 단위의 상대적인 시각 값이다. 외부 요인에 영향을 받지 않고 오직 앞으로만 증가하는 단조(monotonic) 특성을 보장한다.
  - **용도**: 성능 측정, 즉 "얼마나 걸렸는가"를 계산하는 데 유일하게 신뢰할 수 있는 방법이다. Spring의 `StopWatch`도 내부적으로 `System.nanoTime()`을 사용한다.

### 5.2. 나노초 분석을 위한 수정된 로그 포맷 제안

이 두 가지 시간의 목적을 모두 충족시키기 위해, 기존 JSON 포맷에 `System.nanoTime()` 값을 기록할 수 있는 필드를 추가해야 한다.

#### 수정된 JSON 포맷 예시

```json
// 시작 로그
{
    "timestamp": "2025-10-21T10:30:01.123Z", // 시점을 위한 시각 정보 (ms 단위)
    "nanoTime": 1578394726583100,           // 기간을 위한 경과 시간 측정용 (ns 단위)
    "traceId": "a1b2c3d4",
    "eventType": "PERFORMANCE",
    "step": "R-03",
    "method": "performDatabaseQuery",
    "action": "findCctvByGeohashIdIn",
    "status": "START"
}

// 종료 로그
{
    "timestamp": "2025-10-21T10:30:01.246Z",
    "nanoTime": 1578394849583100,
    "traceId": "a1b2c3d4",
    "eventType": "PERFORMANCE",
    "step": "R-03",
    "method": "performDatabaseQuery",
    "action": "findCctvByGeohashIdIn",
    "status": "END",
    "duration_ns": 123000000,               // nanoTime 기반으로 계산한 경과 시간 (ns)
    "duration_ms": 123                      // 참고용 경과 시간 (ms 단위)
}
```

### 5.3. 이 구조의 장점 및 분석 워크플로우

1. **정밀도 보장**: Python 분석 스크립트는 `START` 로그와 `END` 로그를 `traceId`와 `action`으로 짝지은 후, `nanoTime` 필드의 차이(`end_log['nanoTime'] - start_log['nanoTime']`)를 계산하여 **운영체제 시계 변경과 무관하게, 매우 정밀한 경과 시간(ns)**을 얻을 수 있다. 이것이 분석의 핵심 데이터가 된다.

2. **가독성 유지**: 로그를 직접 읽는 개발자는 여전히 `timestamp` 필드를 통해 이벤트 발생 시점을 쉽게 파악할 수 있으며, `duration_ms` 필드를 통해 대략적인 소요 시간을 빠르게 인지할 수 있다.

3. **구현의 용이성**: Java의 `StopWatch`는 `stopWatch.getLastTaskTimeNanos()`와 같은 메서드를 통해 나노초 단위의 경과 시간을 직접 제공하므로, `duration_ns` 필드를 채우는 것은 간단하다. `System.nanoTime()` 값을 직접 기록하는 것도 쉽다.

### 5.4. 로그 파싱 및 분석 접근법

#### 5.4.1. 파싱의 안정성과 용이성 (Robust & Easy Parsing)
- Python에서 각 로그 라인을 `json.loads(line)`로 읽으면 즉시 딕셔너리(Dictionary) 객체로 변환할 수 있다.
- `split()` 및 인덱스 조작에 의존하거나 정규 표현식을 복잡하게 작성할 필요가 전혀 없어 단순하고 안정적이다.
- `log_data['duration_ms']`와 같이 키 이름으로 데이터에 직접 접근함으로써 코드가 직관적이고 안정적이다.

#### 5.4.2. 분석의 유연성과 확장성 (Flexible & Extensible Analysis)
- `traceId`의 도입: 단일 API 요청(`traceId: "a1b2c3d4"`) 내에서 발생한 모든 로그를 그룹화할 수 있다. 각 단계별 소요 시간을 정확히 집계하여 병목 구간을 명확히 식별한다. 동시 사용자가 많은 환경에서는 이 ID 없이는 어떤 로그가 어떤 요청에 속하는지 구분하는 것이 거의 불가능하다.
- 새로운 분석 차원 추가 용이: 나중에 '사용자 ID'나 '요청 파라미터' 같은 정보를 로그에 추가할 때, 단순히 JSON에 `"userId": "user123"`과 같은 새로운 Key-Value 쌍만 추가하면 된다. 기존 파이썬 분석 코드는 전혀 수정할 필요가 없다.

### 5.5. 구현의 표준화
- SLF4J와 Logback 같은 Java 로그 프레임워크는 이러한 구조화된 로깅을 기본적으로 지원하거나, `logstash-logback-encoder` 같은 라이브러리를 통해 전체 로그를 자동으로 JSON 형식으로 출력할 수 있다.
- MDC(Mapped Diagnostic Context) 라는 SLF4J 기능을 사용하면, HTTP 요청이 시작될 때 `traceId`를 한 번만 설정해두면 해당 요청이 끝날 때까지 모든 로그에 `traceId`가 자동으로 포함된다.