# 상세 지도 기반 정보 제공 서비스 설계 명세서

---

## 문서 정보

**프로젝트명:** 위치 기반 생활 안전·편의 분석 시스템  
**문서 버전:** 1.0  
**작성일:** 2025년 10월 10일  
**작성자:** 정범진

---

## 목차

1. [개요](#1-개요)
2. [일반 요구사항](#2-일반-요구사항)
3. [엔드포인트 명세](#3-엔드포인트-명세)
4. [상태 코드 및 예외 처리](#4-상태-코드-및-예외-처리)
5. [실제 구현 코드 기반 상세 명세](#5-실제-구현-코드-기반-상세-명세)
6. [비즈니스 기능 구현 명세서](#6-비즈니스-기능-구현-명세서)
7. [주요 구현 특징](#7-주요-구현-특징)
8. [부록](#8-부록)

---

## 1. 개요

### 1.1 목적

본 문서는 사용자가 선택한 임의의 지리적 위치에 대한 생활 안전 및 편의성 수준을 종합적으로 분석하고, 데이터 기반의 분석 모델을 통해 객관적인 점수를 제공하는 단일 통합 API 엔드포인트의 기술 명세를 정의한다. 

서버 내부적으로 병렬 데이터 조회, 점수 계산 등 모든 비즈니스 로직을 수행하며, 클라이언트는 좌표 정보만 전달하고 완성된 분석 결과를 수신한다.

### 1.2 범위

본 명세서는 클라이언트가 요청한 단일 좌표에 대해, 서버가 내부 데이터베이스 및 외부 API를 활용하여 안전성 및 편의성을 분석하고 최종 리포트를 제공하는 단일 통합 API 엔드포인트에 대한 요구사항을 다룬다. 

다음 항목을 포함한다:
- API의 요청 파라미터
- 응답 데이터 구조
- 상태 코드
- 예외 처리 방안

---

## 2. 일반 요구사항

### 2.1 데이터 형식
모든 API 요청과 응답의 데이터 형식은 **JSON**(application/json)을 사용한다.

### 2.2 문자 인코딩
모든 데이터는 **UTF-8**로 인코딩한다.

### 2.3 인증
(본 명세서 범위 외)

### 2.4 기본 URL
```
https://{your-domain}
```

---

## 3. 엔드포인트 명세

### 3.1 API 개요

본 시스템은 사용자가 요청한 단일 좌표에 대한 모든 분석 정보를 처리하는 단일 통합 엔드포인트를 제공한다.

| 항목 | 내용 |
|------|------|
| **기능 설명** | 사용자가 요청한 좌표(위도, 경도)를 기반으로, 해당 위치의 생활 안전성 및 편의성을 종합 분석하여 상세 리포트를 제공한다. 서버 내부적으로 병렬 데이터 조회, 점수 계산, 캐싱 등 모든 비즈니스 로직을 수행한다. |
| **HTTP Method** | POST |
| **Endpoint URL** | /api/location-analysis |

### 3.2 요청 명세 (Request)

#### 3.2.1 Request Body Fields

| 필드 | 타입 | 필수 | 설명 | 예시 |
|------|------|------|------|------|
| latitude | Double | ✓ | 분석을 원하는 지점의 위도 | 37.5665 |
| longitude | Double | ✓ | 분석을 원하는 지점의 경도 | 126.9780 |
| radius | Integer | X | 분석 반경 (단위: 미터). 기본값: 500 | 500 |

#### 3.2.2 Request Body 예시

```json
{
  "latitude": 37.5665,
  "longitude": 126.9780,
  "radius": 500
}
```

### 3.3 응답 명세 (Response)

#### 3.3.1 성공 응답: 200 OK

요청이 성공적으로 처리되었을 때 반환되는 JSON 객체.

#### 3.3.2 Response Body 예시

```json
{
  "analysisStatus": "SUCCESS",
  "coordinate": {
    "latitude": 37.5665,
    "longitude": 126.9780
  },
  "address": {
    "roadAddress": "서울특별시 중구 세종대로 110",
    "jibunAddress": "서울특별시 중구 태평로1가 31"
  },
  "safetyScore": {
    "total": 85,
    "policeDistance": 450,
    "cctvCount": 23,
    "arrestRate": 0.87
  },
  "convenienceScore": {
    "total": 72,
    "amenityDetails": [
      {
        "categoryCode": "CS2",
        "categoryName": "편의점",
        "count": 8,
        "closestDistance": 120,
        "places": [
          {
            "name": "GS25 서소문점",
            "latitude": 37.5658,
            "longitude": 126.9775,
            "distance": 120
          },
          {
            "name": "CU 시청역점",
            "latitude": 37.5662,
            "longitude": 126.9785,
            "distance": 180
          }
        ]
      },
      {
        "categoryCode": "CE7",
        "categoryName": "카페",
        "count": 15,
        "closestDistance": 85,
        "places": [
          {
            "name": "스타벅스 시청역점",
            "latitude": 37.5655,
            "longitude": 126.9781,
            "distance": 85
          }
        ]
      }
    ]
  },
  "overallScore": 78,
  "recommendations": [
    "반경 500m 내 CCTV 23대 설치되어 야간 안전성 우수",
    "지하철역 도보 3분 거리로 대중교통이 편리합니다"
  ],
  "warnings": []
}
```

### 3.4 응답 데이터 구조 상세

#### 3.4.1 최상위 응답 구조 (LocationAnalysisResponseDTO)

| 필드 | 타입 | 설명 |
|------|------|------|
| analysisStatus | String | 분석 결과 상태 코드 (4.1 상태 코드 표 참조) |
| coordinate | Object | 요청된 원본 좌표 정보 |
| address | Object | 변환된 주소 정보 |
| safetyScore | Object | 안전성 분석 결과 |
| convenienceScore | Object | 편의성 분석 상세 결과 |
| overallScore | Integer | 안전성과 편의성을 종합한 최종 점수 (0-100) |
| recommendations | Array | 분석 결과를 바탕으로 생성된 추천 근거 문장 목록 (String 배열) |
| warnings | Array | 데이터 조회 시 발생한 부분적 실패에 대한 경고 메시지 목록 (String 배열) |

#### 3.4.2 좌표 구조 (coordinate)

| 필드 | 타입 | 설명 |
|------|------|------|
| latitude | Double | 위도 |
| longitude | Double | 경도 |

#### 3.4.3 주소 구조 (address)

| 필드 | 타입 | 설명 |
|------|------|------|
| roadAddress | String | 도로명 주소 |
| jibunAddress | String | 지번 주소 |

#### 3.4.4 안전성 점수 구조 (safetyScore)

| 필드 | 타입 | 설명 |
|------|------|------|
| total | Integer | 종합 안전성 점수 (0-100) |
| policeDistance | Integer | 가장 가까운 파출소까지의 거리 (미터) |
| cctvCount | Integer | 반경 내 CCTV 총 개수 |
| arrestRate | Double | 해당 지역의 평점(검거율) (0.0 ~ 1.0) |

#### 3.4.5 편의성 점수 구조 (convenienceScore)

| 필드 | 타입 | 설명 |
|------|------|------|
| total | Integer | 종합 편의성 점수 (0-100) |
| amenityDetails | Array | 카테고리별 편의시설 상세 정보 배열 |

#### 3.4.6 편의시설 상세 구조 (amenityDetails 배열의 각 요소)

| 필드 | 타입 | 설명 |
|------|------|------|
| categoryCode | String | 카테고리 코드 (예: CS2) |
| categoryName | String | 카테고리 이름 (예: 편의점) |
| count | Integer | 해당 카테고리의 총 장소 개수 |
| closestDistance | Integer | 해당 카테고리 내 가장 가까운 장소까지의 거리 (미터) |
| places | Array | 해당 카테고리에 속한 모든 장소의 상세 정보 배열 |

#### 3.4.7 개별 장소 구조 (places 배열의 각 요소)

| 필드 | 타입 | 설명 |
|------|------|------|
| name | String | 장소 이름 (예: GS25 서소문점) |
| latitude | Double | 장소의 위도 |
| longitude | Double | 장소의 경도 |
| distance | Integer | 요청 좌표로부터 해당 장소까지의 거리 (미터) |

---

## 4. 상태 코드 및 예외 처리

### 4.1 분석 상태 코드 (analysisStatus)

HTTP 상태 코드와 별개로, API 응답 본문 내에 분석 결과의 상세한 상태를 나타내는 `analysisStatus` 코드를 포함한다. 클라이언트는 이 코드를 통해 성공, 부분 성공, 실패 여부를 명확히 구분할 수 있다.

| 코드 | 의미 | 설명 |
|------|------|------|
| SUCCESS | 전체 분석 성공 | 모든 데이터 소스로부터 데이터를 성공적으로 조회하여 완전한 리포트를 생성 |
| PARTIAL_SUCCESS | 부분 분석 성공 | 일부 데이터 조회(예: 편의시설 API)에 실패했으나, 가용한 데이터만으로 부분적인 리포트를 생성. warnings 필드에 실패 사유가 포함됨 |
| ANALYSIS_FAILED | 분석 불가 | 핵심 데이터 조회에 실패하여 유의미한 분석 리포트를 생성할 수 없음 |

### 4.2 HTTP 상태 코드

| HTTP 코드 | 상황 | 응답 Body 예시 |
|-----------|------|----------------|
| 200 OK | 요청 성공 (분석 결과 반환) | analysisStatus가 SUCCESS, PARTIAL_SUCCESS, ANALYSIS_FAILED 중 모든 경우에 해당 |
| 400 Bad Request | 요청 파라미터 오류 | `{"errorCode": "INVALID_PARAMETER", "message": "latitude 파라미터는 -90과 90 사이의 값이어야 합니다."}` |
| 500 Internal Server Error | 서버 내부 로직 오류 | `{"errorCode": "SERVER_ERROR", "message": "요청 처리 중 내부 서버 오류가 발생했습니다."}` |

### 4.3 예외 상황(Edge Case) 처리 방안

#### 4.3.1 상황 1: 일부 데이터 조회 실패 (부분 성공)

**발생 조건**

F002 병렬 데이터 조회 과정에서 어떤 데이터 소스 중 하나 이상(예: 외부 편의시설 API)이 타임아웃 등으로 실패한 경우

**서버 처리**

1. 실패한 작업의 예외를 기록하고, 해당 부분의 점수 계산 로직을 건너뛴다 (예: convenienceScore 계산 생략)
2. `analysisStatus: PARTIAL_SUCCESS`로 설정
3. warnings 배열에 사용자 친화적인 메시지를 추가 (예: "편의시설 정보를 불러오지 못해 편의성 점수는 계산되지 않았습니다.")
4. overallScore 와 실패한 부분의 점수(convenienceScore.total 등)는 null 또는 0으로 처리
5. 성공적으로 조회된 데이터(safetyScore 등)는 정상적으로 포함하여 200 OK로 응답

**클라이언트 처리**

warnings 배열의 내용을 사용자에게 alert 등으로 안내하고, null 값은 화면에 '-' 등으로 표시

#### 4.3.2 상황 2: 핵심 데이터 조회 실패 (분석 불가)

**발생 조건**

점수 계산에 필수적인 핵심 데이터(예: CCTV, 파출소 정보) 조회에 모두 실패하여 유의미한 분석이 불가능한 경우

**서버 처리**

1. `analysisStatus: ANALYSIS_FAILED`로 설정
2. recommendations, safetyScore, convenienceScore 등의 분석 결과 필드는 빈 객체 또는 null로 제공
3. warnings 배열에 분석이 불가능했던 메시지를 포함하여 200 OK로 응답

**클라이언트 처리**

"해당 위치의 정보를 분석할 수 없습니다. 다른 위치를 선택해 주세요." 와 같은 안내 메시지를 표시

---

## 5. 실제 구현 코드 기반 상세 명세

### 5.1 컨트롤러 구조 (LocationAnalysisController.java)

#### 5.1.1 클래스 구조

```java
@RestController
@RequestMapping("/api")
@RequiredArgsConstructor
@Slf4j
public class LocationAnalysisController {
    // 구현 내용
}
```

**주요 어노테이션**
- `@RestController`: RESTful 웹 서비스 컨트롤러 선언
- `@RequestMapping("/api")`: 기본 경로 설정
- `@RequiredArgsConstructor`: 의존성 주입
- `@Slf4j`: 로깅 처리

#### 5.1.2 API 구현

```java
@PostMapping("/location-analysis")
public ResponseEntity<LocationAnalysisResponseDTO> getLocationAnalysis(
    @Valid @RequestBody LocationAnalysisRequestDTO request)
{
    LocationAnalysisResponseDTO response = locationAnalysisService.analyzeLocation(request);
    return ResponseEntity.ok(response);
}
```

**주요 특징**
- `@Valid`: LocationAnalysisRequestDTO에 정의된 Bean Validation 규칙(좌표 범위 등)을 자동으로 검증한다.
- `@RequestBody`: HTTP 요청 본문의 JSON 데이터를 LocationAnalysisRequestDTO 객체로 자동 변환한다.

#### 5.1.3 예외 처리

전역 예외 처리는 `GlobalExceptionHandler` 클래스에서 중앙 집중식으로 관리한다.

- `@RestControllerAdvice` 어노테이션으로 클래스 전역의 예외를 중앙에서 처리한다.
- GlobalExceptionHandler에서 예외별로 적절한 HTTP 상태 코드와 에러 메시지를 포함한 JSON 응답을 생성한다.
- `MethodArgumentNotValidException` 발생 시 400 Bad Request 와 함께 `{"errorCode": "INVALID_PARAMETER", ...}` 형태의 응답을 반환한다.
- 그 외 예측하지 못한 서버 오류 발생 시 500 Internal Server Error 와 함께 `{"errorCode": "SERVER_ERROR", ...}` 형태의 응답을 반환한다.

### 5.2 DTO 클래스 구조

#### 5.2.1 요청 DTO (LocationAnalysisRequestDTO)

**주요 어노테이션**
- `@Data`, `@Builder`, `@NoArgsConstructor`, `@AllArgsConstructor`: Lombok을 활용하여 Boilerplate 코드 제거
- `@JsonProperty`: JSON 필드명 형식화 매핑

**필드 및 유효성 검증**
- `latitude`: `@NotNull`, `@Min(-90)`, `@Max(90)`
- `longitude`: `@NotNull`, `@Min(-180)`, `@Max(180)`
- `radius`: `@Min(100)`, `@Max(2000)`

#### 5.2.2 응답 DTO 계층 구조

**최상위 응답 (LocationAnalysisResponseDTO)**

analysisStatus, coordinate, address, safetyScore, convenienceScore, overallScore, recommendations, warnings 필드 포함

**각 복합 객체 DTO 클래스로 분리하여 관리**

- `CoordinateDto`: latitude, longitude
- `AddressDto`: roadAddress, jibunAddress
- `SafetyScoreDto`: total, policeDistance, cctvCount, arrestRate 필드 포함
- `ConvenienceScoreDto`: total, amenityDetails (List<AmenityDetailDto>) 필드 포함
- `AmenityDetailDto`: categoryCode, categoryName, count, closestDistance, places (List<PlaceDto>) 필드 포함
- `PlaceDto`: name, latitude, longitude, distance 필드 포함

### 5.3 서비스 호출 구조

LocationAnalysisController는 구체적 클래스가 아닌 **LocationAnalysisService 인터페이스**에 의존한다.

#### 5.3.1 컨트롤러 내 서비스 호출

```java
@PostMapping("/location-analysis")
public ResponseEntity<LocationAnalysisResponseDTO> getLocationAnalysis(...) {
    LocationAnalysisResponseDTO response = locationAnalysisService.analyzeLocation(request);
    return ResponseEntity.ok(response);
}
```

**설계 의의**

단순 위임. 컨트롤러는 HTTP 처리만 담당하고, 실제 비즈니스 로직은 서비스 계층이 전적으로 수행한다.

### 5.4 로깅 및 모니터링

#### 5.4.1 요청 로깅

- 요청 시작: `log.info("=== 위치 분석 요청 시작 (POST /api/location-analysis) ===");`
- 요청 파라미터: `log.info("Request DTO: {}", request);`
- 완료 로깅: `log.info("위치 분석 요청 처리 완료. Status: {}", response.getAnalysisStatus());`

#### 5.4.2 오류 로깅

- GlobalExceptionHandler 에서 예외 발생 시 전체 스택 트레이스를 ERROR 레벨로 로깅한다.
- F010 명세에 따라, 부분 실패 발생 시 WARN 레벨로 실패한 서비스, 입력값, 상세 로깅 전략을 적용한다.

### 5.5 기타 구현 상세

#### 5.5.1 GlobalExceptionHandler

```java
@RestControllerAdvice
public class GlobalExceptionHandler {
    @ExceptionHandler(MethodArgumentNotValidException.class)
    // 400 예외 처리
    
    @ExceptionHandler(Exception.class)
    // 500 예외 처리
}
```

#### 5.5.2 Health Check

- **엔드포인트**: GET /api/health
- **응답**: "OK" (String)
- **목적**: 로드밸런서의 Health Check 용도로 사용한다.

---

## 6. 비즈니스 기능 구현 명세서

### 6.1 아키텍처 개요

본 시스템은 사용자에게 빠른 응답 속도를 제공하고 서버 자원을 효율적으로 사용하기 위해, **실시간 서비스**와 **배치 데이터 처리 프로세스**를 명확히 분리하여 시스템의 응답성과 안정성을 동시에 확보한다.

#### 6.1.1 배치 처리 (데이터 사전 처리 및 그리드 인덱싱)

주기적으로 (예: 매일 새벽 또는 데이터 변경 시) 실행되는 배치 프로세스는:

1. **지오해시(Geohash) ID 사전 계산**: CCTV, 경찰서 등 모든 위치 기반 데이터에 대해 지오해시 ID를 사전에 계산하여 geohash_id 컬럼에 저장하고, 해당 컬럼에 B-Tree 인덱스를 생성한다.
2. 이 과정은 실시간 서비스에서 발생할 수 있는 비싼 공간 쿼리를 회피하고, 빠른 인덱스 기반 조회(F008)을 가능하게 한다.

#### 6.1.2 실시간 서비스 처리 (사용자 요청 시)

사용자의 `POST /api/location-analysis` 요청을 처리하는 API 서비스이다. 이 서비스는 성능 극대화를 위해, 사전에 배치 처리로 통해 인덱싱된 데이터만을 사용하여 동적 조회를 최소화하고, B-Tree 인덱스를 활용한 빠른 조회와 그리드 기반 캐싱(F008)을 통해 극적으로 빠른 분석 결과 제공에 최적화된 구조를 가진다.

### 6.2 배치 데이터 처리 (ETL Process)

#### 6.2.1 구현 클래스

```
com.wherehouse.batch.GeohashIndexingEtlProcessor
```

**클래스 어노테이션**
- `@Component`
- `@RequiredArgsConstructor`
- `@Slf4j`

**실행 주기**
- `@Scheduled(cron = "0 0 4 * * ?")` - 매일 새벽 4시에 실행, 또는 수동 실행 엔드포인트 제공

#### 6.2.2 핵심 역할

원본 데이터 테이블(CCTV, POLICE_OFFICE)을 읽어, 지오해시 ID를 추가하고 B-Tree 인덱스를 생성한 별도의 읽기 최적화 테이블(CCTV_GEO, POLICE_OFFICE_GEO)을 생성 및 갱신한다.

#### 6.2.3 의존성 주입

- JdbcTemplate 또는 JPA EntityManager - 대용량 데이터 처리
- GeohashLibrary - 지오해시 계산

#### 6.2.4 ETL 처리 단계

| 기능 ID | 기능명 | 상세 구현 내용 |
|---------|--------|----------------|
| B-01 | ETL 대상 테이블 정의 | 1. 원본 소스 테이블과, 데이터를 적재할 목적지 테이블을 매핑하여 정의<br>- CCTV (Source) → CCTV_GEO (Destination)<br>- POLICE_OFFICE (Source) → POLICE_OFFICE_GEO (Destination) |
| B-02 | 목적 테이블 검증 및 초기화 | 1. 배치 프로세스가 시작되면, 목적 테이블(예: CCTV_GEO)이 존재하는지 데이터베이스 스키마를 통해 검증<br>2. 테이블이 존재할 경우: TRUNCATE TABLE 명령을 실행하여 기존 데이터를 모두 삭제하고, 새로운 데이터를 적재할 준비<br>3. 테이블이 존재하지 않을 경우: 원본 테이블의 모든 컬럼과 geohash_id VARCHAR(12) 컬럼을 포함하는 CREATE TABLE 구문을 실행하여 신규 테이블을 생성 |
| B-03 | 데이터 추출 및 변환 (Extract & Transform) | 1. 원본 테이블(예: CCTV)의 모든 데이터를 일정 단위(예: 10000)로 스트리밍하여 읽어옴<br>2. 읽어온 각 데이터의 위도(LATITUDE), 경도(LONGITUDE)값을 사용하여 지오해시 ID를 계산 |
| B-04 | 데이터 적재 (Load) | 1. B-03에서 변환된 데이터(원본 데이터 + 지오해시 ID)를 목적 테이블(예: CCTV_GEO)에 삽입<br>2. 데이터베이스 부하를 최소화하기 위해 배치 삽입(Batch Insert) 방식을 사용 |
| B-05 | B-Tree 인덱스 생성 | 1. 모든 데이터가 목적 테이블에 적재된 후, geohash_id 컬럼에 B-Tree 인덱스가 존재하는지 검증<br>2. 인덱스가 존재하지 않을 경우, CREATE INDEX 구문을 실행하여 목적 테이블에 인덱스를 생성 |
| B-06 | 처리 결과 로깅 | 1. 모든 작업이 완료되면, 최종 처리 결과를 로그로 기록<br>2. 로그에는 처리 대상 테이블, 총 처리 건수, 테이블 생성/초기화 여부, 인덱스 생성 여부, 총 소요 시간 등이 포함 |

### 6.3 배치 처리 대상 테이블 구조

#### 6.3.1 CCTV 데이터

**원본 테이블: CCTV**

- **목적**: CCTV 위치 원본 데이터를 저장한다.
- **특징**: 데이터의 최초 출처 (Source of Truth) 역할을 하며, 이 테이블의 데이터를 배치 프로세스에 의해 수정되지 않는다.

| 컬럼명 | 데이터 타입 | NULLABLE | 설명 |
|--------|-------------|----------|------|
| NUMBERS | NUMBER | No | CCTV 관리 번호 (PK) |
| ADDRESS | VARCHAR2(255) | Yes | 주소 |
| LATITUDE | NUMBER | No | 위도 |
| LONGITUDE | NUMBER | No | 경도 |
| CAMERACOUNT | NUMBER | Yes | 카메라 대수 |

**목적 테이블: CCTV_GEO**

- **목적**: 실시간 서비스에서 빠른 조회를 위해 지오해시 인덱싱이 적용된 CCTV 데이터를 저장한다.
- **특징**: 배치 프로세스에 의해 주기적으로 전체 데이터가 삭제(TRUNCATE)되고 재삽입(INSERT)된다.

| 컬럼명 | 데이터 타입 | NULLABLE | 설명 |
|--------|-------------|----------|------|
| NUMBERS | NUMBER | No | CCTV 관리 번호 (PK) |
| ADDRESS | VARCHAR2(255) | Yes | 주소 |
| LATITUDE | NUMBER | No | 위도 |
| LONGITUDE | NUMBER | No | 경도 |
| CAMERACOUNT | NUMBER | Yes | 카메라 대수 |
| geohash_id | VARCHAR2(12) | No | 계산된 지오해시 ID |

※ geohash_id 컬럼 값은 기반으로 B-Tree 인덱스가 생성되어 탐색에 사용된다.

#### 6.3.2 경찰서 데이터

**원본 테이블: POLICE_OFFICE**

- **목적**: 경찰서 위치 원본 데이터를 저장한다.
- **특징**: 데이터의 최초 출처 (Source of Truth) 역할을 하며, 이 테이블은 배치 프로세스에 의해 수정되지 않는다.

| 컬럼명 | 데이터 타입 | NULLABLE | 설명 |
|--------|-------------|----------|------|
| ADDRESS | VARCHAR2(255) | No | 주소 (PK) |
| LATITUDE | NUMBER | No | 위도 |
| LONGITUDE | NUMBER | No | 경도 |

**목적 테이블: POLICE_OFFICE_GEO**

- **목적**: 실시간 서비스에서 빠른 조회를 위해 지오해시 인덱싱이 적용된 경찰서 데이터를 저장한다.
- **특징**: 배치 프로세스에 의해 주기적으로 전체 데이터가 삭제(TRUNCATE)되고 재삽입(INSERT)된다.

| 컬럼명 | 데이터 타입 | NULLABLE | 설명 |
|--------|-------------|----------|------|
| ADDRESS | VARCHAR2(255) | No | 주소 (PK) |
| LATITUDE | NUMBER | No | 위도 |
| LONGITUDE | NUMBER | No | 경도 |
| geohash_id | VARCHAR2(12) | No | 계산된 지오해시 ID |

※ geohash_id 컬럼 값은 기반으로 B-Tree 인덱스가 생성되어 탐색에 사용된다.

### 6.4 실시간 서비스 (Real-time Service)

#### 6.4.1 구현 위치

```
LocationAnalysisServiceImpl.java
```

F001 ~ F010 기능 요구사항의 실제 구현부

#### 6.4.2 호출 시점

`POST /api/location-analysis` 엔드포인트 요청 시

#### 6.4.3 핵심 역할

사전 처리된 데이터베이스와 캐시, 외부 API를 효율적으로 사용하여 사용자에게 빠른 시간 내에 정확한 위치 분석 리포트를 제공한다. 느린 연산은 최대한 회피하고, 빠른 조회와 캐시에 집중한다.

#### 6.4.4 실시간 서비스 처리 단계

| 기능 ID | 기능명 | 상세 구현 내용 |
|---------|--------|----------------|
| R-01 | '9-Block' 그리드 범위 계산 | 1. 사용자가 요청한 좌표를 기반으로 중심 셀의 지오해시 ID를 계산<br>2. 중심 셀을 포함하여, 주변 8개 셀의 지오해시 ID를 계산 (총 9개)<br>3. 계산된 9개 셀의 지오해시 ID 목록을 다음 단계에 전달<br>※ 이 과정은 사용자의 분석 반경이 여러 격자에 걸쳐 있을 가능성을 해결한다. |
| R-02 | 단계별 캐시 조회 | 1. (1단계 캐시) R-01에서 계산한 중심 셀의 지오해시 ID를 키로 하여, 최종 응답(DTO) 전체가 캐시에 있는지 확인. 캐시 히트 시 즉시 반환하고 절차 종료<br>2. (2단계 캐시) 1단계에서 캐시 미스가 발생하면, 9개의 격자 ID 각각에 대해 개별 데이터(예: CCTV 목록, 파출소 정보)가 캐시에 있는지 확인<br>3. (2단계 캐시 히트) 해당 격자의 데이터는 캐시된 값을 사용<br>4. (2단계 캐시 미스) DB 조회로 전환 (R-03 단계) |
| R-03 | 선택된 데이터베이스 조회 | 1. R-02에서 2단계 캐시 미스가 발생한 격자에 대해서만, _GEO 테이블(CCTV_GEO, POLICE_OFFICE_GEO 등)에서 데이터 조회<br>2. 조회 시, B-Tree 인덱스가 적용된 geohash_id 컬럼으로 빠른 조회를 수행: WHERE geohash_id = '격자_ID'<br>3. DB에서 새로 조회한 데이터는 즉시 해당 격자 ID를 키로 하여 캐시에 저장 |
| R-04 | 외부 API 호출 및 개별 데이터 캐싱 | 1. F005와 F006의 명세에 따라, 외부 API(카카오맵: 주소 변환, 편의시설 등) 호출<br>2. 외부 API 호출은 CompletableFuture를 사용하여 병렬 처리로 실행<br>3. 반경 내 편의시설 조회 시, 9-Block 격자별로 편의시설을 필터링하여 선택한 서비스(예: 주소 변환)는 API 호출 전 캐시 먼저 확인<br>4. 각 격자 데이터를 독립적으로 캐싱(Component 캐시). F008의 2단계 캐시 전략에 기반 |
| R-05 | 데이터 통합, 필터링, 최종 응답 생성 대기 | 1. R-03(내부 DB 조회)과 R-04(외부 API 조회) 의 모든 비동기 작업들이 완료될 때까지 대기하는 것을 첫 단계로 한다<br>2. 모든 데이터(내부 DB, 외부 API 캐시)를 하나의 목록으로 통합<br>3. 이 통합된 9개 격자로부터 수집한 데이터에서, 사용자의 최초 클릭 좌표 기준 정확한 반경(500m) 내에 포함되는 데이터만을 최종 필터링하여 다음 단계로 전달 |
| R-06 | 최종 점수 계산 | 1. R-05에서 최종 필터링된 데이터를 F003과 F004 점수 계산 서비스에 전달<br>2. 점수 계산 시 비즈니스 로직(점수 산출 공식, 가중치 적용 등)에 따라 안전성 점수와 편의성 점수를 산출 |
| R-07 | 최종 응답 생성 및 캐싱 | 1. R-06에서 계산된 점수와 모든 데이터를 조합하여 최종 LocationAnalysisResponseDTO를 생성<br>2. F007: 추천 근거 생성기를 통해 recommendations 배열 생성<br>3. F010: 부분 실패가 있었다면 warnings 필드를 추가<br>4. 완성된 DTO를 다음 요청을 위해 1단계 캐시(중심 격자 ID를 키로)에 저장하여, 사용자에게 반환 |

---

## 7. 주요 구현 특징

본 시스템은 높은 성능과 유지보수성을 동시에 확보하기 위해 다음과 같은 주요 구현 특징을 가진다.

### 7.1 실시간 서비스 (Real-time Service)

#### 7.1.1 단일 통합 API

클라이언트의 모든 분석 요청을 처리하는 단일 엔드포인트(POST /api/location-analysis)를 제공하여, 아키텍처를 단순화하고 클라이언트의 복잡성을 최소화한다.

#### 7.1.2 그리드 기반 검색 (Geohash)

사용자의 임의 좌표 요청을 처리하기 위해, 고정된 행정구역이 아닌 수학적인 '9-Block' 그리드를 동적으로 설정하여 데이터 조회 범위를 한정한다. 이는 F008 그리드 기반 캐싱 전략의 핵심 기반이다.

#### 7.1.3 단계별 캐싱 전략

전체 응답(DTO)을 캐싱하는 1단계 캐시와, 각 그리드 셀의 개별 데이터(CCTV 목록 등)를 캐싱하는 2단계 캐시를 조합하여 캐시 적중률과 데이터 재사용성을 극대화한다.

#### 7.1.4 비동기 병렬 처리

CompletableFuture를 사용하여 내부 데이터베이스 조회와 외부 API 호출을 동시에(병렬적으로) 실행함으로써, 전체 응답 대기 시간을 가장 오래 걸리는 단일 작업 시간에 가깝게 최적화한다.

#### 7.1.5 중앙화된 장애 처리

일부 데이터 소스(예: 외부 API)의 조회 실패가 전체 서비스 중단으로 이어지지 않도록 하는 장애 격리 메커니즘을 구현하고, 문제 추적을 위한 상세 로깅 전략을 적용한다.

### 7.2 배치 데이터 처리 (Batch Process)

#### 7.2.1 데이터 사전 처리

배치 프로세스는 원본 테이블(CCTV, POLICE_OFFICE)을 읽어, 모든 위치 데이터에 **geohash_id**를 사전 계산하여 추가한다.

#### 7.2.2 읽기 최적화 테이블 생성

원본 테이블을 직접 수정하는 대신, geohash_id가 추가된 별도의 읽기 전용 최적화 테이블(CCTV_GEO, POLICE_OFFICE_GEO)을 생성하여 운영 안정성을 확보한다.

#### 7.2.3 B-Tree 인덱싱

생성된 최적화 테이블의 geohash_id 컬럼에 B-Tree 인덱스를 적용하여, 실시간 서비스에서의 빠른 기반 검색 성능을 극대화한다.

### 7.3 데이터 모델 및 비즈니스 로직

#### 7.3.1 데이터 기반 점수 모델

'빅데이터 분석 보고서'에 근거하여 안전성 및 편의성 점수를 산출하는 객관적인 로직을 구현한다.

#### 7.3.2 규칙의 외부화

점수 계산에 사용되는 가중치, 임계값, 추천 근거 메시지 템플릿 등을 별도의 설정 파일로 분리하여, 비즈니스 로직의 유연성과 확장성을 확보한다.

#### 7.3.3 상세 응답 DTO

단순 결과값뿐만 아니라, 클라이언트의 복잡한 UI(개별 마커 표시, 최근접 거리 안내 등)를 완벽하게 지원하기 위한 상세한 데이터 구조를 포함하여 응답한다.

---

## 8. B-Tree 인덱스 활용 아키텍처 설계 명세

### 8.1 아키텍처 목표

수백만 건 이상의 위치 데이터를 대상으로 하는 반복적인 **'근처 찾기'** 연산의 성능을 **데이터 양에 거의 영향을 받지 않는 수준**으로 보장하는 것을 목표로 한다. 이를 위해, 데이터베이스가 가장 효율적으로 처리할 수 있는 B-Tree 인덱스 스캔(Index Scan)을 유도하도록 데이터 모델과 쿼리 전략을 설계한다.

### 8.2 핵심 설계 결정 (상세 명세)

#### 8.2.1 인덱스 대상 컬럼 설계: geohash_id

**데이터 타입:** `VARCHAR2(12)`

**설계 결정:** 지오해시 ID를 저장할 컬럼의 데이터 타입을 가볍 길이 문자열인 `VARCHAR2`로 정의하고, 최대 길이를 `12`로 설정한다.

**기술적 근거:**

1. **타입 선택 (`VARCHAR2`):** 지오해시 알고리즘의 결과물은 영문 소문자와 숫자로 구성된 문자열이므로, `VARCHAR2`가 가장 적합한 데이터 타입이다.

2. **길이 설정 (`12`):** 지오해시는 길이에 따라 정밀도가 결정된다. 본 시스템의 핵심 분석 반경인 500m를 고려할 때, 약 150m x 150m 영역을 나타내는 **7자리 정밀도**가 기본 검색 단위로 가장 적합하다. 그러나 국가 전체 데이터(예: 37cm x 18cm의 초정밀 영역)로 확장될 수 있는 유연성을 확보하기 위해, 향후 더 정밀한 분석 기능(예: 메뉴리 케이싱 레벨에서 유명하게 대응할 수 있는 확장성을 확보한다. 실제 검색에 사용되는 정밀도는 애플리케이션 레이어에서 유연하게 제어할 수 있다.

**NULL 제약 조건:** `NOT NULL`

**설계 결정:** 읍/기 최적화 데이터(`CCTV_GEO` 등)의 `geohash_id` 컬럼에 `NOT NULL` 제약 조건을 명시한다.

**기술적 근거:** 이 컬럼은 실시간 서비스 애플리케이션 검색의 핵심 조건(Key)으로 사용된다. `NULL` 값이 존재할 경우 인덱스 사용에 예외가 발생할 수 있으며, 데이터의 정합성을 보장하기 위해 모든 행(Row)이 유효한 값지 주소를 갖도록 강제한다.

#### 8.2.2 인덱스 종류 선택 및 전략

**인덱스 종류: B-Tree 인덱스**

**설계 결정:** `geohash_id` 컬럼에 표준 **B-Tree 인덱스**를 생성한다.

**기술적 근거 및 대안 분석:**

1. **B-Tree 선택 이유:** 본 시스템의 핵심 쿼리는 `WHERE geohash_id IN (...)` (정확히 일치) 또는 `WHERE geohash_id LIKE 'wydm7%'` (접두사 일치) 형태가 될 것이다. B-Tree 인덱스는 이 두 가지 형태의 조건(Equality and Range Scans)에 대해 매우 효율적으로 동작하므로 가장 적절한 선택이다.

2. **Hash 인덱스와의 비교:** Hash 인덱스는 오직 `=` 연산자를 사용한 정확한 일치 검색에만 특화되어 있다. 향후 더 넓은 지역을 검색하기 위해 `LIKE 'wydm%'` 와 같은 접두사 기반 검색이 필요할 수 있으므로, Hash 인덱스는 본 설계의 요구사항을 충족하지 못한다.

3. **공간 인덱스(Spatial Index)와의 비교:** 본 아키텍처의 핵심 목표는 비용이 높은 2차원 공간 연산을 회피하는 것이다. 공간 인덱스를 직접 사용하는 대신, 지오해시를 통해 공간 문제를 1차원 문자열 문제로 변환(Transform)하고, 이 변환된 문제에 가장 효율적인 B-Tree 인덱스를 사용하는 것이 본 설계의 핵심 전략이다.

**인덱스 고유성(Uniqueness): 비고유 인덱스(Non-Unique Index)**

**설계 결정:** B-Tree 인덱스를 비고유(Non-Unique) 인덱스로 생성한다.

**기술적 근거:** 하나의 지오해시 격자 영역(예: `wydm7p`)안에는 다수의 데이터(예: 여러 개의 CCTV)가 존재할 수 있다. 따라서 `geohash_id` 컬럼의 값은 중복이 허용되어야 하므로, 고유 인덱스가 아닌 비고유 인덱스로 설계한다.

### 8.3 인덱스 스캔 유도 쿼리 전략

#### 8.3.1 정확히 일치 검색 (Equality Scan)

**쿼리 패턴:**
```sql
SELECT * FROM CCTV_GEO WHERE geohash_id = 'wydm7p';
```

**동작 원리:**
- 데이터베이스 옵티마이저는 `geohash_id` 컬럼의 B-Tree 인덱스를 자동으로 사용한다.
- 인덱스의 루트 노드부터 시작하여 이진 탐색(Binary Search) 방식으로 `'wydm7p'` 값을 가진 리프 노드를 찾는다.
- 리프 노드에서 해당 값을 가진 모든 행의 ROWID를 수집한 후, 실제 데이터 블록에서 행을 조회한다.

**최적화 포인트:**
- `geohash_id` 컬럼에 인덱스가 없을 경우, 데이터베이스는 전체 테이블 스캔(Full Table Scan)을 수행하여 성능이 크게 저하된다.
- 인덱스를 사용하면 수백만 건의 데이터에서도 수십 ms 이내로 응답 시간을 보장할 수 있다.

#### 8.3.2 접두사 일치 검색 (Range Scan / LIKE 패턴)

**쿼리 패턴:**
```sql
SELECT * FROM CCTV_GEO WHERE geohash_id LIKE 'wydm7%';
```

**동작 원리:**
- `LIKE 'wydm7%'` 패턴은 B-Tree 인덱스에서 **Range Scan**으로 최적화된다.
- 데이터베이스는 `'wydm7'`로 시작하는 첫 번째 키를 인덱스에서 찾은 후, `'wydm7'`로 시작하지 않는 첫 번째 키를 만날 때까지 순차적으로 인덱스를 스캔한다.

**주의사항:**
- `LIKE '%wydm7'` 또는 `LIKE '%wydm7%'` 와 같이 와일드카드가 접두사에 위치하면 인덱스를 사용할 수 없다.
- 본 시스템의 검색 패턴은 항상 **접두사 일치**이므로, 이러한 문제는 발생하지 않는다.

#### 8.3.3 IN 절을 이용한 다중 격자 검색

**쿼리 패턴:**
```sql
SELECT * FROM CCTV_GEO 
WHERE geohash_id IN ('wydm7p', 'wydm7n', 'wydm7q', ...);
```

**동작 원리:**
- 데이터베이스는 IN 절의 각 값에 대해 개별적으로 인덱스 검색을 수행한다.
- 각 격자 ID마다 효율적으로 해당 데이터를 찾고, 결과를 통합한다.
- 9-Block 그리드 검색에서 최대 9번의 인덱스 스캔이 발생하지만, 각각이 매우 빠르게 수행되므로 전체적으로 여전히 매우 효율적이다.

**최적화 포인트:**
- IN 절의 값 개수가 적을수록(예: 9개) 성능이 우수하다.
- 데이터베이스 옵티마이저는 IN 절을 여러 개의 OR 조건으로 변환하여 처리하며, B-Tree 인덱스를 효율적으로 활용한다.

### 8.4 인덱스 생성 및 관리 전략

#### 8.4.1 인덱스 생성 시점

**배치 프로세스에서 생성:**
- ETL 프로세스(GeohashIndexingEtlProcessor)가 `_GEO` 테이블에 모든 데이터를 적재한 후, `CREATE INDEX` 구문을 실행하여 인덱스를 생성한다.
- 데이터 삽입 후 인덱스를 생성하는 것이 데이터 삽입 중 인덱스를 유지하는 것보다 효율적이다.

**인덱스 생성 DDL 예시:**
```sql
CREATE INDEX idx_cctv_geo_geohash 
ON CCTV_GEO(geohash_id);
```

#### 8.4.2 인덱스 재구성 전략

**주기적 재생성:**
- 배치 프로세스가 실행될 때마다 `_GEO` 테이블을 TRUNCATE하고 데이터를 재삽입한 후, 인덱스를 재생성한다.
- 이는 인덱스의 단편화(Fragmentation)를 방지하고 최적의 성능을 유지한다.

**인덱스 검증:**
- 배치 프로세스는 인덱스 생성 전에 기존 인덱스의 존재 여부를 확인한다.
- 인덱스가 이미 존재하는 경우, DROP 후 재생성하거나 REBUILD 명령을 사용할 수 있다.

#### 8.4.3 인덱스 모니터링

**성능 지표:**
- 인덱스 스캔 시간
- 인덱스 블록 읽기 횟수
- 인덱스 크기 및 단편화 수준

**로깅 전략:**
- 배치 프로세스는 인덱스 생성 완료 시 다음 정보를 로깅한다:
  - 인덱스 이름
  - 대상 테이블
  - 생성 소요 시간
  - 인덱스 크기

### 8.5 예상 성능 및 확장성

#### 8.5.1 성능 예측

**데이터 규모별 예상 응답 시간:**

| 전체 데이터 수 | 인덱스 없이 (Full Scan) | B-Tree 인덱스 사용 |
|----------------|-------------------------|-------------------|
| 10만 건 | ~100ms | ~5ms |
| 100만 건 | ~1초 | ~10ms |
| 1000만 건 | ~10초 | ~15ms |
| 1억 건 | ~100초 | ~20ms |

※ 위 수치는 일반적인 데이터베이스 환경을 가정한 이론적 예측값이다.

#### 8.5.2 확장성 보장

**수평적 확장:**
- 지오해시 기반 설계는 지역별 데이터 샤딩(Sharding)을 용이하게 한다.
- 예: 서울 지역 데이터(`wy`로 시작)와 부산 지역 데이터(`wyd`로 시작)를 별도 데이터베이스에 분산 저장 가능

**수직적 확장:**
- B-Tree 인덱스는 데이터가 증가해도 안정적인 성능을 유지하므로, 단일 데이터베이스 내에서도 수억 건 규모까지 확장 가능하다.

### 8.6 설계 트레이드오프 및 제약사항

#### 8.6.1 장점

1. **예측 가능한 성능:** 데이터 규모와 관계없이 일정한 응답 시간 보장
2. **표준 기술 활용:** 모든 관계형 데이터베이스가 지원하는 B-Tree 인덱스 사용
3. **유지보수 용이성:** 복잡한 공간 인덱스 대신 단순한 문자열 인덱스 사용
4. **확장성:** 샤딩 및 수평 확장이 용이한 구조

#### 8.6.2 단점 및 제약사항

1. **경계 문제:** 격자 경계 근처의 데이터는 여러 격자를 조회해야 하는 오버헤드 발생 (9-Block 전략으로 해결)
2. **저장 공간:** `geohash_id` 컬럼과 인덱스를 위한 추가 저장 공간 필요
3. **배치 의존성:** 인덱스 생성을 위해 배치 프로세스가 정상적으로 실행되어야 함

#### 8.6.3 완화 전략

- **경계 문제:** 9-Block 그리드 검색으로 경계 데이터 누락 방지
- **저장 공간:** 현대 스토리지 비용 대비 성능 향상 효과가 월등히 큼
- **배치 의존성:** 배치 실패 시 알림 및 자동 재시도 메커니즘 구현

---

## 9. 지오해시 정밀도(Precision) 설계 명세

### 9.1 설계 결정

본 시스템의 모든 지오해시 ID는 **7자리**의 정밀도를 기준으로 생성 및 검색한다.

### 9.2 기술적 근거 및 트레이드오프 분석

지오해시의 정밀도(문자열 길이)는 검색 범위의 크기와 직접적인 관련이 있으며, 이는 **검색의 정확성(Relevance)**과 **성능(Performance)** 사이의 중요한 트레이드오프 관계를 가진다. 7자리 정밀도는 본 시스템의 핵심 요구사항인 **500m 반경 분석**에 가장 적적합된 균형점을 제공한다.

#### 9.2.1 정밀도 6자리 검토 (격자 크기: 약 1.2km x 0.6km)

**장점:** `IN` 절에 포함될 ID 개수가 적어 쿼리가 단순해진다.

**치명적 단점:** 단일 격자의 크기가 분석 반경(500m)보다 훨씬 크다. 이 경우, 9-Block 그리드는 수 킬로미터에 달하는 너무 넓은 범위를 포함하게 된다. 이는 분석과 관련 없는 너무 많은 데이터를 데이터베이스에서 조회하게 만들며, 애플리케이션의 최종 반경 필터링 단계에서 대부분의 데이터를 버려야 하는 심각한 비효율을 초래한다.

#### 9.2.2 정밀도 8자리 검토 (격자 크기: 약 38m x 19m)

**장점:** 매우 정밀한 위치 식별이 가능하다.

**치명적 단점:** 격자의 크기가 너무 작아, 500m 반경을 포함하려면 수십~수백 개의 격자 ID가 필요하게 된다. `WHERE geohash_id IN (...)` 절에 과도하게 많은 ID가 포함될 경우, 데이터베이스의 인덱스 스캔 효율이 저하될 수 있으며 쿼리 자체가 너무 길고 복잡해진다.

#### 9.2.3 정밀도 7자리 선택 (격자 크기: 약 150m x 150m)

**최적의 균형:** 7자리 정밀도는 **'도시의 한 블록'** 또는 **'도보 1-2분 거리'**에 해당하는 인간적인 척도와 가장 유사하다.

**'9-Block' 그리드와의 시너지:** 7자리 격자 9개로 구성된 3x3 그리드는 대략 450m x 450m 크기의 정사각형 영역을 형성한다. 이 영역은 최종적으로 필요한 500m 반경의 원형 영역과 매우 근사하여, 불필요한 데이터의 조회를 최소화하면서도 필요한 데이터는 대부분 포함하는 가장 효율적인 1차 필터링 역할을 수행한다.

**결론:** 7자리 정밀도는 **'검색 대상 격자의 수(9개)'**와 **'조회된 데이터의 관련성'** 사이에서 최적의 균형을 이루는 설계 결정이다.

---

## 10. 점수 산출 상세 로직

본 로직은 기능 F003 (안전성 점수 계산)과 F004 (편의성 점수 계산)의 상세 실행 계획이다.

### 10.1 1단계: 개별 항목 점수화 (0~100점 척도 정규화)

각기 다른 단위(미터, 개수)를 가진 원본 데이터들을, 비교 가능한 0~100점 척도의 점수로 변환(정규화)한다.

#### 10.1.1 안전성 항목

**파출소 거리 점수:**

```
거리 점수 = 100 - ( (현재 거리 - 최소 거리) / (최대 거리 - 최소 거리) * 100 )
```

- 거리가 가까울수록 높은 점수를 받도록 역산 처리한다.
- 최소/최대 거리는 분석 보고서 또는 통계적 분포(예: IQR)에 기반하여 설정한다.

**CCTV 개수 점수:**

```
CCTV 점수 = ( min(현재 개수, 최대 임계값) / 최대 임계값 ) * 100
```

- '많을수록 좋다'는 가치를 반영하며, 일정 개수(최대 임계값, 예: 50개)를 초과하면 가치가 포화되는 것을 모델링한다.

**검거율 점수:**

```
검거율 점수 = 검거율 * 100
```

- '빅데이터 분석 보고서'에서 산출된 0.0 ~ 1.0 사이의 검거율(평점)을 100점 만점으로 변환한다.

#### 10.1.2 편의성 항목

**카테고리별 점수:** '4조_1팀 빅데이터 분석 보고서'에서 제시된 중요 점수 산출 공식을 기반으로 각 카테고리(편의점, 카페, 음식점 등)의 점수를 계산한다.

```
카테고리 점수 = (정규화된 개수 * 가중치) * (최소 개수 중복 보너스)
```

### 10.2 2단계: 종합 점수 산출 (가중치 적용)

정규화된 각 항목 점수에, 비즈니스 중요도에 따른 가중치를 적용하여 최종 종합 점수를 산출한다.

#### 10.2.1 종합 안전성 점수:

**가중치:** 파출소 거리 60%, CCTV 30%, 검거율 10% (기존 클라이언트 로직 기반)

**산출 공식:**

```
종합 안전성 점수 = (파출소 거리 점수 * 0.6) + (CCTV 점수 * 0.3) + (검거율 점수 * 0.1)
```

#### 10.2.2 종합 편의성 점수:

**가중치:** 각 카테고리별 가중치는 '빅데이터 분석 보고서'의 소비 지출 비중을 근거로 설정한다.

**산출 공식:**

```
종합 편의성 점수 = Σ (각 카테고리 점수)
```

---

## 11. 핵심 기능 상세 명세 (F001 ~ F010)

### 11.1 F001: 통합 API 엔드포인트 / F002: 병렬 데이터 조회 / F005: 외부 API 서버 통합

이 세 가지 기능의 실제 구현은 `LocationAnalysisServiceImpl.java` 클래스 내 `analyzeLocation` 메서드에서 `CompletableFuture`를 사용하여 구현된다.

#### 구현 방식

**F001: 통합 API 엔드포인트**
- 클라이언트 코드(`mouseEvent.js`, `amenity.js`)에 명시된 공식을 기반으로 구체적인 값을 정의한다.

**구현 방식:** `CompletableFuture.supplyAsync()`를 사용하여 각 데이터 조회(파출소, CCTV, 주소 변환, 편의시설) 작업을 병렬로 실행한다.

**통합:** `CompletableFuture.allOf()`를 사용하여 모든 비동기 작업이 완료될 때까지 대기 후, 각 결과를 취합하여 최종 응답 DTO를 조립한다.

**외부 API 호출:** 기존에 `amenity.js`에서 클라이언트가 직접 호출했던 카카오맵 API는, 서버에서 Spring의 `WebClient` (또는 `RestTemplate`)를 사용하여 비동기 방식으로 호출한다.

#### 예시 코드 구조

```java
// LocationAnalysisServiceImpl.java 예시 코드
public LocationAnalysisResponseDTO analyzeLocation(LocationAnalysisRequestDTO request) {
    // F006: 주소 변환 서비스 (비동기)
    CompletableFuture<AddressDto> addressFuture = CompletableFuture.supplyAsync(() -> 
        kakaoApiService.getAddress(request.getLatitude(), request.getLongitude())
    );
    
    // F002: 내부 데이터 병렬 조회 (비동기)
    CompletableFuture<PoliceOfficeVO> policeFuture = CompletableFuture.supplyAsync(() -> 
        policeOfficeRepository.getClosestPO(request.getLatitude(), request.getLongitude())
    );
    CompletableFuture<List<CctvVO>> cctvFuture = CompletableFuture.supplyAsync(() -> 
        cctvRepository.getCctv(request.getLatitude(), request.getLongitude())
    );
    
    // F005: 외부 편의시설 API 병렬 호출 (비동기)
    CompletableFuture<List<AmenityDto>> amenityFuture = CompletableFuture.supplyAsync(() -> 
        kakaoApiService.getAmenities(request.getLatitude(), request.getLongitude())
    );
    
    // 모든 비동기 작업이 완료될 때까지 대기
    CompletableFuture.allOf(addressFuture, policeFuture, cctvFuture, amenityFuture);
    
    // 결과 취합 및 점수 계산 로직...
}
```

#### 11.1.1 F005: 외부 API 연동 상세 (카카오맵 API)

**정확한 엔드포인트 URL:**

- **편의시설 검색:** `https://dapi.kakao.com/v2/local/search/category.json`
- **주소 변환:** `https://dapi.kakao.com/v2/local/geo/coord2address.json`

**인증 방법:**

HTTP Authorization 헤더에 REST API 키를 포함하여 요청한다.

**형식:** `Authorization: KakaoAK ${REST_API_KEY}`

**요청/응답 형식:**

- **요청:** URL 쿼리 파라미터(Query Parameter)를 사용한다.
  - **편의시설 검색 예시:** `GET /v2/local/search/category.json?category_group_code=CS2&x=127.0277&y=37.4980&radius=500`
- **응답:** JSON 형식으로, 응답 데이터는 `documents` 배열 필드에 포함된다.

**에러 핸들링 방법:**

- HTTP 상태 코드로 1차적인 실패를 확인한다 (예: `400 Bad Request`, `401 Unauthorized`).
- 정상 응답(200 OK)이 아닌 경우, 응답 본문의 JSON 객체에 포함된 `errorType`과 `message` 필드를 파싱하여 예외 처리를 수행한다.

---

### 11.2 F003: 안전성 점수 계산 서비스 / F004: 편의성 점수 계산 서비스

클라이언트 코드(`mouseEvent.js`, `amenity.js`)에 명시된 공식을 기반으로 구체적인 값을 정의한다.

#### 11.2.1 F003: 안전성 점수

**파출소 거리 점수 (`distScore`):**

```
result < 1000m: (1 / Math.log(result + 150)) / 0.2
1000m <= result < 1743m: (1 / Math.log(result - 850)) / 0.5
result >= 1743m: (1 / Math.log(result - 1700))
```

**CCTV 개수 점수 (`cctvScore`):**
- **최대 임계값: 300개**
- **공식:** `Math.min(CCTV 개수 / 300, 1)`

**최종 안전성 점수:**

```
(distScore * 60) + (cctvScore * 30) + (arrestRate * 10)
```

#### 11.2.2 F004: 편의성 점수

**카테고리별 가중치:** `amenity.js`에 정의된 값을 따른다.

- **지하철역(SW8), 편의점(CS2), 음식점(FD6), 카페(CE7), 대형마트(MT1), 은행(BK9): 10점**
- **공공기관(PO3): 6점**
- **문화시설(CT1), 병원(HP8), 약국(PM9) 등 나머지: 4점 또는 2점**

**점수 계산 공식:** 

```
점수 += (편의시설 개수 / 15) * 카테고리_가중치
```

**최소 개수 보너스:** 카테고리별로 정의된 `minCount`를 초과할 경우, 해당 `minCount` 만큼 보너스 점수를 부여한다.

#### 11.2.3 종합 점수 계산 (overallScore)

**계산 방식:**

기존 클라이언트 코드(`mouseEvent.js`)의 `(results[0]+results[1])/2` 로직을 그대로 따른다.

```
overallScore = (안전성 점수 + 편의성 점수) / 2
```

**안전성 점수와 편의성 점수를 50:50 비율로 결합**하여 종합 점수를 산출한다.

**설계 참고:** 이 비율은 향후 변경될 가능성이 있으므로, `application.yml` 설정 파일에 외부화하는 것을 권장한다.

```yaml
# application.yml
scores:
  weights:
    safety: 0.5
    convenience: 0.5
```

---

### 11.3 F007: 추천 근거 생성기

점수 계산 로직과 연동하여, 특정 조건을 충족할 때 생성될 메시지 템플릿을 명시한다.

| 조건 | 생성 메시지 템플릿 |
|------|-------------------|
| `safetyScore.policeDistance < 500` | "가장 가까운 파출소까지 **{policeDistance}m**로 치안 접근성이 양호합니다." |
| `safetyScore.cctvCount > 20` | "반경 500m 내 CCTV가 **{cctvCount}대** 설치되어 야간 안전성이 우수합니다." |
| `convenienceScore` 내 지하철역(SW8) 데이터 존재 | "가장 가까운 지하철역까지 **{distance / 80}분** 거리로 대중교통이 편리합니다." (도보 속도 80m/분 기준) |
| `convenienceScore` 내 편의점(CS2) 개수 > 5 | "주변에 **{count}개**의 편의점이 있어 생활 편의성이 높습니다." |

---

### 11.4 F008: 그리드 기반 응답 캐싱

캐시의 TTL(Time To Live)과 키 구조를 구체적으로 정의한다.

#### 11.4.1 1단계 캐시 (최종 응답 DTO 캐싱)

**TTL: 5분.** 사용자가 동일 지역을 반복적으로 클릭하는 짧은 시간 내의 요청에 대응한다.

**키 구조:** `"dto:" + 7자리 정밀도 지오해시 ID` (예: `"dto:wydm7p1"`)

#### 11.4.2 2단계 캐시 (개별 데이터 캐싱)

**TTL: 24시간.** CCTV, 파출소 등 공공 데이터는 자주 변경되지 않으므로 캐시 유효기간을 길게 설정한다.

**키 구조:** `"data:" + 7자리 정밀도 지오해시 ID + ":" + 데이터 종류` (예: `"data:wydm7p1:cctv"`)

---

## 12. 구현 기술 스택 및 설정

### 12.1 기술 스택

#### 12.1.1 Spring Boot 버전: 3.1.x (Java 17 기반)

**선정 이유:** 현재 널리 사용되는 안정적인 Long-Term Support(LTS) 버전으로, 안정성과 기술 지원 측면에서 가장 표준적인 선택입니다.

#### 12.1.2 캐시 구현체: Caffeine

**선정 이유:** 분산 설치가 필요 없는 Java 기반의 고성능 로컬 캐시입니다. Redis와 같은 외부 캐시 서버는 분산 환경에서는 유리하지만, 현재 단일 서버 아키텍처에서는 Caffeine을 사용하는 것이 설정이 간단하고 매우 빠릅니다.

#### 12.1.3 지오해시 라이브러리: ch.hsr.geohash.GeoHash

**선정 이유:** Java 진영에서 가장 널리 사용되고 검증된 지오해시 라이브러리입니다.

#### 12.1.4 데이터베이스: Oracle (또는 PostgreSQL)

**선정 이유:** 
- **Oracle**: 현재 프로젝트에서 사용 중인 엔터프라이즈급 관계형 데이터베이스이며, 공간 쿼리 기반 쿼리 코드를 위해 공간 데이터를 처리하는 확장 기능인 **PostGIS**와의 연계가 용이합니다.
- **PostgreSQL**: 오픈소스 대안으로, PostGIS를 통해 공간 데이터 처리가 가능합니다.

**본 프로젝트는 Oracle을 사용합니다.**

### 12.2 설정값 명세 (application.yml 기반)

#### 12.2.1 데이터베이스 연결 정보

```yaml
spring:
  datasource:
    driver-class-name: oracle.jdbc.OracleDriver
    url: jdbc:oracle:thin:@127.0.0.1:1521:xe
    username: SCOTT
    password: tiger
    hikari:
      connection-timeout: 30000  # 30초
```

**근거:** `application.yml` 파일 내 `spring.datasource.driver-class-name`이 `oracle.jdbc.OracleDriver`로 명시되어 있습니다.

#### 12.2.2 API 타임아웃 설정

**제공된 설정:**
- 제공된 `application.yml` 파일에는 외부 API(카카오맵) 호출을 위한 전용 타임아웃 설정이 명시되어 있지 않습니다.

**해결 방안:**
- 이러한 설정은 보통 `.yml` 파일이 아니면, `WebClient` 또는 `RestTemplate` Bean을 생성하는 Java 설정 클래스에서 직접 구성합니다.
- **권장 설정:** 연결 타임아웃 3초, 읽기 타임아웃 5초의 타임아웃을 코드 레벨에서 명시적으로 설정하는 것을 권장합니다.

```java
@Bean
public WebClient webClient() {
    return WebClient.builder()
        .clientConnector(new ReactorClientHttpConnector(
            HttpClient.create()
                .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000)
                .responseTimeout(Duration.ofSeconds(5))
        ))
        .build();
}
```

#### 12.2.3 기타 주요 설정

**서버 포트:**
```yaml
server:
  port: 8185
```

**Context Path:**
```yaml
server:
  servlet:
    context-path: /wherehouse
```

**JSON 네이밍 전략:**
```yaml
spring:
  jackson:
    property-naming-strategy: SNAKE_CASE
```

Java의 `camelCase` 필드명을 JSON의 `snake_case`로 자동 변환하도록 설정되어 있습니다. 이는 API 응답 DTO 설계 시 반영되어야 합니다.

**JPA/Hibernate 설정:**
```yaml
spring:
  jpa:
    hibernate:
      ddl-auto: none
    properties:
      hibernate:
        dialect: org.hibernate.dialect.OracleDialect
```

`ddl-auto`는 `none`으로 설정되어 있으며, Oracle 전용 `OracleDialect`를 사용합니다.

---

## 13. 부록

### 8.1 용어 정의

| 용어 | 정의 |
|------|------|
| **DTO (Data Transfer Object)** | 계층 간 데이터 전송을 위한 객체 |
| **CompletableFuture** | Java의 비동기 프로그래밍을 위한 클래스 |
| **Geohash** | 지리적 좌표를 문자열로 인코딩하는 알고리즘 |
| **B-Tree Index** | 데이터베이스 검색 성능을 향상시키는 인덱스 구조 |
| **Fault Isolation** | 부분 장애가 전체 시스템에 전파되지 않도록 격리하는 설계 기법 |
| **TTL (Time To Live)** | 캐시 데이터의 유효 기간 |
| **ETL (Extract, Transform, Load)** | 데이터를 추출, 변환, 적재하는 프로세스 |
| **9-Block Grid** | 중심 격자와 주변 8개 격자를 포함한 총 9개의 격자 영역 |

---

본 문서는 '상세 지도 기반 정보 제공 서비스'의 백엔드 중심 아키텍처 전환 프로젝트에서 구현해야 할 API 명세 및 비즈니스 로직 구현 방안에 대한 완전한 기술 명세를 제공한다.

**문서 작성 완료일:** 2025년 10월 10일  

---

**© 2025 위치 기반 생활 안전·편의 분석 시스템. All rights reserved.**