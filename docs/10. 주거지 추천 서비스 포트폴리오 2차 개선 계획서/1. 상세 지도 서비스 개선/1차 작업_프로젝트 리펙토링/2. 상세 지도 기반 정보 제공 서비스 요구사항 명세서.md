# 상세 지도 기반 정보 제공 서비스 기능 요구사항 명세서

**문서 버전:** 1.0  
**작성일:** 2025-10-10  
**프로젝트명:** 백엔드 중심 아키텍처 전환 프로젝트

---

## 목차

1. [개요](#1-개요)
   - 1.1. 문서 목적
   - 1.2. 역할 분담 설계
2. [기능 요구사항 명세](#2-기능-요구사항-명세)
   - F001: 통합 API 엔드포인트
   - F002: 병렬 데이터 조회
   - F003: 안전성 점수 계산 서비스
   - F004: 편의성 점수 계산 서비스
   - F005: 외부 API 서버 통합
   - F006: 주소 변환 서비스
   - F007: 추천 근거 생성기
   - F008: 그리드 기반 응답 캐싱
   - F009: 클라이언트 단순화
   - F010: 중앙화된 장애 처리

---

## 1. 개요

### 1.1. 문서 목적

본 문서는 '상세 지도 기반 정보 제공 서비스'의 백엔드 중심 아키텍처 전환 프로젝트에서 구현해야 할 모든 기능적 요구사항을 상세히 정의한다. 각 기능은 기능 개요, 입출력 데이터 모델, 핵심 처리 로직, 설계 원칙으로 구성되어 개발팀이 명확한 구현 방향을 설정할 수 있도록 한다.

### 1.2. 역할 분담 설계

본 프로젝트는 '관심사의 분리(Separation of Concerns)' 원칙에 따라 두 시스템의 역할을 다음과 같이 명확하게 정의한다.

| 구분 | 클라이언트 (JavaScript)의 역할 | 서버 (Java)의 역할 |
|------|-------------------------------|-------------------|
| **핵심 책임** | 표현 (Presentation) & 사용자 상호작용 (User Interaction) | 데이터 생성 (Data Creation) & 비즈니스 로직 (Business Logic) |
| **데이터 요청** | - 사용자의 지도 클릭 이벤트를 감지 - 단일 통합 API(`POST /api/location-analysis`)에 좌표 정보만 담아 한 번 요청 | - 클라이언트의 단일 요청 수신 - 요청 데이터(좌표)의 유효성 검증 |
| **데이터 처리 및 계산** | - (수행 안 함) - 데이터 조합, 점수 계산 등 모든 비즈니스 로직을 서버에 위임함 | - (모든 책임 수행) - `CompletableFuture`를 사용한 병렬 데이터 조회 (DB, 외부 API) - 안전성/편의성 점수 계산 - 추천 근거 메시지 생성 |
| **데이터 응답** | - 서버로부터 모든 계산이 완료된 단일 `LocationAnalysisResponseDTO` 객체를 수신 | - 처리된 모든 결과를 클라이언트에 단일 완성된 형태로 클라이언트에 응답 |
| **데이터 표시 (시각화)** | - (모든 책임 수행) - 수신한 DTO의 데이터를 각 UI 요소(텍스트, 그래프, 그래프 너비)에 바로 매핑 도 위에 마커, 서클 등 시각적 요소를 렌더링 | - (수행 안 함) - 데이터 제공만 하며 화면에 어떻게 표시할지는 클라이언트가 전적으로 결정 |

**설계 의의:** 이러한 명확한 역할 분리는 향후 모바일 앱이나 다른 플랫폼에서도 동일한 서버 API를 재사용할 수 있는 확장 가능한 아키텍처를 구축하며, 비즈니스 로직의 변경이 클라이언트 배포 없이 서버 측에서만 처리될 수 있는 유연성을 제공한다.

---

## 2. 기능 요구사항 명세

### F001 - 통합 API 엔드포인트

#### 1. 기능 개요

클라이언트가 요청한 특정 위치에 대한 모든 분석 정보를 제공하는 단일 API 엔드포인트. 서버는 이 요청을 받아 내부적으로 필요한 모든 데이터 조회, 조합, 계산을 수행한 후, 완성된 형태의 단일 데이터 객체를 클라이언트에 반환한다.

#### 2. 요청 로직 (Request Logic)

클라이언트는 분석을 원하는 위치의 **핵심 지리 정보(위도, 경도)**와 **분석 범위(반경)**를 포함하는 표준화된 요청 데이터 구조를 생성하여 서버에 전달한다. 이는 요청의 목적과 범위를 명확히 정의하고 서버가 수집하여 분석해야 할 분석 작업의 경계를 설정한다.

#### 3. 응답 로직 (Response Logic)

서버는 모든 분석 과정이 완료된 **완결된 형태의 정보 집합(Complete Information Set)**을 응답 데이터 구조에 담아 반환한다. 이 응답 데이터는 클라이언트가 별도의 연산이나 조합 없이 즉시 화면에 표현할 수 있도록 **최종 분석 결과(점수, 추천 근거)**와 **이를 뒷받침하는 원본 데이터(상세 지표)**를 모두 포함한다. 또한 데이터 처리 과정에서 발생한 **부분적인 정보 누락(경고)**까지 포함하여 응답의 무결성을 보장한다.

#### 4. 서버 처리 로직 (Server Processing Logic)

서버의 처리 절차는 다음과 같은 논리적 단계로 구성된다.

**4.1. 데이터 수집 (Data Collection)**

요청이 수신되면 서버는 정의된 모든 데이터 소스(내부 데이터베이스, 외부 API)로부터 필요한 정보를 병렬적(Parallel)으로 수집하는 절차에 착수한다. 이는 각 데이터 소스의 응답 지연이 전체 시스템의 대기 시간에 미치는 영향을 최소화하기 위한 동시성(Concurrency) 처리 원칙에 기반한다.

**4.2. 데이터 정제 및 분석 (Data Refinement & Analysis)**

수집된 다양한 형태의 원본 데이터는 시스템 정의된 비즈니스 규칙에 따라 정제되고 안전성 및 편의성이라는 두 가지 핵심 속성을 기준으로 분석된다. 이 단계에서 각 데이터는 사용자의 의사결정을 돕는 유의미하고 정량적인 지표로 변환된다.

**4.3. 종합 점수 산출 (Comprehensive Score Calculation)**

정량화된 지표들은 가중치 기반의 평가 모델을 통해 종합적인 점수(안전성, 편의성, 종합)로 산출된다. 이 모델은 비즈니스 요구사항에 따라 각 지표의 중요도를 유연하게 조정할 수 있는 구조를 갖는다.

**4.4. 응답 생성 및 최적화 (Response Generation & Optimization)**

최종적으로 산출된 점수와 분석 근거, 원본 데이터를 모두 포함하는 표준 응답 객체를 생성한다. 또한 전체 처리 과정의 무결성을 보장하는 한편 개정 전략을 적용하여 동일 요청에 대한 응답 속도를 최적화하고 시스템 부하를 경감시킨다.

---

### F002 - 병렬 데이터 조회

#### 1. 기능 개요

**병렬 데이터 조회**는 'F001: 통합 API 엔드포인트'의 핵심 처리 과정 중 하나로, 단일 사용자 요청을 처리하기 위해 필요한 다수의 이질(異質) 데이터 소스로부터 정보를 동시에(Concurrently) 수집하는 기능이다. 순차적 데이터 조회와 야기하는 대기 시간(Latency)을 최소화하고, 시스템의 전체 응답 속도와 처리 효율성을 극대화하는 것을 목표로 한다.

#### 2. 논리적 흐름 (Logical Flow)

본 기능의 논리적 흐름은 **분해(Decomposition) → 동시 실행(Concurrent Execution) → 통합(Aggregation)**의 3단계로 구성된다.

**2.1. 작업 분해 (Task Decomposition)**

통합 API가 수신한 단일 요청 (좌표, 물서, 반경)은 내부적으로 상호 의존성이 없는 여러 개의 하위 데이터 조회 작업으로 분해된다. 각 작업은 독립된 데이터 소스를 대상으로 한다.

- **Task A:** 내부 데이터베이스(DB)로부터 최단 거리 파출소 정보 조회
- **Task B:** 내부 DB로부터 반경 내 CCTV 목록 및 통계 조회
- **Task C:** 내부 DB로부터 지역 평점(검거율) 정보 조회
- **Task D:** 외부 API로부터 최표-주소 변환(Geocoding) 및 편의시설 정보 조회

**2.2. 동시 실행 (Concurrent Execution)**

분해된 하위 작업들은 전통적인 순차 방식이 아닌, 비차단(Non-Blocking) 방식으로 동시에 실행된다. 이는 특정 작업의 외부 I/O(네트워크, 디스크)로 인한 대기 상태에 빠지더라도, 다른 작업의 실행을 막지 않음을 의미한다. 이를 통해 시스템은 가용한 자원(CPU Core)을 최대한 활용하여 여러 작업을 병렬(Parallel)로 처리하게 되며, 전체 데이터 수집 시간은 개별 작업 시간의 총합이 아닌, 가장 오래 걸리는 단일 작업의 시간에 근접하게 된다.

**2.3. 결과 통합 및 장애 격리 (Result Aggregation & Fault Isolation)**

모든 동시 실행 작업이 완료되면, 각 작업의 결과는 하나의 통합된 데이터셋으로 취합된다. 이 과정에서는 장애 격리(Fault Isolation) 원칙이 적용된다. 즉, 여러 데이터 소스 중 하나(예: 외부 편의시설 API)에서 장애가 발생하여 조회가 실패하더라도, 전체 요청이 실패로 처리되지 않는다. 시스템은 성공적으로 조회된 데이터만이라도 우선 취합하고, 실패한 부분에 대해서는 응답 객체 내의 경고(Warning) 메시지를 포함하여 데이터의 무결성을 보장적으로 보장한다.

#### 3. 핵심 원칙

- **비차단(Non-Blocking) I/O:** 시스템의 스레드가 I/O 작업을 기다리며 유휴 상태에 빠지지 않고, 자원 활용률을 극대화한다.
- **시간 효율성:** 전체 작업 시간을 단일 최장 작업 시간에 수렴시켜, 사용자에게 빠른 응답성을 제공한다.
- **시스템 안정성 및 복원력(Resilience):** 부분적인 장애가 전체 시스템의 실패로 이어지지 않도록 하여, 보다 안정적이고 예측 가능한 서비스를 제공한다.

---

### F003 - 안전성 점수 계산 서비스

#### 1. 기능 개요

**안전성 점수 계산 서비스**는 'F002: 병렬 데이터 조회'를 통해 수집된 다양한 형태의 원본 데이터(Raw Data)를 입력받아, 사용자가 직관적으로 이해할 수 있는 단일 **안전성 점수**로 변환하는 핵심 비즈니스 로직이다. 이 서비스는 객관적인 데이터를 기반으로 특정 위치의 안전 수준을 정량화으로 평가하는 역할을 수행한다.

#### 2. 입력 및 출력 데이터 모델

**입력 데이터 (Input Data):** 병렬 조회를 통해 취합된 원본 데이터로, 안전성 평가에 필요한 원본 지표가 없는 원본 데이터셋.

- 최단 거리 파출소 정보 (단위: 미터)
- 반경 내 CCTV 총 개수 (단위: 점수)
- 지역 평점(검거율) 정보 (단위: 0.0 ~ 1.0 사이의 실수)

**출력 데이터 (Output Data):** 최종 계산된 안전성 점수와 그 근거가 되는 상세 지표를 포함하는 구조화된 객체.

- 종합 안전성 점수 (Total Score): 0-100 사이의 정규화된 최종 점수.
- 상세 지표 (Detailed Metrics): 점수 산출에 사용된 원본 데이터(거리, CCTV 개수 등)를 함께 포함하여, 클라이언트가 점수의 근거를 사용자에게 제시할 수 있도록 한다.

#### 3. 핵심 처리 로직

본 서비스의 처리 로직은 **정규화(Normalization) → 가중치 적용(Weight Application) → 종합(Aggregation)**의 3단계로 구성된다.

**3.1. 지표별 정규화 (Metric-specific Normalization)**

서로 다른 단위와 스케일을 가진 원본 데이터들을 일관된 점수 체계(0~1의 척도)로 변환하는 과정이다.

- **거리 데이터:** 단순 거리는 비선형적 가치를 지닌다 (100m와 200m의 차이는 2100m와 2200m의 차이보다 훨씬 크다). 따라서, 로그 함수 기반의 변환 모델을 적용하여 거리가 가까울수록 높은 점수를 부여한다.
  - `if (거리 < 1000m) 점수 = (1 / log(거리 + 150)) / 0.2`
  - `else if (거리 < 1743m) 점수 = (1 / log(거리 - 850)) / 0.5`
  - `else 점수 = (1 / log(거리 - 1700))`

- **CCTV 개수 데이터:** 사전에 정의된 임계값(예: 300대)를 기준으로 정규화한다. CCTV 개수가 임계값을 초과하면, 도달로 간주하여 추가 점수를 제한한다.
  - `점수 = min(CCTV개수 / 300, 1.0)`

- **지역 평점 데이터:** 이미 0과 1 사이의 값으로 벡터의 정규화 없이 직접 점수로 활용한다.

**3.2. 가중치 적용 (Weight Application)**

정규화된 각 지표 점수에 비즈니스적 중요도에 따른 가중치를 곱하여 최종 점수에 미치는 영향력을 조절한다. 예를 들어, 파출소와의 거리가 가장 중요하다고 판단되면 파출소의 거리 점수가 다른 점수보다 종합 점수에 많이 반영된다. 이 가중치는 소스 코드에 하드코딩하지 않고, 별도 설정 파일(예: YAML)로 외부화하여 비즈니스 요구사항 변화에 유연하게 대응할 수 있도록 한다.

- 예: 거리 60%, CCTV 30%, 검거율 10%
- `종합_안전성_점수 = (거리점수 × 0.6) + (CCTV점수 × 0.3) + (검거율점수 × 0.1)`

**3.3. 종합 점수 산출 (Final Score Aggregation)**

가중치가 적용된 모든 지표 점수를 합산하여 초기 종합 점수를 산출한다. 최종적으로 이 점수를 사용자가 이해하기 쉬운 0-100 척도로 변환하여 최종 '안전성 점수'를 완성한다.

#### 4. 설계 원칙

- **전략 패턴(Strategy Pattern) 적용:** 각 지표(거리, CCTV, 검거율)의 점수 계산 로직을 독립된 '전략' 객체로 캡슐화한다. 이를 통해 향후 새로운 평가 기준(예: 가로등 밀도)을 추가하거나 기존 로직을 변경할 때, 다른 계산 로직에 영향을 주지 않고 해당 전략만 수정하면 되는 유연성을 확보한다. 이는 단일 책임 원칙(SRP)과 개방-폐쇄 원칙(OCP)을 동시에 충족하는 설계이다.

- **가중치 외부화(Externalization of Weights):** 점수 계산에 사용되는 가중치(60%, 30%, 10% 등)를 소스 코드에 하드코딩하지 않고, 별도의 설정 파일이나 데이터베이스 테이블로 분리하여 관리한다. 이를 통해 서비스 재배포 없이도 비즈니스 요구사항 변경에 따라 신속하게 점수 산출 방식을 신속하게 변경할 수 있는 유연성을 확보한다.

---

### F004 - 편의성 점수 계산 서비스

#### 1. 기능 개요

**편의성 점수 계산 서비스**는 M2세대 1인 가구의 실제 소비 데이터와 라이프스타일 분석에 기반하여, 특정 위치 주변의 편의시설이 실제 생활에 얼마나 유용한지를 정량화하는 서비스이다. 외부 API를 통해 수집된 편의시설 정보를 벡터화하여 분석 결과에 따라 재해석하고, 사용자가 직관적으로 이해할 수 있는 단일 편의성 점수로 변환하는 역할을 수행한다.

#### 2. 입력 및 출력 데이터 모델

**입력 데이터 (Input Data):** F005: 카카오맵 API 서버 통합 기능을 통해 조회된, 특정 반경 내에 위치한 편의시설의 원본 데이터 목록. 각 편의시설 데이터는 카테고리 정보(예: SW8-지하철역, CS2-편의점)를 포함한다.

**출력 데이터 (Output Data):** 최종 계산된 편의성 점수와 그 근거를 포함하는 구조화된 객체.

- 종합 편의성 점수 (Total Score): 0-100 사이의 정규화된 최종 점수.
- 핵심 편의시설 정보 (Key Amenity Info): 가장 중요한 편의시설(예: 가장 가까운 지하철역 정보)을 별도로 포함.
- 상세 지표 (Detailed Metrics): 점수 산출에 사용된 각 지표별 점수를 제시.

#### 3. 핵심 처리 로직

본 서비스의 처리 로직은 **데이터 기반 카테고리 선정 → 정규화 및 가중치 적용 → 종합 점수 산출**의 3단계로 구성된다.

**3.1. 데이터 기반 카테고리 선정**

점수 평가에 사용되는 편의시설의 종류는 임의로 결정되지 않는다. '4조_1팀 박태하의 분석 보고서'에 명시된 M2세대 1인 가구의 실질적 소비패턴 분석 결과를 선별한다. 쓰비츠를 비롯한 '음식/숙박', '식료품', '교통' 등의 실질적 관점의 편의점, 카페, 음식점, 지하철역 등을 핵심 평가 카테고리로 정의한다.

**3.2. 정규화 및 가중치 적용**

각 카테고리별 편의시설 데이터를 보고서의 분석 결과에 따라 정규화하고 가중치를 적용한다.

- **정규화:** 편의점 개수와 같이 지역 간 편차가 연계에 영향을 받는 지표는 먼저 대비 밀도를 고려하여 보정한다.

- **가중치 적용:** 1인 가구의 소비 패턴 분석 결과에 따라, 각 카테고리별 중요도를 반영한 가중치를 적용한다. 예를 들어, 소비 지출 비중이 높은 '음식' 관련 카테고리는 상대적으로 높은 가중치를 부여받는다.
  - 예: 지하철역 10점, 편의점 10점, 음식점 10점, 카페 10점 등

**3.3. 종합 점수 산출 및 상관관계 분석 결과 반영**

모든 카테고리에서 산출된 1차 점수들을 보고서의 최종 종합 점수 산출 공식에 따라 합산한다.

- 기본 점수: `점수 += (편의시설_개수 / 15) × 카테고리_가중치`
- 최소 개수 충족 보너스: `if (편의시설_개수 > 최소개수) 점수 += 보너스`

최종적으로 이 점수를 사용자가 이해하기 쉬운 0-100점 척도로 변환하여 최종 '편의성 점수'를 완성한다. 이 과정에서, M2세대 가구 비율과 약학 영역 상관관계를 보인 편의점, 카페, 음식점 등의 요소가 점수에 유의미하게 기여함을 확인하고, 상관관계가 거의 없는 것으로 나타난 지하철역, 대규모 점포 등의 요소는 보편적인 편의성 지표로서 기능하도록 모델을 설계한다.

#### 4. 설계 원칙

- **데이터 기반 의사결정(Data-Driven Decision-Making):** 편의성 점수를 구성하는 모든 평가 항목, 가중치, 산출 공식은 직관이나 추측이 아닌, 제공된 박태하의 분석 보고서의 통계적 근거에 기반한다. 이는 추상 결과가 객관성과 신뢰성을 담보하는 핵심 원칙이다.

- **모델의 외부화(Externalization of Model):** 점수 계산에 사용되는 복잡한 산출 공식과 각 카테고리별 가중치는 소스 코드로부터 분리된 설정 파일 또는 데이터베이스 테이블로 관리한다. 이를 통해 향후 새로운 분석 결과나 데이터 분석 결과가 도출되었을 때, 서비스 재배포 없이도 평가 모델을 신속하게 업데이트할 수 있는 유연성을 확보한다.

---

### F005 - 외부 API 서버 통합

#### 1. 기능 개요

**외부 API 서버 통합**은 기존에 클라이언트(JavaScript)가 직접 수행하던 제3자 서비스(Third-Party API, 예: 카카오맵 API)와의 통신 책임을 서버로 이전하는 기능이다. 이를 통해 외부 API 키의 보안을 강화하고, 외부 서비스와의 통신을 중앙에서 제어하며, 시스템 전체 아키텍처의 안정성과 유연성을 확보하는 것을 목표로 한다.

#### 2. 핵심 처리 로직

본 서비스의 처리 로직은 **요청 추상화 → 비동기 병렬 호출 → 응답 파싱 및 정제 → 에러 처리 및 장애 격리**의 4단계로 구성된다.

**2.1. 요청 추상화 (Request Abstraction)**

서버는 내부 시스템의 요구사항(예: "특정 좌표의 편의시설 정보 조회")을 외부 API가 이해할 수 있는 기술적인 HTTP 요청 형태로 변환하는 추상화 계층(Abstraction Layer) 역할을 수행한다. 이 과정을 통해 내부 비즈니스 로직은 외부 API의 구체적인 방식(Endpoint URL, 파라미터 등)에 직접적으로 의존하지 않게 된다.

**2.2. 비동기 병렬 호출 (Asynchronous Parallel Calls)**

편의성 점수 산출에 필요한 다수의 카테고리(총 15개) 정보를 얻기 위해, 서버는 각 카테고리에 대한 API 요청을 순차적으로 보내지 않는다. **F002: 병렬 데이터 조회** 원칙에 따라 모든 API 요청을 동시에(Concurrently) 전송한다. 이를 통해 전체 조회 시간은 개별 요청 시간의 총합이 아닌, 가장 오래 걸리는 단일 요청 시간에 근접하게 최적화된다.

**2.3. 응답 파싱 및 정제 (Response Parsing & Refinement)**

서버는 외부 API로부터 수신한 원본 응답 데이터(Raw Response, 예: JSON)를 파싱하여, 시스템 내에서 필요한 핵심 정보(예: 장소명, 카테고리, 거리)만을 추출한다. 이후 이 데이터를 내부 표준 데이터 모델로 변환(정제)하여, 외부 API의 데이터 구조가 내부 시스템에 미치는 영향을 최소화한다.

**2.4. 에러 처리 및 장애 격리 (Error Handling & Fault Isolation)**

외부 API 통신 과정에서 발생할 수 있는 모든 예외 상황(네트워크 오류, 타임아웃, API 키 오류 등)을 중앙에서 처리한다. 일부 카테고리의 API 호출이 실패하더라도, 전체 기능이 중단되지 않고 성공적으로 조회된 데이터만이라도 반환하는 장애 격리 메커니즘을 구현하여 시스템의 안정성을 보장한다.

#### 3. 설계 원칙

- **보안 강화: API 키 은닉(API Key Encapsulation):** 클라이언트 측에 노출될 위험이 있는 모든 외부 API 인증 키를 서버의 환경 변수나 보안 설정 파일 내로 이전하여 완벽히 은닉한다. 이는 외부 서비스의 무단 사용을 방지하는 핵심적인 보안 조치이다.

- **중앙화 및 제어(Centralization & Control):** 모든 외부 API와의 통신이 서버 내의 단일 지점을 통하게 되므로, 향후 요청 로깅, 사용량 모니터링, 캐싱 전략 적용 등을 일괄되고 효율적으로 관리할 수 있는 기반을 마련한다.

- **느슨한 결합(Loose Coupling):** 내부 시스템은 외부 카카오맵 API가 아닌, 우리가 직접 설계한 '외부 API 연동 서비스'에만 의존하게 된다. 이를 통해 향후 카카오맵 API를 다른 지도 서비스 API(예: 네이버 지도)로 교체하더라도, 변경 범위를 해당 서비스 내로 국한시켜 시스템 전체의 유연성과 유지보수성을 극대화한다.

---

### F006 - 주소 변환 서비스

#### 1. 기능 개요

**주소 변환 서비스**는 시스템 내부에서 사용되는 기계 친화적인 지리 데이터(좌표)를 사용자가 이해할 수 있는 인문학적 주소 정보(예: 도로명 주소)로 변환하는 역할 유틸리티 기능이다. 이 서비스는 좌표 기반의 다른 데이터 셋(예: 지역별 평점, 통계 정보)과 연결하고, 사용자에게 명확한 위치 정보를 제공하기 위한 필수적인 가교 역할을 수행한다.

#### 2. 입력 및 출력 데이터 모델

**입력 데이터 (Input Data):** 시스템 내에서 사용되는 표준 지리 좌표 객체.

- 위도 (Latitude)
- 경도 (Longitude)

**출력 데이터 (Output Data):** 다양한 활용 목적을 위해 여러 형식을 포함하는 구조화된 주소 객체.

- 도로명 주소 (Road Name Address)
- 지번 주소 (Lot Number Address)

#### 3. 핵심 처리 로직

본 서비스의 처리 로직은 **외부 지오코딩 API 연동 → 응답 데이터 파싱 및 정제 → 장애 처리 및 폴백 전략**의 3단계로 구성된다.

**3.1. 외부 지오코딩 API 연동 (External Geocoding API Integration)**

본 서비스의 핵심 로직은 외부의 전문적인 지오코딩 API(역방향 지오코딩)를 호출하여 수행된다. 서비스는 내부의 좌표 데이터를 외부 API의 요청 명세에 맞게 변환하여 전달하고, 주소 정보를 반환받는 통신 인터페이스 역할을 담당한다.

**3.2. 응답 데이터 파싱 및 정제 (Response Data Parsing & Refinement)**

외부 API로부터 수신한 복합적인 원본 데이터(Raw Response)에서, 시스템에 필요한 핵심 주소 정보(도로명, 지번 등)만을 선별적으로 추출(Parsing)한다. 이후 이 데이터를 시스템 내부의 표준 주소 모델로 변환(정제)하여, 외부 API의 데이터 구조에 대한 내부 시스템의 의존성을 최소화한다.

**3.3. 장애 처리 및 폴백 전략 (Error Handling & Fallback Strategy)**

외부 API와의 통신은 네트워크 불안정, 서비스 장애 등 다양한 실패 가능성을 내포한다. 본 서비스는 이러한 예외 상황을 처리하는 폴백(Fallback) 전략을 포함한다. 주소 변환에 실패할 경우, 전체 상위 프로세스를 중단하는 대신 "주소 정보 없음"과 같은 대체 데이터를 반환하되, 이는 주소 정보가 없더라도 좌표 기반의 다른 분석(예: 반경 내 CCTV 개수 조회)은 계속 진행될 수 있도록 하여 시스템 전체의 안정성을 보장한다.

#### 4. 설계 원칙

- **서비스 재사용성(Service Reusability):** 주소 변환은 시스템 전반에 걸쳐 반복적으로 요구될 수 있는 기능이므로, 특정 트랜잭션 흐름과 밀접하게 얽힌 특정 서비스가 아닌 범용적인 유틸리티 서비스로 설계된다. 이를 통해 시스템 내 어떤 모듈이든 필요할 때 이 서비스를 독립적으로 호출 가능하다.

- **외부 의존성 격리(Isolation of External Dependencies):** 이 서비스는 외부 카카오맵 API에 대한 의존성을 하나의 층(Corruption Layer) 내부로 캡슐화하여, 시스템의 다른 부분들은 카카오맵 API의 존재를 인지할 필요 없이 오직 이 서비스를 통한 변환 요청만을 보낸다. 이를 통해 향후 지도 서비스 제공자를 변경하더라도, 수정 범위를 이 서비스 내로 한정시켜 유지보수 비용을 최소화한다.

- **성능 최적화(Performance Optimization):** 주소 변환은 네트워크 호출을 수반하는 상대적으로 비용이 높은 작업이므로, 캐싱(Caching) 전략을 적극적으로 적용한다. 동일하거나 인접한 좌표에 대한 반복적인 변환 요청이 발생할 경우, 외부 API를 재호출하는 대신 캐시된 결과를 즉시 반환하여 응답 속도를 향상시키고 외부 API 호출 횟수를 줄인다.

---

### F007 - 추천 근거 생성기

#### 1. 기능 개요

**추천 근거 생성기**는 정량적인 분석 데이터(점수, 통계)와 사용자의 직관적인 이해 사이의 간극을 매우는 데이터 해석(Data Interpretation) 서비스이다. 'F003', 'F004' 등에서 계산된 복잡한 분석 결과를 입력받아, "왜 이 위치가 추천되는가?"라는 질문에 대한 명확하고 설득력 있는 답변을 자연어 문장(Natural Language Sentences) 형태로 자동 생성한다. 이는 서비스의 신뢰도를 높이고 사용자의 최종 의사결정을 돕는 핵심적인 역할을 수행한다.

#### 2. 입력 및 출력 데이터 모델

**입력 데이터 (Input Data):** 서버에서 모든 처리가 완료된 `LocationAnalysisResponseDTO` 객체. 이 객체는 최종 점수뿐만 아니라, 근거 생성에 필요한 모든 원본 상세 지표(예: CCTV 개수, 파출소 거리 등)를 포함한다.

**출력 데이터 (Output Data):** 추천 근거 문자열의 배열(`List<String>`). 각 문자열은 해당 위치의 긍정적인 속성을 강조하는 간결하고 이해하기 쉬운 문장으로 구성된다.

- 예시: ["반경 500m 내 CCTV 23대 설치되어 야간 안전성 우수", "지하철역 도보 5분 거리로 대중교통 편리"]

#### 3. 핵심 처리 로직

본 서비스의 처리 로직은 **규칙 기반 평가 → 동적 메시지 생성 → 우선순위 기반 선정**의 3단계로 구성된다.

**3.1. 규칙 기반 평가 (Rule-Based Evaluation)**

생성기의 핵심은 사전에 정의된 **규칙 엔진(Rule Engine)**이다. 이 엔진은 입력된 데이터의 각 지표(예: `cctvCount`, `policeDistance`)를 탐정된 임계값과 비교하여, 해당 위치가 사용자에게 강조할 만한 '주목할 만한 특징'을 가지고 있는지 평가한다.

규칙 예시:
- `IF policeDistance 가 500m 미만 THEN '치안 접근성 우수'로 평가한다.`
- `IF cctvCount 가 20개 초과 THEN 'CCTV 밀도 높음'으로 평가한다.`
- `IF nearestSubway.distance 가 400m 미만 THEN '역세권'으로 평가한다.`

**3.2. 동적 메시지 생성 (Dynamic Message Generation)**

규칙 평가를 통해 '주목할 만한 특징'이 발견되면, 시스템은 템플릿 기반 메시지 생성 단계에 진입한다. 각 규칙과 짝을 이루는 메시지 템플릿은 위, 실제 데이터 값을 동적으로 삽입하여 구체적이고 데이터에 기반한 추천 문장을 생성한다.

- 템플릿: "가장 가까운 파출소까지 {distance}m로 치안 접근성 양호"
- 실제 데이터: `policeDistance = 450`
- 생성된 문장: "가장 가까운 파출소까지 450m로 치안 접근성 양호"

**3.3. 우선순위 기반 선정 (Priority-Based Selection)**

하나의 위치가 여러 긍정적인 특징을 가질 수 있으므로, 모든 근거를 나열하는 것은 사용자에게 정보 과부하를 유발할 수 있다. 따라서 시스템은 사전에 정의된 우선순위에 따라 가장 중요하고 명확한 것는 추천 근거 2-3개를 선별하여 최종 결과로 제공한다. 우선순위는 비즈니스 중요도나 특정 지표가 입계값을 얼마나 초과했는지에 따라 결정될 수 있다.

#### 4. 설계 원칙

- **규칙의 외부화(Externalization of Rules):** 추천 근거를 생성하는 데 사용되는 모든 규칙(임계값, 우선순위)과 메시지 템플릿은 소스 코드에 하드코딩하지 않고, 별도의 설정 파일(예: YAML)이나 데이터베이스 테이블로 분리하여 관리한다. 이를 통해 개발자의 개입 없이도 마케터나 기획자가 추천 문구를 수정하거나 새로운 추천 규칙을 추가할 수 있는 높은 유연성을 확보한다.

- **확장성(Extensibility):** 새로운 평가 지표(예: 가로등 밀도 점수)가 시스템에 추가될 경우, 쏘스 코드의 핵심 로직을 변경할 필요 없이 설정에 새로운 규칙과 메시지 템플릿을 추가하는 것만으로도 추천 근거 생성 기능을 쉽게 확장할 수 있도록 모듈식으로 설계된다.

---

### F008 - 그리드 기반 응답 캐싱

#### 1. 기능 개요

**그리드 기반 응답 캐싱**은 사용자의 입의 좌표 요청이 반반한 지리 정보 서비스의 특성을 고려한 고도화된 성능 최적화 기능이다. 본 기능은 '공간 지역성(Spatial Locality)' 원리를 활용하여, 단순 좌표 기반 캐싱의 낮은 적중률 문제를 해결한다. 수학적 공간 분할(지오해시)을 통해 정의된 격자(Grid) 단위로 데이터를 캐싱하고, 데이터베이스 조회를 최소화하여 사용자 응답 시간을 단축시키고 시스템 전체의 부하를 경감시키는 것을 목표로 한다.

#### 2. 핵심 처리 로직

본 기능의 처리 로직은 **사전 처리 → 동적 범위 설정 → 단단계 캐시 조회 → 데이터 통합**의 4단계로 구성된다.

**2.1. 사전 처리: 데이터베이스 그리드 인덱싱**

본격적인 캐싱 전략 실행에 앞서, 데이터베이스의 모든 위치 기반 데이터(CCTV, 경찰서 등)에 대해 **격자 좌소**를 부여하는 사전 처리 작업을 수행한다.

- **지오해시 계산:** 모든 데이터의 좌표를 지오해시(Geohash) 알고리즘을 통해 일정한 정밀도의 문자열 ID로 변환한다.
- **인덱스 생성:** 변환된 지오해시 ID를 데이터베이스 데이블의 `geohash_id` 컬럼에 저장하고, 해당 컬럼에 B-Tree 인덱스를 생성한다. 이는 향후 특정 격자 내의 데이터를 매우 빠르게 조회하기 위한 핵심적인 최적화 작업이다.

**2.2. 동적 조회 범위 설정: '9-Block' 그리드**

사용자 요청이 수신되면, 시스템은 클릭된 좌표를 기반으로 실제 데이터를 조회할 동위를 설정한다.

- **중심 및 인접 격자 계산:** 클릭된 좌표가 속한 '중심 격자'의 지오해시 ID를 계산하고, 이를 둘러싼 8개의 '인접 격자' ID까지 **총 9개의 격자 ID 목록(3x3 그리드)**을 생성한다. 이는 사용자의 분석 반경이 여러 격자에 걸쳐 있을 가능성을 해결한다.

**2.3. 단단계 캐시 조회 및 선별적 DB 접근**

설정된 9개 격자 범위를 기반으로, 두 단계에 걸쳐 캐시를 조회하고 필요한 데이터만 선별적으로 DB에 요청한다.

- **1단계 (최종 결과 캐시):** 먼저 '중심 격자'의 ID를 키로 하여, 모든 계산이 완료된 최종 DTO가 캐시에 있는지 확인한다. 캐시 히트 시, 즉시 결과를 반환하고 절차를 종료한다.

- **2단계 (개별 격자 데이터 캐시):** 1단계에서 캐시 미스가 발생하면, 9개의 격자 ID 각각에 대해 개별 데이터(예: CCTV 목록)가 캐시되어 있는지 확인한다.
  - **개별 캐시 히트 시:** 해당 격자의 데이터는 캐시된 값을 사용한다.
  - **개별 캐시 미스 시:** B-Tree 인덱스를 활용하여 `WHERE geohash_id = '해당_격자_ID'` 조건으로 DB에 매우 빠른 조회를 실행한다. 조회된 결과는 즉시 해당 격자 ID를 키로 하여 캐시에 저장한다.

**2.4. 데이터 통합 및 최종 필터링**

9개 격자에 대한 모든 데이터를 (캐시 또는 DB 조회를 통해) 수집한 후, 이를 하나의 큰 데이터 목록으로 통합한다. 최종적으로 이 통합된 목록에서 사용자의 최초 클릭 좌표 기준 정확한 반경(예: 500m) 내에 포함되는 데이터만을 필터링하여 최종 응답 객체를 생성한다.

#### 3. 설계 원칙

- **데이터베이스 부하 최소화:** B-Tree 인덱스가 적용된 `geohash_id` 컬럼을 조회함으로써, 비용이 높은 전체 테이블 스캔이나 복잡한 공간 쿼리의 실행을 완전적으로 방지한다.

- **계층적/세분화된 캐싱(Hierarchical/Granular Caching):** 최종 결과물과 그 구성 요소를 각기 다른 계층에서 캐싱한다. 이를 통해 데이터의 재사용성을 극대화하고, 일부 데이터만 변경되었을 경우 전체를 재계산하는 낭비를 방지한다.

- **캐시 데이터의 독립적 생명주기:** 각 개별 격자 데이터는 자체적인 유효 기간(TTL)을 가질 수 있다. 이를 통해 데이터의 신선도와 성능 사이의 균형을 유연하게 조절할 수 있다.

---

### F009 - 클라이언트 단순화

#### 1. 기능 개요

**클라이언트 단순화**는 서버 아키텍처 개선에 맞춰 클라이언트(JavaScript)의 역할을 재정의하는 리팩토링 가이드이다. 기존에 클라이언트가 수행하던 모든 데이터 조합 및 비즈니스 로직을 제거하고, 순수한 **표현 계층(Presentation Layer)**으로서의 책임에만 집중하도록 구조를 변경한다. 이를 통해 클라이언트 코드의 복잡성을 낮추고, 거동성과 유지보수성을 극대화하는 것을 목표로 한다.

#### 2. 핵심 처리 로직

리팩토링된 클라이언트의 처리 로직은 **이벤트 감지 → 단일 요청 → 데이터 바인딩**의 선명적인 흐름으로 단순화된다.

**2.1. 이벤트 감지 및 요청 생성 (Event Detection & Request Generation)**

사용자의 지도 클릭과 같은 상호작용(Interaction)을 감지하는 역할은 그대로 유지된다. 이벤트 발생 시, 클라이언트는 해당 상호작용에 필요한 최소한의 정보(예: 클릭된 좌표)만을 포함하는 단순한 요청 객체를 생성한다.

**2.2. 단일 API 호출 (Single API Call)**

생성된 요청 객체를 **F001: 통합 API 엔드포인트**로 전송하는 단 한 번의 API 호출을 수행한다. 기존에 존재했던 여러 엔드포인트로의 분산된 `fetch` 호출은 모두 이 단일 호출로 통합 및 대체된다.

**2.3. 통합 데이터 수신 (Integrated Data Reception)**

서버로부터 모든 비즈니스 로직 처리가 완료된 최종 형태의 통합 데이터 객체(`LocationAnalysisResponseDTO`)를 수신한다. 클라이언트는 이 데이터가 '어떻게' 만들어졌는지에 대한 과정은 전혀 알지 못하며, 서버로부터 전달 받은 단일 데이터 소스(Single Source of Truth)를 취급한다.

**2.4. 데이터 바인딩 및 UI 갱신 (Data Binding & UI Update)**

수신한 통합 데이터 객체의 각 필드값을 읽어와, 이에 대응하는 UI 요소에 **바인딩(Binding)**하여 화면을 갱신하는 역할만 집중한다.

- `safetyScore.total` 값은 그래프 컴포넌트의 너비를 조정하는 데 사용됨
- `safetyScore.cctvCount` 값은 정보 패널의 'CCTV 수' 텍스트 영역에 표시됨
- `recommendations` 배열의 문자열들은 추천 근거 목록에 순서대로 나열됨

#### 3. 제거되는 로직 및 모듈

클라이언트의 역할을 '표현'에만 집중시키기 위해 다음 로직들이 제거된다:

- **모든 비즈니스 로직 제거:** 안전성/편의성 점수를 계산하는 모든 공식, 가중치 적용 로직, 거리 변환 공식 등이 `mouseEvent.js`, `score.js`에서 완전히 제거된다. 이에 따라 `score.js` 모듈은 그 역할이 없어지거나 대폭 축소될 수 있다.

- **개별 API 호출 로직 제거:** `policeOffice.js`, `cctv.js` 등에 존재했던 개별 `fetch` 호출 함수들이 모두 제거된다. (단, 지도 위에 마커를 그리는 순수 UI 관련 기능은 유지된다.)

- **데이터 조합 로직 제거:** 여러 비동기 호출의 결과를 조합하고 관리하던 복잡한 로직(예: 모든 계기덱)이 사라지거나 대폭 축소될 수 있다.

#### 4. 설계 원칙

- **단일 책임 원칙(Single Responsibility Principle, SRP):** 리팩토링된 클라이언트는 '사용자에게 정보를 어떻게 보여줄 것인가'라는 단 하나의 책임만을 갖게 된다. 이를 통해 각 모듈의 역할이 명확해지고 코드의 응집도가 높아진다.

- **서버 의존성 단순화:** 클라이언트의 서버에 대한 의존성이 복잡한 다중 엔드포인트에서 예측 가능한 단일 엔드포인트로 단순화된다. 이는 서버의 내부 구현 변경이 클라이언트에 미치는 영향을 최소화하는 디커플링(Decoupling) 효과를 가져온다.

- **상태 관리 용이성(Simplified State Management):** 여러 비동기 요청의 중간 상태를 관리할 필요가 없어지므로, 클라이언트의 상태 관리 로직이 대폭 단순화되거나 불필요해진다.

---

### F010 - 중앙화된 장애 처리

#### 1. 기능 개요

**중앙화된 장애 처리**는 분산된 데이터 소스 조회 시 발생할 수 있는 부분적인 실패에 대응하는 시스템의 안정성 및 관측 가능성(Observability) 확보 기능이다. 본 기능은 일부 데이터 조회(예: 외부 API)가 실패할 경우, 부정확한 점수를 계산을 시도하는 대신 실패를 명시적으로 처리한다. 이를 위해 장애적으로 조회된 데이터와 실패 정보를 담은 부분적 응답 모델을 클라이언트에 전달하고, 서버 내부에는 문제 해결을 위한 상세한 로그를 기록하여 운영 가시성을 확보하는 것을 목표로 한다.

#### 2. 핵심 처리 로직

본 기능의 처리 로직은 **장애 감지 및 수집 → 조건부 응답 분기 → 상세 로깅**의 3단계로 구성된다.

**2.1. 장애 감지 및 수집 (Fault Detection & Collection)**

'F002: 병렬 데이터 조회'의 `CompletableFuture` 작업들이 완료되는 시점에서, 각 작업의 성공 여부를 검사하고 발생한 모든 예외(Exception) 객체를 수집한다. 이 과정은 개별 작업의 실패가 전체 프로세스를 중단시키지 않도록 보장한다.

**2.2. 조건부 응답 분기 (Conditional Response Branching)**

모든 병렬 작업이 완료된 후, 수집된 예외가 하나라도 존재하는지에 따라 시스템의 응답 흐름이 두 가지로 분기된다.

- **정상 흐름 (Success Path):** 단 하나의 예외도 발생하지 않았을 경우, 시스템은 'F003', 'F004' 등의 점수 계산 로직을 정상적으로 수행하고, 모든 정보가 포함된 표준 `LocationAnalysisResponseDTO`를 반환한다.

- **장애 흐름 (Failure Path):** 하나 이상의 예외가 발생했을 경우, 시스템은 모든 점수 계산 로직을 즉시 건너뛴다. 그리고 성공적으로 조회된 데이터와 수집된 예외 정보를 담은 `PartialFailureResponseDTO`를 생성하여 반환한다. 클라이언트의 `alert` 표시에 최적화된 부분적 응답 모델이다.

**2.3. 중앙화된 서버 로깅 (Centralized Server Logging)**

'장애 흐름'으로 분기될 경우, 시스템은 응답을 반환하기 직전에 문제 추적 및 분석을 위한 상세한 로그를 서버에 기록한다. 이는 실무에서 서비스의 안정성을 모니터링하는 데 필수적인 과정이다.

**로그 레벨(Log Level) 결정:**

- 외부 API 타임아웃과 같이 간헐적으로 발생할 수 있고 예측 가능한 실패는 `WARN` (경고) 레벨로 기록된다. 이는 즉각적인 조치는 필요 없지만, 빈도가 높아지면 주의가 필요하다는 의미이다.

- DB 연결 실패, 설정 오류 등 시스템 내부의 심각한 문제로 인한 실패는 `ERROR` (오류) 레벨로 기록된다. 이는 개발자의 즉각적인 확인과 조치가 필요하다는 의미이다.

**로그 내용 구체화:**

- **로그 ID (Trace ID):** 요청마다 고유한 ID를 부여하여, 여러 로그를 하나의 요청 흐름으로 묶어 추적할 수 있게 한다.

- **실패한 서비스 정보:** 어떤 데이터 조회(예: `CCTV_SERVICE`, `KAKAO_API`)에서 문제가 발생했는지 명확히 기록한다.

- **입력 파라미터:** 문제가 발생했을 당시의 입력값(예: `latitude: 37.xxx, longitude: 126.xxx`)을 기록하여, 동일한 조건에서 문제를 재현할 수 있도록 돕는다.

- **발생한 예외 정보 (Stack Trace):** 예외가 발생한 코드 위치와 원인을 담고 있는 전체 스택 트레이스를 기록하여, 개발자가 신속하게 버그의 원인을 파악할 수 있도록 한다.

**로그 포맷 예시 (JSON 형식):**

```json
{
  "timestamp": "2025-10-10T14:13:00.123Z",
  "level": "WARN",
  "traceId": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
  "message": "Partial data retrieval failure",
  "failedServices": ["KAKAO_API_CONVENIENCE_STORE"],
  "input": { "latitude": 37.5665, "longitude": 126.9780 },
  "exception": "java.net.SocketTimeoutException: Read timed out ..."
}
```

#### 3. 응답 모델 설계

'장애 흐름' 시 반환될 `PartialFailureResponseDTO`는 다음과 같이 설계된다:

| 필드명 | 데이터 타입 | 설명 |
|--------|-------------|------|
| `retrievedData` | Object | 성공적으로 조회된 데이터들을 담는 객체. (예: `policeInfo`, `cctvList`) |
| `failures` | Array | 실패한 작업에 대한 정보를 담는 배열. |
| `userMessage` | String | 클라이언트 `alert`에 표시될 사용자 친화 메시지. (예: "편의시설 정보를 불러오지 못했습니다. 일부 정보만 표시됩니다.") |

#### 4. 설계 원칙

- **실패의 명시적 처리(Explicit Failure Handling):** 아쉽도록 계산된 부정확한 점수를 제공하는 대신, 실패 상황을 명확히 인지하고 별도의 응답으로 처리하여 데이터의 신뢰성을 보장한다.

- **운영 가시성 확보(Operational Visibility):** 체계적인 로깅 전략을 통해, 서비스 운영 중 발생하는 모든 예외 상황을 놓치지 않고 추적, 집계, 분석할 수 있는 기반을 마련한다. 이는 서비스 품질 개선의 핵심 데이터로 활용된다.

---

## 문서 종료

본 문서는 '상세 지도 기반 정보 제공 서비스'의 백엔드 중심 아키텍처 전환 프로젝트에서 구현해야 할 총 10개의 핵심 기능(F001~F010)에 대한 완전한 요구사항 명세를 제공한다.

**문서 작성 완료일:** 2025-10-10  
**총 기능 수:** 10개  
**문서 상태:** 최종 승인 대기

---

### 부록: 기능 간 의존성 다이어그램

```
F001 (통합 API 엔드포인트)
  ├─> F002 (병렬 데이터 조회)
  │     ├─> F005 (외부 API 서버 통합)
  │     └─> F006 (주소 변환 서비스)
  │
  ├─> F003 (안전성 점수 계산)
  ├─> F004 (편의성 점수 계산)
  ├─> F007 (추천 근거 생성기)
  ├─> F008 (그리드 기반 응답 캐싱)
  └─> F010 (중앙화된 장애 처리)

F009 (클라이언트 단순화)
  └─> F001에 단일 요청 전송
```

### 부록: 용어 정의

- **DTO (Data Transfer Object):** 계층 간 데이터 전송을 위한 객체
- **CompletableFuture:** Java의 비동기 프로그래밍을 위한 클래스
- **Geohash:** 지리적 좌표를 문자열로 인코딩하는 알고리즘
- **B-Tree Index:** 데이터베이스 검색 성능을 향상시키는 인덱스 구조
- **Fault Isolation:** 부분 장애가 전체 시스템에 전파되지 않도록 격리하는 설계 기법
- **TTL (Time To Live):** 캐시 데이터의 유효 기간