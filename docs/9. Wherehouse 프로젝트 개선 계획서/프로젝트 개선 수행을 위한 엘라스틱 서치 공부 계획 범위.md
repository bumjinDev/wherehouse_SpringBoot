# 프로젝트 개선을 위한 Elasticsearch 학습 계획서

## 개요

본 문서는 WhereHouse 프로젝트 개선을 위한 Elasticsearch 학습 범위와 일정을 정의한다.

프로젝트 목표 달성을 위해서는 Elasticsearch의 모든 기능을 학습할 필요는 없다. 핵심적으로 요구되는 세 가지 기능에 집중한다:
1. **데이터 색인(Indexing)**: 외부 API 데이터를 Elasticsearch에 저장
2. **조건부 검색(Query)**: 사용자 조건에 맞는 매물 검색  
3. **통계 분석(Aggregation)**: 지역별 시세, 안전도 등 통계 데이터 생성

기존 단순 분기문 기반 로직과 달리, 개선된 시스템의 핵심 비즈니스 로직은 Elasticsearch 쿼리로 구현된다. 따라서 데이터 가공 및 조회 방식의 이해가 프로젝트 성공의 핵심 요소가 된다.

## 1. Elasticsearch 최소 학습 범위 (Must-Know)

이 프로젝트만을 위한 핵심 바운더리는 다음과 같다. 아래 목록 외의 기능은 학습 대상에서 제외해도 좋다.

### 1.1 기본 환경 구축 (1순위)

**학습 내용**: Docker를 이용한 Elasticsearch 및 Kibana 설치 및 실행

**프로젝트 역할**: 개발 환경을 구축하는 가장 첫 단계이다. Kibana는 Elasticsearch에 데이터가 잘 들어갔는지 눈으로 확인하는 필수 시각화 도구이다.

### 1.2 핵심 개념 이해

**학습 내용**: Index, Document, Mapping 이 세 가지 용어의 관계

**프로젝트 역할**: Elasticsearch의 기본 구조를 이해하기 위해 필요하다. 간단히 Index는 '데이터베이스', Document는 '테이블의 한 행(Row)', Mapping은 '테이블 스키마(Schema)' 와 유사하다고 생각하면 된다.

### 1.3 Spring Boot 연동

**학습 내용**: Spring Data Elasticsearch를 사용한 연동 방법

- application.properties 설정
- @Document 어노테이션을 사용한 엔티티 클래스 정의
- ElasticsearchRepository 인터페이스를 사용한 기본 데이터 저장/조회

**프로젝트 역할**: 현재의 Java 백엔드와 Elasticsearch를 연결하는 다리 역할을 한다.

### 1.4 필수 쿼리 3종 세트

이 부분이 가장 중요하며, 비즈니스 로직의 핵심이 된다.

#### 1.4.1 필터링 쿼리 (Filtering)

**학습 내용**: Bool Query를 사용하여 Term(정확히 일치), Match(텍스트 검색), Range(범위) 조건을 조합하는 방법

**프로젝트 역할**: "강남구에서", "전세금이 2억에서 3억 사이인" 매물을 찾는 1단계 기본 검색 로직을 구현한다.

#### 1.4.2 지리 공간 쿼리 (Geo-spatial Query)

**학습 내용**: geo_distance 쿼리 사용법

**프로젝트 역할**: "사용자가 찍은 위치(Pin-Point)에서 반경 500m 내 CCTV 개수" 또는 **"가장 가까운 파출소까지의 거리"**를 계산하는 핵심 안전 점수 로직을 구현한다.

#### 1.4.3 집계 쿼리 (Aggregations)

**학습 내용**: Terms(그룹화), Extended Stats(평균, 표준편차 등 통계) 집계 사용법

**프로젝트 역할**: "구별 평균 가격", "가격 변동성(표준편차)" 등 통계 데이터를 생성하는 로직을 구현한다.

## 2. 지금은 몰라도 되는 범위 (Don't-Need-to-Know)

학습 시간을 단축하기 위해 아래 내용들은 과감히 무시한다.

- **클러스터 운영 및 관리**: 샤드, 레플리카 설정 등 분산 시스템 관리 (단일 노드로 충분)
- **고급 텍스트 분석**: 형태소 분석기(Analyzer), 토크나이저(Tokenizer) 등 자연어 처리 기술
- **성능 튜닝**: 인덱스 설정 최적화, 캐시 관리 등
- **데이터 파이프라인**: Logstash, Beats 등 ELK Stack의 다른 구성 요소

## 3. 현실적인 2주 계획

| 기간 | 목표 | 핵심 활동 | 결과물 |
|------|------|-----------|--------|
| **1주차 (1~4일)** | 데이터 적재 (Getting Data In) | Docker로 ES/Kibana 실행, Spring Boot 연동, 외부 API 데이터 파싱 및 ES 저장 로직 구현 | Kibana에서 API로 수집한 데이터가 조회되는 상태 |
| **1주차 (5~7일)** | 기본 검색 API 구현 | Bool Query를 사용한 1단계 매물 검색 API 개발 | 조건에 맞는 매물 목록을 JSON으로 반환하는 API |
| **2주차 (8~12일)** | 핵심 로직 구현 | geo_distance 쿼리로 위치 기반 안전 점수 계산, Aggregations로 통계 데이터 생성, 2단계 폴백(Fallback) 로직에 위 기능들 통합 | 안전 점수와 통계가 포함된 최종 추천 API |
| **2주차 (13~14일)** | 정리 및 테스트 | 코드 리팩토링 및 최종 테스트, README 문서 업데이트 | 동작 가능한 프로젝트 최종 버전 |