# Wherehouse 프로젝트 — Phase 2 리뷰 데이터 대량 생성 작업 이력서

> 작성일: 2026-02-09  
> 작업자: 정범진 (Back-end Engineer) + Claude AI  
> 프로젝트: Wherehouse (주거지 추천 서비스)  
> 문서 버전: v1.0  
> 선행 문서: `2. Wherehouse_마이그레이션_운영 테스트데이터생성_회원및인증테이블.md` (Phase 1)

---

## 목차

1. [작업 배경 및 선행 조건](#1-작업-배경-및-선행-조건)
2. [작업 전 환경 확인](#2-작업-전-환경-확인)
3. [배치 실행 및 매물 데이터 적재](#3-배치-실행-및-매물-데이터-적재)
4. [Phase 2 PL/SQL 프로시저 개발 과정](#4-phase-2-plsql-프로시저-개발-과정)
5. [Phase 2 최종 실행 결과](#5-phase-2-최종-실행-결과)
6. [시퀀스 동기화](#6-시퀀스-동기화)
7. [최종 데이터 현황 총괄](#7-최종-데이터-현황-총괄)
8. [트러블슈팅 기록](#8-트러블슈팅-기록)
9. [산출물 목록](#9-산출물-목록)
10. [부록 — 프로시저 설계 상세](#10-부록--프로시저-설계-상세)

---

## 1. 작업 배경 및 선행 조건

### 1.1 Phase 1 완료 상태

Phase 1에서 회원 데이터 2,500명이 생성 완료된 상태이며, Phase 2 시작 전 아래 조건이 충족되어야 했다.

| 선행 조건 | 상태 |
|----------|------|
| MEMBERTBL 2,500건 | ✅ Phase 1 완료 |
| USERENTITY 2,500건 | ✅ Phase 1 완료 |
| USERENTITY_ROLES 2,500건 | ✅ Phase 1 완료 |
| 매물 데이터 배치 적재 | ⏳ 본 세션에서 실행 |

### 1.2 Phase 2 목표

| 대상 테이블 | 목표 건수 | 용도 |
|-----------|----------|------|
| REVIEWS | 100,000건 이상 | 리뷰 원본 데이터 |
| REVIEW_KEYWORDS | ~350,000건 (리뷰당 평균 3.5개) | 키워드 감성 분석 데이터 |
| REVIEW_STATISTICS | 리뷰 달린 매물 수만큼 | 매물별 집계 통계 |

### 1.3 검증 대상 (설계 명세서 기반)

설계 명세서 경로: `docs/11. 주거지 추천 서비스 사용자 경험 반영 개선/4. 주거지_추천_서비스_사용자_경험_반영_설계_명세서_v2.md`

| 검증 항목 | 필요 데이터 조건 |
|----------|----------------|
| 하이브리드 추천 점수 (LegacyScore 50% + ReviewScore 50%) | Hot 매물 (리뷰 8건 이상) |
| Cold Start 분기 (리뷰 < 5건 → LegacyScore 100%) | Warm 매물 (경계값 5~7건), Cold 매물 (1~3건) |
| KeywordScore 산출 (긍정/(긍정+부정) × 100) | 긍정/부정 키워드 혼합 분포 |
| Zero 매물 기본값 동작 | 리뷰 0건 매물 |

---

## 2. 작업 전 환경 확인

### 2.1 배치 실행 전 Redis 상태 확인

배치 실행 전 Redis에 기존 데이터가 있는지 확인하기 위해 미니PC(61.75.54.208)에 SSH 접속하여 Redis CLI를 실행하였다.

**인증 이슈**: Redis에 `requirepass abed1234`가 설정되어 있어 `AUTH abed1234` 명령으로 인증 후 진행하였다.

### 2.2 Oracle DB 사전 확인 쿼리

SQL Developer에서 매물 및 리뷰 테이블 현황을 확인하였다.

```sql
-- 매물 건수
SELECT 'CHARTER' AS TYPE, COUNT(*) AS CNT FROM PROPERTIES_CHARTER
UNION ALL
SELECT 'MONTHLY', COUNT(*) FROM PROPERTIES_MONTHLY;

-- 기존 리뷰 데이터
SELECT 'REVIEWS' AS TBL, COUNT(*) AS CNT FROM REVIEWS
UNION ALL
SELECT 'REVIEW_KEYWORDS', COUNT(*) FROM REVIEW_KEYWORDS
UNION ALL
SELECT 'REVIEW_STATISTICS', COUNT(*) FROM REVIEW_STATISTICS;

-- 회원 수
SELECT COUNT(*) AS USER_CNT FROM MEMBERTBL WHERE ID LIKE 'user%';
```

### 2.3 매물 데이터 길이 확인 (프로시저 버퍼 크기 산정용)

```sql
-- 매물명 최대 바이트 길이
SELECT MAX(LENGTHB(APT_NM)) AS MAX_APT_NM_BYTES,
       MAX(LENGTHB(DISTRICT_NAME)) AS MAX_DISTRICT_BYTES
FROM PROPERTIES_CHARTER
UNION ALL
SELECT MAX(LENGTHB(APT_NM)), MAX(LENGTHB(DISTRICT_NAME))
FROM PROPERTIES_MONTHLY;
-- 결과: APT_NM 최대 58바이트, DISTRICT_NAME 최대 12바이트

-- PROPERTY_ID 길이 확인
SELECT MAX(LENGTHB(PROPERTY_ID)) AS MAX_PID_BYTES,
       MIN(LENGTHB(PROPERTY_ID)) AS MIN_PID_BYTES
FROM PROPERTIES_CHARTER
UNION ALL
SELECT MAX(LENGTHB(PROPERTY_ID)), MIN(LENGTHB(PROPERTY_ID))
FROM PROPERTIES_MONTHLY;
-- 결과: 모두 정확히 32바이트 (MD5 해시)
```

---

## 3. 배치 실행 및 매물 데이터 적재

### 3.1 배치 실행 흐름

IntelliJ에서 WhereouseApplication을 실행하여 배치 스케줄러(BatchScheduler)가 트리거되었다.

```
[실행 흐름]
BatchScheduler.executeBatchProcess()
  → 국토교통부 API 25개 구 순차 호출 (서대문구 577건, 구로구 700건, 광진구 381건, 송파구 1,642건 등)
  → publishDataCollectionCompletedEvent()
    → RdbSyncListener.handleDataCollectionCompletedEvent()
      → saveCharterPropertiesToRdb() (전세)
      → saveMonthlyPropertiesToRdb() (월세)
      → Redis 동기화 (인덱스, bounds, safety 등)
```

### 3.2 배치 수집 결과

| 항목 | 건수 |
|------|------|
| 전세 매물 수집 | 10,113건 |
| 월세 매물 수집 | 8,481건 |
| **총 수집** | **18,594건** |

### 3.3 HikariCP Connection Leak Detection 경고

배치 실행 중 `20:01:41`에 HikariCP leak detection 경고가 발생하였다.

```
WARN c.zaxxer.hikari.pool.ProxyLeakTask - Connection leak detection triggered 
for oracle.jdbc.driver.T4CConnection@720ffab4 on thread scheduling-1
```

**원인 분석**: `saveCharterPropertiesToRdb()`에서 `saveAll()` → JPA `merge()` 호출 시 엔티티당 SELECT 1회 + INSERT/UPDATE 1회를 순차 실행. 전세 10,113건 처리에 60초 이상 소요되면서 HikariCP의 `leakDetectionThreshold`(기본 60초)를 초과한 것이다.

**결론**: 실제 누수 아님. 커넥션 풀 상태 `total=6, active=1, idle=5, waiting=0`으로 정상. 배치 완료 후 `Previously reported leaked connection ... was returned to the pool (unleaked)` 로그로 정상 반환 확인됨.

**권장 조치**: `application.yml`에서 배치 특성에 맞게 임계값 조정.
```yaml
spring:
  datasource:
    hikari:
      leak-detection-threshold: 300000  # 5분
```

### 3.4 RDB 적재 완료 확인

SQL Developer에서 확인한 최종 RDB 매물 건수:

| 테이블 | 건수 |
|--------|------|
| PROPERTIES_CHARTER (전세) | 58,660 |
| PROPERTIES_MONTHLY (월세) | 56,272 |
| **합계** | **114,932** |

배치 수집은 당월(2026-01) 매물 18,594건이었으나, 기존 적재분과 합산되어 총 114,932건이 존재한다.

### 3.5 Redis 적재 완료 확인

```
127.0.0.1:6379> EVAL "return #redis.call('keys','property:charter:*')" 0
(integer) 58660

127.0.0.1:6379> EVAL "return #redis.call('keys','property:monthly:*')" 0
(integer) 56272

127.0.0.1:6379> ZCARD idx:charterPrice:강남구
(integer) 50747

127.0.0.1:6379> HGETALL bounds:강남구:전세
 1) "maxArea"      2) "64.7271"
 3) "propertyCount" 4) "50747"
 5) "minArea"      6) "4.9671"
 7) "maxPrice"     8) "350000.0"
 9) "lastUpdated"  10) "2026-02-09"
11) "minPrice"     12) "9439.0"

127.0.0.1:6379> HGETALL safety:강남구
 1) "safetyScore"   2) "20.431298014384..."
 3) "lastUpdated"   4) "2026-02-09"
 5) "version"       6) "1.0"
 7) "districtName"  8) (UTF-8 강남구)

127.0.0.1:6379> EVAL "return #redis.call('keys','stats:*')" 0
(integer) 0   ← 리뷰 통계 미생성 (Phase 2 대상)

127.0.0.1:6379> DBSIZE
(integer) 164833
```

### 3.6 배치 성능 요약 (최종 실행 로그)

```
CHUNK_SIZE          = 10000 건/청크
PIPELINE_BATCH_SIZE = 2000 건/파이프라인
DBLOAD:CHARTER      = 29555 ms (66651건, 7청크)
DBLOAD:MONTHLY      = 2815 ms (63091건, 7청크)
TRANSFORM:CHARTER   = 15 ms (누적)
TRANSFORM:MONTHLY   = 13 ms (누적)
BATCH:TOTAL         = 77674 ms
```

### 3.7 IntelliJ OOM 이슈

배치 실행 중 Redis Lettuce 드라이버의 DEBUG 로그가 대량 출력되면서 IntelliJ가 OOM(Out of Memory)으로 먹통되었다.

**원인**: `logging.level.io.lettuce.core=DEBUG` 설정으로 인해 Redis 커맨드 하나당 로그 1줄 × 매물 114,000건 × 인덱스 5~6개 ≈ 60만줄 이상이 콘솔에 출력됨.

**해결**:
1. 작업관리자에서 IntelliJ 강제 종료
2. `application.yml` 로그 레벨 수정:
```yaml
logging:
  level:
    io.lettuce.core: WARN
    io.lettuce: WARN
    io.netty: WARN
```
3. 이전 Java 프로세스가 포트 8185를 점유 중이어서 `taskkill /F /IM java.exe` 후 재시작

---

## 4. Phase 2 PL/SQL 프로시저 개발 과정

### 4.1 프로시저 반복 과정 요약

총 3번의 버전을 거쳐 최종 프로시저를 완성하였다.

| 버전 | 문제 | 수정 사항 |
|------|------|----------|
| **v1** | `ORA-06502: 문자열 버퍼가 너무 작습니다` (447행, 135행) | VARCHAR2 레코드 필드 크기 부족, NUMBER 중간연산 미분리 |
| **v2** | 첫 실행: 40,000건까지 성공 후 사용자 취소(ORA-01013) → 두 번째 실행: `ORA-00001 UK_REVIEWS_PROPERTY_USER 위배` | 중간 커밋된 40,000건과 새 실행의 (PROPERTY_ID, USER_ID) 충돌. DUP_VAL_ON_INDEX 처리 미구현 |
| **v3** ✅ | 정상 완료 (99,937건) | UK 중복 사전 체크(메모리 해시맵) + DUP_VAL_ON_INDEX 스킵 + 기존 데이터 자동 감지 |

### 4.2 v1 → v2 수정 상세

**ORA-06502 원인 분석 과정**:

매물명(APT_NM) 최대 58바이트, DISTRICT_NAME 최대 12바이트, PROPERTY_ID 정확히 32바이트로 모두 선언된 VARCHAR2(255) 범위 내였으나, PL/SQL 레코드 타입의 `NUMBER(1)` 변수에 `DBMS_RANDOM.NORMAL`의 극단값이 할당되면서 버퍼 오버플로가 발생하였다.

| 항목 | v1 | v2 |
|------|----|----|
| 레코드 VARCHAR2 크기 | 255 | 100~1000 (대폭 확대) |
| 별점 계산 | `v_rating := GREATEST(1, LEAST(5, ROUND(...)))` 직접 할당 | `v_rand` 중간변수로 분리 후 IF 클램프 |
| 템플릿 인덱스 | `TRUNC(DBMS_RANDOM.VALUE(...))` | `MOD(ABS(DBMS_RANDOM.RANDOM), count) + 1` 안전 방식 |
| 에러 트레이스 | 없음 | `DBMS_UTILITY.FORMAT_ERROR_BACKTRACE` 추가 |

### 4.3 v2 → v3 수정 상세

**v2 실행 중 발생한 문제**:

1. 첫 실행에서 40,000건(5,000건×8회 커밋)까지 진행 후 사용자가 SQL Developer에서 취소(ORA-01013)
2. 중간 커밋으로 40,000건이 DB에 남아있는 상태에서 두 번째 실행 시작
3. 두 번째 실행이 동일 매물에 동일 유저를 할당하면서 UK `(PROPERTY_ID, USER_ID)` 제약 위반 → ORA-00001

| 항목 | v2 | v3 |
|------|----|----|
| UK 위반 처리 | 전체 중단 (RAISE) | `DUP_VAL_ON_INDEX` → 해당 건만 스킵 |
| 중복 사전 체크 | 없음 | 메모리 해시맵 `v_existing_pairs(property_id\|user_id)` |
| 기존 데이터 감지 | 없음 | 시작 시 `SELECT PROPERTY_ID, USER_ID FROM REVIEWS` 로드 |
| 에러 시 처리 | ROLLBACK (전체 롤백) | COMMIT (지금까지 성공한 건 보존) |
| REVIEW_STATISTICS | 단순 INSERT | `DELETE` 후 재생성 (재실행 안전) |

### 4.4 최종 프로시저 (v3) 핵심 설계

#### 4.4.1 리뷰 분배 전략

```
Hot2 매물:  2,500개 × 8~20건 (평균 ~14건)  ≈ 35,000건
Hot 매물:   1,200개 × 8~15건 (평균 ~11건)  ≈ 13,200건
Warm 매물:  3,000개 × 5~7건  (평균 ~6건)   ≈ 18,000건
Cold 매물: ~16,600개 × 1~3건 (평균 ~2건)   ≈ 33,000건
Zero 매물: 나머지 ~91,600개                = 0건
────────────────────────────────────────────
합계:      ~23,300개 매물                  ≈ 100,000건
```

#### 4.4.2 UK 제약 준수 — Fisher-Yates 셔플

매물당 할당된 리뷰 수만큼 유저 풀(2,500명)에서 중복 없이 선택하기 위해 Fisher-Yates 셔플 알고리즘을 사용하였다.

```
매물 A에 15건 할당 시:
  1. 유저 인덱스 배열 [1..2500] 초기화
  2. Fisher-Yates로 처음 15개만 셔플
  3. 셔플된 15개 유저로 리뷰 생성
  → (PROPERTY_ID_A, user_X) 조합이 절대 중복되지 않음
```

#### 4.4.3 별점 생성 (정규분포 유사)

```sql
v_rand := ROUND(3.5 + DBMS_RANDOM.NORMAL * 0.9);
IF v_rand < 1 THEN v_rand := 1; END IF;
IF v_rand > 5 THEN v_rand := 5; END IF;
```

중심값 3.5, 표준편차 0.9로 별점 3~4에 집중되고 1, 5는 드물게 분포.

#### 4.4.4 키워드 생성 (별점 연동)

| 별점 | 긍정 키워드 확률 | 부정 키워드 확률 |
|------|----------------|----------------|
| 4~5 (긍정) | 80% | 20% |
| 3 (중립) | 50% | 50% |
| 1~2 (부정) | 20% | 80% |

키워드 사전 (KeywordDictionary Enum 기반):

| 구분 | 키워드 | SCORE |
|------|--------|-------|
| 긍정 | 조용, 밝다, 역세권, 편리, 깨끗, 넓은, 남향, 채광, 평지, 관리비저렴 | +1 |
| 부정 | 시끄럽, 어둡, 멀다, 불편, 노후, 좁은, 층간소음, 언덕, 관리비비쌈 | -1 |

#### 4.4.5 리뷰 내용 템플릿

별점에 따라 긍정(10개)/부정(5개)/중립(5개) 템플릿 중 랜덤 선택 후, 매물명+지역명 접두사를 붙여 유니크한 콘텐츠를 생성하였다.

```
예시: "래미안강남아파트 강남구 거주 후기. 채광이 좋고 환기가 잘 되는 집입니다..."
```

#### 4.4.6 커밋 전략

```
5,000건마다 중간 COMMIT + 진행률 로그 출력
에러 발생 시에도 COMMIT (지금까지 성공분 보존) → 재실행 시 기존 데이터 자동 감지
```

#### 4.4.7 REVIEW_STATISTICS 집계

REVIEWS + REVIEW_KEYWORDS를 JOIN하여 매물별 집계를 한 번의 INSERT-SELECT로 생성.

```sql
INSERT INTO REVIEW_STATISTICS (
    PROPERTY_ID, REVIEW_COUNT, AVG_RATING,
    POSITIVE_KEYWORD_COUNT, NEGATIVE_KEYWORD_COUNT, LAST_CALCED
)
SELECT
    r.PROPERTY_ID,
    COUNT(DISTINCT r.REVIEW_ID),
    ROUND(AVG(r.RATING), 2),
    NVL(SUM(CASE WHEN rk.SCORE > 0 THEN 1 ELSE 0 END), 0),
    NVL(SUM(CASE WHEN rk.SCORE < 0 THEN 1 ELSE 0 END), 0),
    SYSTIMESTAMP
FROM REVIEWS r
LEFT JOIN REVIEW_KEYWORDS rk ON r.REVIEW_ID = rk.REVIEW_ID
GROUP BY r.PROPERTY_ID;
```

---

## 5. Phase 2 최종 실행 결과

### 5.1 실행 환경

| 항목 | 값 |
|------|-----|
| 실행 도구 | Oracle SQL Developer |
| 프로시저 | `GENERATE_PHASE2_REVIEWS` (v3) |
| 실행 시각 | 2026-02-09 11:43:30 |
| 완료 시각 | 2026-02-09 11:51:50 |
| 소요 시간 | 약 101초 (1분 41초) |

### 5.2 프로시저 실행 로그

```
============================================
Phase 2 v3: 리뷰 데이터 대량 생성 시작
시작: 2026-02-09 11:43:30.837
============================================
[STEP 1] 매물 데이터 로드 중...
  매물 로드 완료: 114932건
  유저 로드 완료: 2500명
[STEP 2] 리뷰 분배 계획...
  Hot2=2500, Hot=1200, Warm=3000, Cold=16553
  예상 총 리뷰: 99987건
  시작 REVIEW_ID: 1, KEYWORD_ID: 1
[STEP 3] 리뷰 INSERT 시작...
  진행: 5000 리뷰 / 17502 키워드 / 스킵: 0 (11:43:33)
  진행: 10000 리뷰 / 34933 키워드 / 스킵: 0 (11:43:39)
  진행: 15000 리뷰 / 52414 키워드 / 스킵: 0 (11:43:45)
  진행: 20000 리뷰 / 69949 키워드 / 스킵: 0 (11:43:48)
  진행: 25000 리뷰 / 87514 키워드 / 스킵: 0 (11:43:54)
  진행: 30000 리뷰 / 105071 키워드 / 스킵: 0 (11:44:00)
  ...
  진행: 85000 리뷰 / 297124 키워드 / 스킵: 0 (11:51:28)
  진행: 90000 리뷰 / 314647 키워드 / 스킵: 0 (11:51:34)
  진행: 95000 리뷰 / 332144 키워드 / 스킵: 0 (11:51:40)
[STEP 3] 완료 - 리뷰: 99937, 키워드: 349453, 스킵: 0
[STEP 4] REVIEW_STATISTICS 집계 중...
[STEP 4] 완료 - REVIEW_STATISTICS: 23394건

============================================
Phase 2 v3 완료 리포트
============================================
종료: 2026-02-09 11:51:50.018
REVIEWS:           99937건
REVIEW_KEYWORDS:   349453건
REVIEW_STATISTICS: 23394건
스킵 (UK 중복):    0건
리뷰당 평균 키워드: 3.5
최종 REVIEW_ID:    99937
최종 KEYWORD_ID:   349453
============================================

PL/SQL 프로시저가 성공적으로 완료되었습니다.
```

### 5.3 최종 건수 검증

```sql
SELECT 'REVIEWS' AS TBL, COUNT(*) AS CNT FROM REVIEWS
UNION ALL
SELECT 'REVIEW_KEYWORDS', COUNT(*) FROM REVIEW_KEYWORDS
UNION ALL
SELECT 'REVIEW_STATISTICS', COUNT(*) FROM REVIEW_STATISTICS;
```

| 테이블 | 건수 | 목표 | 달성률 |
|--------|------|------|--------|
| REVIEWS | 99,937 | 100,000+ | 99.9% |
| REVIEW_KEYWORDS | 349,453 | ~350,000 | 99.8% |
| REVIEW_STATISTICS | 23,394 | - | ✅ |

---

## 6. 시퀀스 동기화

PL/SQL 프로시저에서 직접 ID를 할당했으므로, JPA의 시퀀스 기반 ID 생성과 충돌하지 않도록 동기화가 필요하다.

### 6.1 실행 쿼리

```sql
-- SEQ_REVIEW_ID 동기화
ALTER SEQUENCE SEQ_REVIEW_ID INCREMENT BY 99937;
SELECT SEQ_REVIEW_ID.NEXTVAL FROM DUAL;
ALTER SEQUENCE SEQ_REVIEW_ID INCREMENT BY 1;

-- SEQ_KEYWORD_ID 동기화
ALTER SEQUENCE SEQ_KEYWORD_ID INCREMENT BY 349453;
SELECT SEQ_KEYWORD_ID.NEXTVAL FROM DUAL;
ALTER SEQUENCE SEQ_KEYWORD_ID INCREMENT BY 1;
```

### 6.2 동기화 확인

SQL Developer에서 실행 완료 확인됨. 이후 JPA에서 `SEQ_REVIEW_ID.NEXTVAL` 호출 시 99,938부터, `SEQ_KEYWORD_ID.NEXTVAL` 호출 시 349,454부터 채번된다.

---

## 7. 최종 데이터 현황 총괄

### 7.1 Oracle DB 전체 현황

| 테이블 | 건수 | 생성 방식 |
|--------|------|----------|
| MEMBERTBL | 2,500 | Phase 1 PL/SQL |
| USERENTITY | 2,500 | Phase 1 PL/SQL |
| USERENTITY_ROLES | 2,500 | Phase 1 PL/SQL |
| PROPERTIES_CHARTER | 58,660 | 배치 스케줄러 (국토교통부 API) |
| PROPERTIES_MONTHLY | 56,272 | 배치 스케줄러 (국토교통부 API) |
| REVIEWS | 99,937 | Phase 2 PL/SQL (v3) |
| REVIEW_KEYWORDS | 349,453 | Phase 2 PL/SQL (v3) |
| REVIEW_STATISTICS | 23,394 | Phase 2 PL/SQL (v3, INSERT-SELECT 집계) |

### 7.2 Redis 전체 현황

| 키 패턴 | 건수 | 설명 |
|--------|------|------|
| `property:charter:*` | 58,660 | 전세 매물 Hash |
| `property:monthly:*` | 56,272 | 월세 매물 Hash |
| `idx:charterPrice:*` | 25개 구 × 각 수천건 | 전세 가격 인덱스 (Sorted Set) |
| `idx:deposit:*` | 25개 구 × 각 수천건 | 보증금 인덱스 |
| `idx:monthlyRent:*` | 25개 구 × 각 수천건 | 월세 임대료 인덱스 |
| `idx:area:*` | 25개 구 × 전세/월세 | 면적 인덱스 |
| `bounds:*` | 25개 구 × 전세/월세 | 정규화 범위 |
| `safety:*` | 25개 구 | 안전성 점수 |
| `stats:*` | 0 | 리뷰 통계 (미동기화 — 다음 단계) |
| **DBSIZE** | **179,643** | 전체 키 수 |

### 7.3 리뷰 분배 결과

| 구분 | 매물 수 | 리뷰 범위 | 리뷰 소계 |
|------|---------|----------|----------|
| Hot2 | 2,500 | 8~20건 | ~35,000 |
| Hot | 1,200 | 8~15건 | ~13,800 |
| Warm | 3,000 | 5~7건 | ~18,000 |
| Cold | 16,553 | 1~3건 | ~33,100 |
| Zero | ~91,679 | 0건 | 0 |
| **합계** | **23,253+** | | **99,937** |

---

## 8. 트러블슈팅 기록

### 8.1 ORA-06502: 문자열 버퍼가 너무 작습니다 (v1)

| 항목 | 내용 |
|------|------|
| 발생 시점 | v1 프로시저 실행 직후 |
| 에러 코드 | ORA-06502 (447행, 135행) |
| 원인 | PL/SQL 레코드 타입 필드의 VARCHAR2 크기가 실 데이터보다 작거나, DBMS_RANDOM.NORMAL 극단값이 NUMBER(1)에 할당 |
| 해결 | VARCHAR2 크기 대폭 확대 (255 → 100~1000), NUMBER 중간변수 분리 |

### 8.2 ORA-01013: 사용자 취소 + ORA-00001: UK 위반 (v2)

| 항목 | 내용 |
|------|------|
| 발생 시점 | v2 첫 실행 40,000건 진행 중 사용자 취소 → 두 번째 실행 시 |
| 에러 코드 | ORA-01013 (취소), ORA-00001 (UK 위반) |
| 원인 | 5,000건 단위 중간 커밋으로 40,000건이 DB에 남아있는 상태에서, 재실행 시 동일 매물-유저 조합 재할당 |
| 해결 | v3에서 (1) 시작 시 기존 (PROPERTY_ID, USER_ID) 페어를 메모리 로드, (2) INSERT 전 메모리 체크, (3) DUP_VAL_ON_INDEX 스킵 |
| 후속 조치 | `DELETE FROM REVIEW_KEYWORDS; DELETE FROM REVIEWS; DELETE FROM REVIEW_STATISTICS; COMMIT;`으로 초기화 후 v3 재실행 |

### 8.3 HikariCP Connection Leak Detection 경고

| 항목 | 내용 |
|------|------|
| 발생 시점 | 배치 실행 60초 후 |
| 에러 | `Apparent connection leak detected` (WARN) |
| 원인 | JPA saveAll() → merge()의 엔티티당 SELECT+INSERT 순차 처리로 트랜잭션이 60초 초과 |
| 영향 | 없음. 배치 완료 후 정상 반환 (unleaked) |
| 권장 조치 | `leak-detection-threshold: 300000` (5분)으로 조정 |

### 8.4 IntelliJ OOM (Out of Memory)

| 항목 | 내용 |
|------|------|
| 발생 시점 | 배치 Redis 동기화 단계 |
| 증상 | IntelliJ 화면 블랙아웃, 힙 메모리 고정 |
| 원인 | Lettuce DEBUG 로그 약 60만줄 콘솔 출력 |
| 해결 | IntelliJ 강제 종료, `io.lettuce.core` 로그 레벨 `WARN`으로 변경 |

### 8.5 포트 충돌 (8185 already in use)

| 항목 | 내용 |
|------|------|
| 발생 시점 | IntelliJ 재시작 후 애플리케이션 실행 시 |
| 에러 | `Web server failed to start. Port 8185 was already in use.` |
| 원인 | 강제 종료된 이전 Java 프로세스가 포트를 여전히 점유 |
| 해결 | `taskkill /F /IM java.exe` 후 재실행 |

---

## 9. 산출물 목록

| # | 파일명 | 유형 | 설명 | 상태 |
|---|--------|------|------|------|
| 1 | `phase2_generate_reviews_v3.sql` | SQL | Phase 2 리뷰 대량 생성 프로시저 (최종) | ✅ 실행 완료 |
| 2 | `phase2_generate_reviews_v2.sql` | SQL | v2 (UK 위반 미처리 버전, 기록용) | 🔄 대체됨 |
| 3 | `phase2_generate_reviews.sql` | SQL | v1 (버퍼 오버플로 버전, 기록용) | 🔄 대체됨 |
| 4 | 본 문서 | MD | Phase 2 전체 작업 이력서 | ✅ 완료 |

---

## 10. 부록 — 프로시저 설계 상세

### 10.1 PL/SQL 타입 정의

```sql
TYPE t_property_rec IS RECORD (
    property_id   VARCHAR2(100),
    apt_nm        VARCHAR2(1000),
    district_name VARCHAR2(500)
);
TYPE t_property_tab IS TABLE OF t_property_rec INDEX BY PLS_INTEGER;
TYPE t_user_tab IS TABLE OF VARCHAR2(100) INDEX BY PLS_INTEGER;
TYPE t_exist_tab IS TABLE OF NUMBER INDEX BY VARCHAR2(200);  -- UK 중복 체크용
```

### 10.2 리뷰 내용 템플릿 목록

**긍정 (10개)**:
1. 채광이 좋고 환기가 잘 되는 집입니다. 남향이라 겨울에도 따뜻하고 관리비도 저렴한 편이에요.
2. 역세권이라 출퇴근이 정말 편리합니다. 주변이 조용하고 깨끗해서 만족스러운 거주 환경이에요.
3. 넓은 거실과 채광 좋은 방이 마음에 듭니다. 관리비도 저렴하고 관리 상태도 깨끗합니다.
4. 조용한 주거 환경이 가장 큰 장점입니다. 밝은 실내와 넓은 수납공간 덕분에 생활이 편리해요.
5. 남향 배치라 채광이 훌륭하고 평지에 위치해서 다니기 편합니다. 깨끗하고 편리한 동네입니다.
6. 전반적으로 만족스러운 아파트입니다. 관리비가 저렴하고 조용하며 밝은 실내가 좋습니다.
7. 교통이 편리하고 주변 인프라가 잘 갖춰져 있습니다. 넓은 평수에 채광도 좋아서 만족합니다.
8. 깨끗한 단지 관리와 조용한 환경이 마음에 듭니다. 역세권이고 평지라서 접근성이 뛰어나요.
9. 실거주 만족하며 살고 있습니다. 채광 좋고 조용하며 관리비도 합리적입니다. 역세권이라 편리해요.
10. 넓고 밝은 거실이 가장 큰 장점이에요. 남향이라 햇빛이 잘 들어오고 주변이 깨끗하고 편리합니다.

**부정 (5개)**:
1. 층간소음이 심해서 스트레스를 많이 받습니다. 건물도 노후되어 관리비도 비싼 편이에요.
2. 어둡고 좁은 방이 단점입니다. 언덕 위에 있어서 오르내리기 불편하고 시끄러운 도로변입니다.
3. 관리비가 비싸고 건물이 노후되었습니다. 층간소음도 심하고 주변 편의시설까지 멀어 불편합니다.
4. 역에서 너무 멀고 언덕길이라 출퇴근이 불편합니다. 방이 좁고 어두워서 답답한 느낌이 들어요.
5. 노후 건물이라 하자가 많습니다. 좁은 공간에 층간소음까지 심해서 추천하기 어렵습니다.

**중립 (5개)**:
1. 전반적으로 무난한 아파트입니다. 가격 대비 적당한 수준이라 생각합니다. 교통은 보통입니다.
2. 채광은 좋은데 층간소음이 조금 있습니다. 역세권이지만 관리비가 약간 비싼 편이에요.
3. 위치는 편리한데 건물이 좀 오래되었습니다. 넓은 편이지만 어두운 방이 하나 있어요.
4. 조용한 편이지만 역에서 조금 멀어요. 깨끗하게 관리되고 있지만 좁은 베란다가 아쉽습니다.
5. 평지라 이동은 편한데 주변이 약간 시끄럽습니다. 밝고 깨끗한 실내는 좋지만 관리비가 나옵니다.

### 10.3 다음 단계

| 순서 | 작업 | 상태 |
|------|------|------|
| 1 | Redis `stats:*` 키에 REVIEW_STATISTICS 동기화 | ⏳ 미진행 |
| 2 | 하이브리드 추천 점수 검증 테스트 | ⏳ 미진행 |
| 3 | Cold Start 분기 검증 테스트 | ⏳ 미진행 |
| 4 | WHEREBOARD, COMMENTTBL 데이터 생성 (최후순위) | ⏳ 미진행 |
