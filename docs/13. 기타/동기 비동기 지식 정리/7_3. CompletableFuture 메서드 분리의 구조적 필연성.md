# CompletableFuture 메서드 분리의 구조적 필연성
## thenAccept()와 thenAcceptAsync()의 설계 철학 및 책임 경계 분리 원리

---

## 1. 서론: 단일 메서드 통합의 구조적 불가능성

### 1.1 직관적 의문과 그 함정

"동일 스레드에서 실행될 거라면 `thenAccept()` 메서드로 분리하지 말고 `supplyAsync()` 내부에서 모든 로직을 한 번에 처리하는 것이 낫지 않은가?" 이 질문은 CompletableFuture 체이닝 API의 근본적인 설계 의도를 정면으로 건드린다. 표면적으로는 타당해 보이는 이 직관은, 비동기 프로그래밍에서 가장 핵심적인 두 가지 개념을 혼동한 결과다. 바로 **작업의 논리적 경계(logical boundary)**와 **작업의 물리적 실행 위치(physical execution location)**의 혼동이다.

Java의 초기 비동기 API인 Future는 이 두 개념을 분리하지 못했다. `Future.get()`은 값을 생성하는 작업만 표현할 수 있었고, 생성된 값을 어떻게 처리할지는 호출자가 블로킹하여 직접 꺼내서 처리해야 했다. 이는 값의 생산과 소비를 시간적으로는 분리할 수 있었지만, 구조적으로는 결합시켰다. 호출자 코드는 Future가 완료될 때까지 블로킹되며, 완료 즉시 동일한 스레드에서 후속 처리를 수행해야 했다.

### 1.2 CompletableFuture가 해결하려 한 구조적 문제

CompletableFuture의 체이닝 API는 이 구조적 결합을 해체하기 위해 등장했다. 핵심 설계 목표는 **"값의 생산자(Producer)"와 "값의 소비자(Consumer)"를 완전히 독립적인 실행 단위로 분리하여, 각각이 독립적인 생명주기와 실행 전략을 가질 수 있게 하는 것"**이다. 이는 단순히 코드를 여러 메서드로 나누는 것이 아니라, 서로 다른 관심사(concern)를 구조적으로 격리하여 각각을 독립적으로 제어 가능하게 만드는 아키텍처적 결정이다.

이 분리가 없다면, 비동기 작업의 조합(composition), 재사용(reusability), 그리고 실행 정책의 독립적 제어(independent execution policy control)가 모두 불가능해진다. CompletableFuture는 이를 해결하기 위해 각 처리 단계를 독립적인 CompletableFuture 객체로 표현하고, 이들을 조합할 수 있는 연산자들을 제공한다.

---

## 2. 본론: 책임 경계 분리의 메커니즘과 설계적 영향

### 2.1 thenAccept()와 thenAcceptAsync()의 본질적 차이

두 메서드의 차이는 단순히 "어느 스레드에서 실행되는가"의 문제가 아니다. 이는 **"후속 작업의 실행 주체 결정권을 누가 가지는가"**라는 제어권(control authority) 문제다.

`thenAccept()`는 이전 단계를 완료한 스레드가 후속 작업까지 연속적으로 처리하는 구조다. 이것이 가능한 이유는 CompletableFuture 내부의 완료 메커니즘(completion mechanism) 때문이다. `supplyAsync()`의 작업이 완료되면, 해당 워커 스레드는 즉시 내부의 completion stack을 순회하며 등록된 후속 작업들을 확인한다. `thenAccept()`가 등록되어 있으면 스레드 컨텍스트 전환 없이 바로 실행한다. 이는 스레드 전환 비용(context switch overhead)을 제거하고 CPU 캐시 지역성(cache locality)을 유지하여 처리 지연시간을 최소화한다.

반면 `thenAcceptAsync()`는 후속 작업을 반드시 별도 스레드에 제출(submit)하여 실행한다. 내부 동작 흐름을 살펴보면, `supplyAsync()`를 실행한 워커 스레드가 작업을 완료한 후 `thenAcceptAsync()`가 등록된 것을 감지하면, 이를 직접 실행하지 않고 executor에 새로운 작업으로 제출한다. 완료 스레드는 즉시 ForkJoinPool로 반환되어 다른 작업을 수행할 수 있고, 별도의 사용 가능한 스레드가 큐에서 이 작업을 가져가 실행한다.

이 차이의 설계적 의미는 명확하다. `thenAccept()`는 "작업 완료 스레드"를 최대한 효율적으로 활용하여 경량 후속 처리를 수행하는 전략이고, `thenAcceptAsync()`는 "작업 완료"와 "후속 처리"를 명시적으로 격리하여 각각의 특성에 맞는 스레드 풀 정책을 적용하는 전략이다.

### 2.2 단일 메서드 통합이 초래하는 구조적 문제

만약 모든 로직을 `supplyAsync()` 내부에 통합한다면 어떤 문제가 발생하는가를 구체적으로 분석해보자.

#### 책임 혼재와 단일 책임 원칙 위반

```java
// 안티패턴: 모든 책임이 하나의 실행 블록에 결합됨
CompletableFuture.supplyAsync(() -> {
    // 값 생성 책임
    int result = MemberService.getMembers().count();
    
    // 값 소비 책임
    System.out.println("Result: " + result);
    
    // 이후 처리 로직
    logger.info("Processing completed");
    
    // 반환값도 애매함 - 이미 소비했는데 뭘 반환하나?
    return result; // 또는 null?
});
```

이 코드는 "값을 생성하는 책임"과 "값을 소비하는 책임"을 하나의 실행 컨텍스트에 강제로 결합시킨다. 생산자는 더 이상 순수한 값 생성자가 아니라 "값을 생성하고 동시에 특정 방식으로 소비하는 복합 작업"이 되어버린다. 이는 단일 책임 원칙(Single Responsibility Principle)의 명백한 위반이며, 코드의 재사용성과 테스트 가능성을 근본적으로 훼손한다.

#### 조합 가능성의 완전한 상실

CompletableFuture의 진짜 가치는 개별 비동기 작업이 아니라 여러 비동기 작업을 선언적으로 조합할 수 있는 능력이다. 이는 각 단계가 독립적인 CompletableFuture 객체로 표현될 때만 가능하다.

15개의 외부 API를 병렬로 호출하고 모두 완료되면 결과를 집계하는 시나리오를 고려해보자. 체이닝 방식에서는 각 API 호출이 독립적인 `CompletableFuture<ApiResponse>`로 존재하므로, `CompletableFuture.allOf()` 같은 조합 연산자로 이들을 합칠 수 있다. 이때 각 Future는 독립적으로 완료되고, 모든 완료를 기다린 후 집계 로직이 실행된다. 이 과정에서 개별 API 완료 시점은 서로 독립적이며, 전체 파이프라인의 병렬성이 최대한 활용된다.

반면 모든 로직을 `supplyAsync()` 내부에 넣으면 이런 조합이 불가능하다. API A를 호출하는 `supplyAsync()` 안에서 API B의 완료를 기다리려면 `futureB.join()`을 호출해야 하는데, 이는 API A를 실행하는 워커 스레드를 블로킹시켜버린다. 비동기 프로그래밍은 본질적으로 **로직을 독립적으로 분리하여 병렬적으로 실행 가능하도록 설계한 구조**인데, 이렇게 하면 이러한 구조적 개선 이점이 완전히 사라진다. 두 API가 진정으로 병렬 실행되려면, 각각의 완료가 독립적인 Future 객체로 표현되어야 하고, 조합 로직은 별도의 단계(`thenCombine`, `allOf` 등)로 분리되어야 한다.

더 복잡한 시나리오에서 이 한계는 더욱 명확해진다. 10개의 API를 병렬 호출하고 가장 먼저 완료된 3개의 결과만 사용하는 경우, 체이닝 구조에서는 각 API 호출이 독립적인 Future로 존재하므로 `List<CompletableFuture<T>>`로 관리하고 커스텀 조합 로직을 적용할 수 있다. 하지만 모든 로직이 `supplyAsync()` 내부에 있다면, 개별 작업의 완료 상태를 외부에서 관찰하거나 제어할 방법이 없다. 각 `supplyAsync()`는 고립된 실행 블록일 뿐, 다른 작업과의 협력이나 조율이 구조적으로 불가능하다.

#### 실행 정책의 독립적 제어 불가능

후속 작업의 성격에 따라 다른 스레드 풀을 사용해야 하는 경우가 빈번하다. 외부 API 호출(I/O 작업)은 블로킹을 허용하는 큰 스레드 풀이 필요하고, 결과 집계(CPU 작업)는 코어 수만큼의 작은 스레드 풀이 적합하다. 체이닝 구조에서는 이것이 자연스럽게 표현된다.

```java
CompletableFuture
    .supplyAsync(() -> callExternalApi(), ioExecutor)     // I/O 전용 스레드 풀
    .thenApplyAsync(data -> parseData(data), cpuExecutor) // CPU 전용 스레드 풀
    .thenAcceptAsync(result -> saveToDb(result), ioExecutor); // 다시 I/O 풀로
```

각 단계가 자신의 성격에 맞는 Executor를 지정할 수 있다. 만약 모든 로직을 `supplyAsync()` 안에 넣는다면, API 호출 다음에 바로 파싱과 DB 저장을 수행하게 되고, 이 모든 작업이 I/O 스레드 풀의 스레드를 점유한다. CPU 집약적 파싱 작업이 I/O 스레드를 점유하는 동안 다른 I/O 작업들이 대기하게 되어 전체 시스템의 처리량이 저하된다. 더 심각한 것은, 이런 문제를 인식하더라도 코드 구조를 완전히 변경하지 않고는 해결할 방법이 없다는 점이다.

#### 에러 처리 경계의 붕괴

CompletableFuture의 체이닝 구조는 에러 처리 경계를 명확하게 정의할 수 있게 한다. `supplyAsync()`에서 예외가 발생하면, 이 예외는 CompletableFuture 내부에 캡슐화되어 예외 완료(exceptional completion) 상태로 전환된다. 이후 체인에 연결된 `thenAccept()`, `thenApply()` 등은 모두 건너뛰어지고, `exceptionally()` 또는 `handle()` 같은 에러 처리 단계만 실행된다.

```java
CompletableFuture
    .supplyAsync(() -> callApi())           // 여기서 예외 발생 가능
    .thenApply(data -> parse(data))         // 건너뜀
    .thenAccept(result -> process(result))  // 건너뜀
    .exceptionally(ex -> {
        logger.error("Pipeline failed", ex);
        return null;
    });
```

이 구조는 "정상 경로"와 "예외 경로"를 완전히 분리한다. 어느 단계에서 예외가 발생하든 에러 핸들러로 전달되며, 정상 로직은 예외 처리 코드에 오염되지 않는다. 반면 모든 로직을 `supplyAsync()` 안에 넣으면 try-catch 블록이 전체 로직을 감싸게 되고, 어느 단계에서 실패했는지 구분하기 위해 중첩된 try-catch나 상태 변수가 필요해진다. 더 중요한 것은, "부분 성공"을 표현할 방법이 없다는 점이다. 4단계 파이프라인에서 2단계까지는 성공했지만 3단계에서 실패한 경우, 체이닝 구조에서는 앞 단계의 결과를 유지하고 있으므로 이를 활용한 fallback 로직을 작성할 수 있다. 하지만 단일 블록 구조에서는 예외 발생 즉시 모든 중간 상태가 소실된다.

### 2.3 추상화 계층으로서의 메서드 분리

메서드 분리의 가장 근본적인 이유는 **비동기 작업을 조합 가능한 독립적 객체(First-Class Object: 변수에 저장하고, 인자로 전달하고, 다른 작업과 조합할 수 있는 완전한 객체)로 다룰 수 있게 하는 추상화 계층**을 만들기 위함이다. `supplyAsync()`는 "값을 생산하는 비동기 작업"이라는 추상을 CompletableFuture 객체로 구체화하고, `thenAccept()`, `thenApply()`, `thenCombine()` 등은 이 추상 위에서 작동하는 조합 연산자들이다. 각 연산자는 명확한 역할 분담을 갖는다:
- `thenAccept()`: 완료된 값을 받아 소비만 수행 (반환값 없음, 부수 효과용)
- `thenApply()`: 완료된 값을 받아 변환하고 새로운 CompletableFuture 반환 (값 변환용)
- `thenCombine()`: 두 개의 독립적 Future를 병렬 실행 후 결과를 결합 (병렬 조합용)

이는 함수형 프로그래밍에서 Stream API가 컬렉션 연산을 추상화한 것과 동일한 패턴이다. `stream().map().filter().collect()`에서 각 단계가 분리되어 있는 것은 코드를 나누기 위함이 아니라, 각 변환을 독립적으로 표현하고 재조합 가능하게 하기 위함이다. CompletableFuture도 마찬가지로, 비동기 작업의 각 단계를 독립적인 변환으로 표현함으로써 복잡한 비동기 플로우를 선언적으로 구성할 수 있게 한다.

함수형 프로그래밍의 Monad 패턴 관점에서 보면, 이 분리는 더욱 명확해진다. Monad에서 'wrap(감싸기)'과 'flatMap(변환 및 평탄화)'은 서로 다른 관심사를 다루는 독립적인 연산이며, CompletableFuture는 이를 정확히 구현한다.

```java
// Monad 패턴의 일관된 구현
Optional.of(value)                          // wrap
    .map(transformer);                      // transform

Stream.of(value)                            // wrap
    .map(transformer);                      // transform

CompletableFuture.supplyAsync(() -> value)  // wrap (비동기 컨테이너로)
    .thenApply(transformer);                // transform (컨테이너 내 값을)
```

만약 "동일 스레드에서 실행될 거라면 하나로 합치자"는 논리를 따른다면, Stream에서도 "어차피 한 번의 반복문으로 처리될 거라면 map과 filter를 분리할 필요가 없다"고 주장해야 한다. 하지만 실제로는 각 단계의 분리가 코드의 재사용성, 테스트 가능성, 조합 가능성을 극적으로 향상시킨다. CompletableFuture의 체이닝도 정확히 같은 이유로 존재한다.

### 2.4 적응적 실행 전략의 설계 철학

`thenAccept()`와 `thenAcceptAsync()`가 모두 존재하는 이유는, 후속 작업의 성격에 따라 최적의 실행 전략을 선택할 수 있게 하기 위함이다. 이는 단순한 "성능 최적화 옵션"이 아니라, **시스템 자원 관리의 책임을 개발자에게 명시적으로 위임**하는 설계 결정이다.

`thenAccept()`는 후속 작업이 경량이고 빠르게 완료될 때 사용한다. 단순 로깅, 간단한 값 변환, 메모리 내 상태 업데이트 등이 이에 해당한다. 이런 경우 스레드 전환 비용(약 1-10μs)이 작업 자체의 실행 시간보다 클 수 있으므로, 완료 스레드에서 연속 실행하는 것이 효율적이다. 또한 이전 작업과 후속 작업이 논리적으로 하나의 처리 단위일 때, CPU 캐시에 이미 로드된 데이터를 그대로 활용할 수 있어 캐시 미스(cache miss)를 줄일 수 있다.

`thenAcceptAsync()`는 후속 작업이 무겁거나 블로킹 가능성이 있을 때 사용한다. 데이터베이스 쓰기, 파일 I/O, 추가적인 외부 API 호출 등이 이에 해당한다. 이런 경우 이전 작업의 워커 스레드를 빠르게 반환하여 다른 비동기 작업이 사용할 수 있게 하는 것이 전체 시스템의 처리량(throughput) 관점에서 유리하다. 특히 ForkJoinPool.commonPool() 같은 공유 스레드 풀을 사용할 때, 한 작업이 스레드를 오래 점유하면 다른 모든 비동기 작업이 대기하게 되어 시스템 전체가 느려질 수 있다.

### 2.5 실제 런타임 동작의 증명

```java
// Case 1: thenAccept() - 동일 스레드 연속 실행
CompletableFuture.supplyAsync(() -> {
    System.out.println("Supply: " + Thread.currentThread().getName());
    // 출력: ForkJoinPool.commonPool-worker-1
    return 100;
}).thenAccept(result -> {
    System.out.println("Accept: " + Thread.currentThread().getName());
    // 출력: ForkJoinPool.commonPool-worker-1 (동일 스레드)
    System.out.println("Result: " + result);
});

// Case 2: thenAcceptAsync() - 별도 스레드 할당
CompletableFuture.supplyAsync(() -> {
    System.out.println("Supply: " + Thread.currentThread().getName());
    // 출력: ForkJoinPool.commonPool-worker-1
    return 200;
}).thenAcceptAsync(result -> {
    System.out.println("Accept: " + Thread.currentThread().getName());
    // 출력: ForkJoinPool.commonPool-worker-2 또는 main (다른 스레드)
    System.out.println("Result: " + result);
});

// Case 3: Fast Path - 이미 완료된 Future
CompletableFuture<Integer> alreadyCompleted = CompletableFuture.completedFuture(300);
alreadyCompleted.thenAccept(result -> {
    System.out.println("Accept: " + Thread.currentThread().getName());
    // 출력: main (호출한 스레드에서 즉시 실행)
});
```

이 실행 결과는 CompletableFuture의 적응적 실행 전략을 명확히 보여준다. Case 1에서는 워커 스레드가 `supplyAsync()` 완료 후 `thenAccept()`까지 연속 실행한다. Case 2에서는 명시적으로 다른 스레드에 작업을 제출한다. Case 3은 Fast Path 최적화를 보여주는데, Future가 이미 완료되었으므로 별도 스레드 할당 없이 호출자 스레드에서 즉시 처리한다.

---

## 3. 결론: 설계 철학으로서의 책임 분리

### 3.1 패러다임 전환: 실행에서 조합으로

CompletableFuture의 메서드 분리는 비동기 프로그래밍에서 **"어떻게 실행하는가"에서 "어떻게 조합하는가"로 관심사를 전환**시켰다. 이는 단순한 구현 기법이 아니라 사고방식의 근본적인 변화다.

전통적인 스레드 기반 동시성에서 개발자는 "어느 스레드에서 무엇을 실행할 것인가"를 명시적으로 관리했다. Thread 객체를 생성하고, Runnable을 정의하고, ExecutorService에 제출하는 일련의 과정이 모두 수동적이었다. CompletableFuture는 이를 추상화하여, 개발자가 "작업 간의 의존성과 변환 관계"만 선언하면 시스템이 최적의 실행 전략을 선택하도록 위임한다. 이는 명령형(imperative)에서 선언형(declarative) 프로그래밍으로의 전환이다.

### 3.2 아키텍처적 영향

이 설계 철학은 현대 백엔드 시스템 아키텍처에 깊은 영향을 미쳤다. 마이크로서비스에서 여러 서비스를 병렬 호출하고 결과를 집계하는 패턴, 리액티브 시스템에서 이벤트 스트림을 변환하고 조합하는 파이프라인, API Gateway에서 여러 downstream 서비스를 조율하는 오케스트레이션 모두 CompletableFuture의 조합 패턴에 기반한다.

특히 실무에서 15개의 외부 API를 병렬 호출하고 결과를 집계하는 경우, 각 API 호출을 독립적인 `CompletableFuture`로 표현하고 `CompletableFuture.allOf()`로 조합하는 것이 표준 패턴이다. 이때 각 API의 실행과 결과 처리가 분리되어 있기 때문에, 일부 API 실패 시 fallback 로직을 적용하거나, 가장 빠른 응답만 사용하는 등의 유연한 전략을 적용할 수 있다.

### 3.3 설계적 책임과 실무 가이드라인

CompletableFuture의 메서드 분리는 개발자에게 새로운 설계 책임을 부여한다.

**스레드 안전성 고려**: 어떤 스레드가 후속 작업을 실행할지 예측할 수 없으므로, 공유 상태에 접근하는 모든 코드는 스레드 안전해야 한다. `thenAccept()` 내부에서 인스턴스 변수를 수정하는 것은 Race Condition을 유발할 수 있다.

**Executor 선택 전략**: 작업의 성격(I/O vs CPU, 블로킹 vs 논블로킹)에 따라 적절한 Executor를 선택해야 한다. ForkJoinPool.commonPool()은 CPU 집약적 비블로킹 작업에 적합하고, 커스텀 ThreadPoolExecutor는 블로킹 I/O 작업에 적합하다.

**체이닝 깊이 관리**: 너무 긴 체이닝은 스택 오버플로우 위험이 있고 디버깅을 어렵게 만든다. 논리적으로 관련된 변환들을 그룹화하고, 중간에 의미 있는 CompletableFuture를 변수로 추출하여 가독성을 높여야 한다.

**에러 처리 전략**: 각 단계에서 발생 가능한 예외를 명시적으로 처리하고, 파이프라인 끝에 `exceptionally()` 또는 `handle()`을 배치하여 전체 에러를 catch해야 한다.

---

## 4. 실무 적용 패턴

### 4.1 메서드 선택 기준

후속 작업의 특성에 따라 `thenAccept()`와 `thenAcceptAsync()` 중 하나를 선택한다.

**thenAccept() 사용 시나리오:**
- 후속 작업이 극히 경량일 때 (100μs 이하): 단순 로깅, 카운터 증가, 플래그 설정
- 이전 작업과 강하게 결합된 논리적 단위일 때: API 응답 파싱과 검증
- 캐시 지역성이 중요할 때: 이전 단계에서 로드한 데이터를 즉시 사용하는 변환

**thenAcceptAsync() 사용 시나리오:**
- 후속 작업이 무겁거나 블로킹 가능성이 있을 때: DB 쓰기, 파일 I/O, 추가 네트워크 호출
- 이전 작업의 스레드 풀이 빠르게 반환되어야 할 때: ForkJoinPool.commonPool() 사용 시
- 서로 다른 특성의 작업을 격리할 때: I/O → CPU 변환, CPU → I/O 변환
- 장시간 실행되는 작업으로 인한 스레드 풀 고갈을 방지할 때

### 4.2 15개 API 병렬 처리 패턴 (실무 예시)

```java
public SafetyScore calculateSafety(Coordinate coord) {
    // 1단계: 15개 API를 각각 독립적인 Future로 호출
    CompletableFuture<CrimeData> crimeFuture = 
        CompletableFuture.supplyAsync(() -> kakaoApi.getCrime(coord), ioExecutor);
    
    CompletableFuture<PoliceData> policeFuture = 
        CompletableFuture.supplyAsync(() -> kakaoApi.getPolice(coord), ioExecutor);
    
    // ... 나머지 13개 API Future 생성
    
    // 2단계: 각 데이터를 점수로 변환 (CPU 작업이므로 별도 Executor)
    CompletableFuture<Integer> crimeScoreFuture = crimeFuture
        .thenApplyAsync(data -> CrimeScoreCalculator.calculate(data), cpuExecutor);
    
    // 3단계: 모든 점수가 준비되면 집계 (경량 작업이므로 thenApply 사용)
    CompletableFuture<SafetyScore> finalScore = CompletableFuture
        .allOf(crimeScoreFuture, policeScoreFuture /*, ... */)
        .thenApply(v -> new SafetyScore(
            crimeScoreFuture.join(),
            policeScoreFuture.join()
            // ...
        ));
    
    // 4단계: 성능 로깅 (부수 효과이므로 thenAccept 사용)
    finalScore.thenAccept(score -> 
        performanceLogger.log("Total calculation", score)
    );
    
    return finalScore.join();
}
```

이 패턴의 핵심은 각 단계가 명확하게 분리되어 있다는 점이다. API 호출 → 점수 계산 → 집계 → 로깅의 각 단계가 독립적인 책임을 가지며, 각각에 최적의 실행 전략(Executor 선택, 동기/비동기 결정)이 적용된다.

### 4.3 에러 처리 및 Fallback 전략

```java
CompletableFuture<Integer> apiResult = CompletableFuture
    .supplyAsync(() -> callExternalApi(), ioExecutor)
    .thenApplyAsync(data -> parseData(data), cpuExecutor)
    .exceptionally(ex -> {
        logger.warn("API call failed, using fallback", ex);
        return getFallbackData();
    })
    .thenAccept(result -> processResult(result));
```

각 단계가 분리되어 있으므로, 어느 지점에서 실패하든 `exceptionally()`로 catch되고 fallback 로직이 실행된다. 만약 모든 로직이 하나의 `supplyAsync()` 안에 있었다면 이런 세밀한 에러 처리는 불가능하다.

---

## 5. 맺음말

"왜 `thenAccept()`로 분리하는가?"라는 질문에 대한 답은 단순하지 않다. 이는 비동기 프로그래밍의 본질, 함수형 프로그래밍의 조합 원리, 시스템 자원 관리 전략, 그리고 소프트웨어 아키텍처의 설계 철학이 모두 얽혀있는 복잡한 문제다.

CompletableFuture의 메서드 분리는 "코드를 나누는 것"이 아니라 **"서로 다른 추상화 계층을 구조적으로 정의하는 것"**이다. 이 분리가 없다면, 비동기 작업의 조합, 재사용, 독립적 제어가 모두 불가능해진다. 실행 스레드가 같은지 다른지는 성능 최적화 차원의 구현 세부사항일 뿐, 메서드를 분리하는 근본 이유는 각 단계가 독립적인 책임과 생명주기를 가지는 완결된 실행 단위이기 때문이다.

개발자는 이제 "어느 스레드에서 무엇을 실행할 것인가"가 아니라, "비동기 작업의 의존성과 변환 관계를 어떻게 설계할 것인가"를 고민해야 한다. 이것이 CompletableFuture가 Java 비동기 프로그래밍에 가져온 진정한 패러다임 전환이다.

---

## 별첨 A: CompletableFuture 설계 철학 심화 학습 자료

CompletableFuture의 진정한 설계 의도를 이해하려면 강의나 튜토리얼을 넘어 다음 자료들을 참고해야 한다.

### A.1 공식 문서 및 설계자 자료

**Java 공식 JavaDoc - CompletableFuture 클래스**
- URL: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html
- 설명: Doug Lea가 작성한 클래스 레벨 JavaDoc에는 설계 의도와 사용 패턴이 명시되어 있다. 특히 "A CompletableFuture may have dependent completion actions" 섹션은 completion mechanism의 핵심을 설명한다.

**Doug Lea의 논문 및 발표 자료**
- "Scalable IO in Java" (http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)
- "Fork/Join Framework" 관련 JSR-166 문서
- 설명: CompletableFuture의 설계자인 Doug Lea의 원문 자료. 비동기 I/O와 task scheduling의 이론적 배경을 다룬다.

### A.2 함수형 프로그래밍 및 Monad 이론

**"Functional Programming in Scala" - Paul Chiusano, Rúnar Bjarnason**
- Chapter 7: Purely functional parallelism
- 설명: CompletableFuture와 유사한 비동기 추상화를 순수 함수형 관점에서 설계하는 과정을 단계별로 보여준다. Future/Promise의 수학적 기반을 이해하는 데 필수적이다.

**Monad 개념**
- 참고: "Learn You a Haskell for Great Good!" - Chapter on Monads
- 설명: CompletableFuture는 Monad의 일종이다. flatMap(thenCompose), map(thenApply), pure(completedFuture)의 관계를 이해하면 왜 메서드가 이렇게 분리되어야 하는지 명확해진다.

### A.3 Reactive Programming 문헌

**"Reactive Programming with RxJava" - Tomasz Nurkiewicz, Ben Christensen**
- Chapter 2-3: Reactive extensions and operators
- 설명: CompletableFuture는 Reactive Streams의 단순화된 형태다. RxJava의 Observable 체이닝 메커니즘을 이해하면 CompletableFuture의 설계 철학이 더 명확해진다.

**"Reactive Design Patterns" - Roland Kuhn**
- Chapter on Future and Promise patterns
- 설명: 비동기 추상화를 시스템 아키텍처 수준에서 어떻게 활용하는지 실무 패턴을 제시한다.

### A.4 동시성 이론

**"Java Concurrency in Practice" - Brian Goetz**
- Chapter 6: Task Execution
- Chapter 8: Applying Thread Pools
- 설명: Executor 프레임워크의 설계 원리와 스레드 풀 관리 전략. CompletableFuture가 왜 특정 방식으로 스레드를 할당하는지 이해하는 데 필수적이다.

**"The Art of Multiprocessor Programming" - Maurice Herlihy, Nir Shavit**
- Chapter on Lock-Free Data Structures
- 설명: CompletableFuture의 completion stack은 lock-free concurrent stack으로 구현되어 있다. 이 이론적 배경을 이해하면 왜 특정 실행 전략이 채택되었는지 알 수 있다.

---

## 별첨 B: 엔지니어링과 컴퓨터 과학의 분리 - 학습 메타인지 분석

### B.1 문제의 근원: 실용주의적 학습의 맹점

대부분의 개발자 교육은 "엔지니어링(How to build)"에 집중하고 "컴퓨터 과학(Why it works)"을 생략한다. 이는 단기적으로는 효율적이지만, 장기적으로는 개발자의 사고 깊이를 제한한다.

**엔지니어링 관점의 CompletableFuture**: "비동기 작업을 연결하는 방법"
- thenApply는 값을 변환한다
- thenAccept는 값을 소비한다
- thenCombine은 두 Future를 합친다
- 이 관점에서는 "같은 스레드에서 실행될 거면 합치면 되지 않나"라는 질문이 타당하다.

**컴퓨터 과학 관점의 CompletableFuture**: "Monad를 이용한 계산의 조합(Composition of computations using monads)"
- CompletableFuture는 "아직 완료되지 않은 값"이라는 추상을 타입으로 표현한 것
- thenApply는 functor의 map 연산, thenCompose는 monad의 flatMap 연산
- 각 단계의 분리는 수학적 조합 법칙(composition law)을 만족하기 위한 필연적 구조
- 이 관점에서는 메서드 통합은 근본적으로 불가능하다. 추상화 계층의 붕괴를 의미하기 때문이다.

### B.2 학습 방법론의 구조적 문제

**강의 기반 학습의 한계**
- 강의는 "How"를 가르치지 "Why"를 가르치지 않는다
- 수강생은 수동적 소비자가 되며, 강의가 다루지 않은 것은 알 수 없다
- 강사의 이해 깊이가 수강생의 천장이 된다

**실용주의적 사고의 역설**
- "작동하는가?"를 먼저 묻고 "왜 작동하는가?"는 나중에 묻는다
- 즉시 드러나는 비용(코드 라인 증가)은 높게 평가하고, 장기적 이익(조합 가능성, 재사용성)은 과소평가한다
- 현재 당면한 문제(15개 API를 400ms 이내에 처리)에만 집중하고, 근본 원리에 대한 탐구를 미룬다

**성능 중심 사고의 함정**
- CompletableFuture를 "성능 최적화 도구"로만 인식
- 비동기 프로그래밍의 본질은 성능이 아니라 "제어 흐름의 재구조화"임을 놓침
- "병렬 실행 = 성능 향상"이라는 단순 도식에 갇힘

### B.3 컴퓨터 과학 학습의 필요성

엔지니어링만 학습한 개발자는 "도구 사용자(Tool User)"에 머물지만, 컴퓨터 과학을 학습한 개발자는 "설계 사고자(Design Thinker)"가 된다.

**추상화 이해의 중요성**
- Optional, Stream, CompletableFuture는 모두 동일한 함수형 프로그래밍 패러다임의 구현이다
- 이들은 개별 기능이 아니라 하나의 일관된 추상화 체계다
- 이 체계를 이해하지 못하면 각 API를 외우는 수밖에 없지만, 이해하면 새로운 API를 보는 순간 그 설계 의도를 파악할 수 있다

**원리 기반 사고의 힘**
- "왜 이렇게 설계되었는가"를 이해하면, 유사한 문제를 만났을 때 스스로 설계할 수 있다
- 강의에서 다루지 않은 케이스를 만나도 원리에서 답을 유도할 수 있다
- 기술의 변화(Java → Kotlin, JavaScript → TypeScript)에도 동일한 원리가 적용됨을 인식한다

### B.4 균형 잡힌 학습 전략

**엔지니어링 학습**: 강의, 튜토리얼, 실습 프로젝트
- 목표: 빠르게 작동하는 코드를 작성하는 능력 획득
- 방법: 패턴 학습, 모방, 반복

**컴퓨터 과학 학습**: 논문, 공식 문서, 이론서
- 목표: 왜 그렇게 작동하는지 근본 원리 이해
- 방법: 수학적 증명, 추상화 모델링, 설계 의도 분석

**통합적 접근**
- 실무 문제를 만나면 엔지니어링 지식으로 빠르게 해결
- 해결 후 "왜 이 방법이 작동하는가" 질문하며 컴퓨터 과학 자료 탐구
- 이해한 원리를 다음 프로젝트에 적용하며 내재화

이번 학습 경험("왜 메서드를 분리하는가?"라는 질문)은 엔지니어링 학습의 한계를 인식하고 컴퓨터 과학 학습으로 전환하는 계기가 되어야 한다. 이는 단순히 CompletableFuture를 더 잘 이해하는 것을 넘어, **"기술의 피상적 사용에서 근본적 이해로"** 학습 패러다임을 전환하는 중요한 전환점이다.

---

## 별첨 C: 구현 메커니즘 계층의 추가 탐구 영역

### C.1 현재 문서의 학습 범위와 한계

본 문서는 CompletableFuture의 **설계 철학 계층(Design Philosophy Layer)**을 다룬다. 즉, "왜 이렇게 설계되었는가", "언제 어떤 메서드를 선택해야 하는가", "실무에서 어떻게 적용하는가"에 대한 답을 제공한다. 이는 CompletableFuture를 올바르게 사용하고 적절한 설계 결정을 내리기에 충분한 지식이다.

하지만 **구현 메커니즘 계층(Implementation Mechanism Layer)**은 의도적으로 생략되었다. 이는 "내부적으로 어떻게 작동하는가", "런타임에 어떤 조건으로 분기하는가", "동시성 제어는 어떻게 이루어지는가"에 대한 깊이 있는 탐구를 의미한다. 설계 철학만으로도 실무 적용은 가능하지만, 완전한 이해를 위해서는 구현 메커니즘까지 탐구해야 한다.

### C.2 Completion Stack Architecture의 내부 동작

본 문서 섹션 2.1에서 "Completion Stack"을 언급했지만, 그 실제 작동 메커니즘은 다루지 않았다. 완전한 이해를 위해서는 다음을 탐구해야 한다.

**UniCompletion 노드의 생성 및 연결 메커니즘**

`thenAccept()` 호출 시 CompletableFuture 내부에서 UniAccept 노드가 생성되고 completion stack에 연결된다. 이 과정은 OpenJDK의 `CompletableFuture.java` 소스코드에서 확인할 수 있다:

```java
// CompletableFuture 내부 구조
public CompletableFuture<Void> thenAccept(Consumer<? super T> action) {
    return uniAcceptStage(null, action);  // null: 동기 실행 신호
}

private CompletableFuture<Void> uniAcceptStage(Executor e, Consumer<? super T> f) {
    // 1. 새 CompletableFuture 생성
    // 2. UniAccept 노드 생성 (함수 f와 executor e 포함)
    // 3. 원본 Future가 이미 완료되었는지 확인
    //    - 완료됨: Fast Path - 현재 스레드에서 즉시 실행
    //    - 미완료: Slow Path - completion stack에 노드 추가
}
```

이 분기 로직을 직접 읽어야 "왜 때로는 main 스레드에서, 때로는 worker 스레드에서 실행되는가"를 정확히 이해할 수 있다. 강의 자료에서 본 실행 결과의 차이는 이 분기 조건의 결과물이다.

**Completion Stack 순회 및 실행 순서**

`supplyAsync()`의 워커 스레드가 작업을 완료하면, `postComplete()` 메서드를 호출하여 등록된 모든 completion 노드를 순회하며 실행한다. 이 과정에서:

- Stack 구조이므로 LIFO(Last In First Out) 순서로 처리되는가, 아니면 역순으로 처리되는가?
- 각 completion의 실행 중 예외가 발생하면 나머지 completion은 어떻게 되는가?
- 한 completion이 무거운 작업이라면 나머지 completion들은 대기하는가, 아니면 별도 스레드로 분산되는가?

이런 질문들은 실제 소스코드를 디버깅하며 step-by-step으로 추적해야만 답할 수 있다.

### C.3 스레드 할당 결정의 정확한 분기 조건

본 문서에서 "thenAccept()는 완료 스레드에서 실행되고, thenAcceptAsync()는 별도 스레드에서 실행된다"고 설명했지만, 정확한 분기 조건은 단순하지 않다.

**Executor 파라미터와 실행 주체의 관계**

```java
// 케이스 1: thenAccept(null 전달)
thenAccept(fn) → uniAcceptStage(null, fn)
// null이 의미하는 것: "Executor를 사용하지 않음" → 호출자 스레드 또는 완료 스레드에서 직접 실행

// 케이스 2: thenAcceptAsync(defaultExecutor 전달)
thenAcceptAsync(fn) → uniAcceptStage(defaultExecutor(), fn)
// defaultExecutor()는 ForkJoinPool.commonPool() 반환 → 반드시 이 풀에 제출

// 케이스 3: thenAcceptAsync(customExecutor 전달)
thenAcceptAsync(fn, customExecutor) → uniAcceptStage(customExecutor, fn)
// 지정된 커스텀 Executor에 제출
```

하지만 실제로는 더 복잡한 조건들이 존재한다:

- 원본 Future가 이미 완료된 상태에서 thenAccept()를 호출하면, "완료 스레드"가 없으므로 호출자 스레드(주로 main)가 실행한다 (Fast Path).
- 원본 Future가 아직 실행 중일 때 thenAccept()를 호출하면, 나중에 완료하는 워커 스레드가 실행한다 (Slow Path).
- 강의에서 본 `Thread.sleep(100)`을 추가하면 Fast Path/Slow Path 중 어느 경로로 가는지 달라진다. 이는 thenAccept() 등록 시점과 supplyAsync() 완료 시점의 상대적 타이밍에 의해 결정된다.

이런 타이밍 의존적 동작(timing-dependent behavior)을 정확히 이해하려면, 디버거로 실제 실행 흐름을 추적하며 각 시점의 Future 상태(result 필드 값, stack 구조)를 확인해야 한다.

### C.4 내부 동기화 메커니즘과 Thread Safety

CompletableFuture는 멀티스레드 환경에서 안전하게 작동해야 하므로, 내부적으로 정교한 동기화 메커니즘을 구현한다. 본 문서에서는 이를 다루지 않았으나, 완전한 이해를 위해서는 필수적이다.

**Lock-Free Completion Stack 구현**

Completion stack은 lock을 사용하지 않고 CAS(Compare-And-Swap) 연산으로 구현되어 있다. 여러 스레드가 동시에 completion 노드를 추가하려 할 때:

```java
// 내부 코드 (의사 코드)
do {
    Completion oldHead = this.stack;
    newNode.next = oldHead;
} while (!CAS(this.stack, oldHead, newNode));  // CAS 성공할 때까지 재시도
```

이런 lock-free 알고리즘은 높은 동시성 환경에서 성능을 보장하지만, 그 작동 원리를 이해하려면 메모리 모델(memory model)과 원자적 연산(atomic operation)에 대한 지식이 필요하다.

**Result 필드의 Volatile 가시성**

CompletableFuture의 result 필드는 volatile로 선언되어 있다:

```java
volatile Object result;  // 완료된 값 또는 예외
```

이는 한 스레드가 result에 값을 쓰면, 다른 모든 스레드가 즉시 최신 값을 볼 수 있도록 메모리 가시성(memory visibility)을 보장한다. 하지만 volatile의 정확한 의미론(semantics)—happens-before 관계, 메모리 배리어(memory barrier) 등—을 이해하지 못하면, 왜 이것만으로 충분한지, 언제 추가 동기화가 필요한지 판단할 수 없다.

**Completion 실행 중 상태 전이**

한 completion이 실행되는 동안 다른 스레드가 새로운 completion을 추가하려 하거나, 동시에 complete()를 호출하려 하면 어떻게 되는가? 이런 concurrent modification을 어떻게 안전하게 처리하는가? 이는 소스코드의 postComplete() 메서드와 tryFire() 메커니즘을 직접 읽어야만 이해할 수 있다.

### C.5 실무에서 구현 메커니즘 지식이 필요한 순간

대부분의 실무 상황에서는 설계 철학 수준의 이해로 충분하다. 하지만 다음과 같은 상황에서는 구현 메커니즘 지식이 필수적이다:

**복잡한 동시성 버그 디버깅**

운영 환경에서 간헐적으로 발생하는 Race Condition이나 Deadlock을 추적할 때, "어느 스레드가 어느 시점에 어떤 completion을 실행했는가"를 정확히 파악해야 한다. 이는 내부 메커니즘을 이해하지 못하면 불가능하다.

**극한 성능 최적화**

Latency-critical 시스템에서 마이크로초 단위 최적화가 필요할 때, Fast Path를 의도적으로 유도하거나, completion stack의 크기를 제어하거나, 특정 Executor 전략을 선택하는 등의 기법이 필요하다. 이는 내부 동작을 정확히 알아야만 가능하다.

**CompletableFuture 확장 또는 커스터마이징**

자체적인 비동기 프레임워크를 구축하거나, CompletableFuture를 확장하여 프로젝트 특화 기능을 추가할 때는 내부 아키텍처를 완전히 이해해야 한다.

### C.6 다음 학습 단계: 소스코드 탐구 방법론

구현 메커니즘 계층을 탐구하려면 다음 순서를 권장한다:

**1단계: OpenJDK 소스코드 다운로드 및 IDE 설정**

IntelliJ IDEA나 Eclipse에서 OpenJDK 소스를 첨부하여, CompletableFuture.java를 직접 읽을 수 있게 환경을 구성한다.

**2단계: 핵심 메서드 디버깅**

간단한 테스트 코드를 작성하고, 브레이크포인트를 설정하여 step-into로 내부 메서드를 추적한다:

```java
// 디버깅용 테스트 코드
CompletableFuture<Integer> cf = CompletableFuture
    .supplyAsync(() -> {
        return 100;  // 브레이크포인트 1
    })
    .thenAccept(result -> {
        System.out.println(result);  // 브레이크포인트 2
    });

cf.join();
```

브레이크포인트에서 멈춘 후 step-into로 들어가면:
- supplyAsync() → asyncSupplyStage() → UniSupply.tryFire()
- thenAccept() → uniAcceptStage() → UniAccept 노드 생성 → Fast/Slow Path 분기

이 과정을 직접 눈으로 확인하며 "ah-ha moment"를 경험한다.

**3단계: 주요 내부 클래스 분석**

- `Completion`: 모든 completion 노드의 추상 기반 클래스
- `UniCompletion`, `BiCompletion`: 단일/이중 의존성 completion
- `UniApply`, `UniAccept`, `UniRun`: 구체적인 변환 타입별 구현
- `Signaller`: 블로킹 대기를 위한 특수 completion

각 클래스의 역할과 상호작용을 UML 다이어그램으로 그려보면 전체 아키텍처가 명확해진다.

**4단계: 동시성 패턴 연구**

Doug Lea의 논문 "Scalable Synchronous Queues"와 "The java.util.concurrent Synchronizer Framework"를 읽으며, CompletableFuture에 적용된 lock-free 알고리즘의 이론적 배경을 이해한다.

---