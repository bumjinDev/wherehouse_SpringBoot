# 동기/비동기 및 블로킹/논블로킹: 완전 기술 백서

## 서론: 개념 혼동의 구조적 문제

### 널리 퍼진 오해의 현실

소프트웨어 개발 커뮤니티에서 "동기는 블로킹이고, 비동기는 논블로킹이다"라는 잘못된 등식이 널리 퍼져 있다. 이 오해는 단순한 용어 혼동을 넘어, 시스템 설계의 잘못된 선택으로 이어진다. 개발자가 "비동기"라고 믿고 구현한 시스템이 실제로는 블로킹되어 성능 병목이 발생하는 사례가 빈번하다.

### 문제 1: 개념의 혼재

많은 기술 문서와 블로그가 동기/비동기와 블로킹/논블로킹을 구분 없이 사용한다. Node.js를 "비동기 논블로킹"이라고 소개하는 문서가 있는가 하면, 같은 Node.js를 "논블로킹 I/O"라고만 설명하는 문서도 있다. 이런 혼재는 학습자에게 두 개념이 동일하다는 잘못된 인상을 준다.

### 문제 2: 실무적 혼란

개발자가 CompletableFuture를 사용하면서 "이제 우리 시스템은 완전 비동기"라고 착각한다. 하지만 실제로는 워커 스레드가 블로킹 I/O를 수행하고 있어, 스레드 풀이 고갈되는 문제가 발생한다. "비동기인데 왜 느리지?"라는 질문이 나오는 이유다.

### 문제 3: 잘못된 아키텍처 결정

"비동기가 항상 빠르다"는 오해로 인해, CPU 집약적 작업에 불필요하게 비동기 패턴을 적용하여 오히려 성능이 저하되는 경우가 있다. 반대로, I/O 집약적 작업에 동기-블로킹만 고집하다가 시스템 확장성이 한계에 부딪히는 경우도 흔하다.

**이 문서는 블로킹/논블로킹과 동기/비동기가 완전히 독립적인 두 개의 축임을 증명하고, 각 개념의 정확한 정의와 구현 메커니즘을 제시한다.**

---

## 1. 근본적 정의: 두 개의 독립적 질문

### 1.1 블로킹/논블로킹이 답하는 질문

블로킹과 논블로킹은 **"함수가 호출되었을 때, 그 함수가 언제 제어권을 반환하는가?"**라는 질문에 답한다.

이 질문은 순전히 함수 호출 메커니즘에 관한 것이다. 함수 f()를 호출했을 때, f()가 즉시 반환되는가, 아니면 어떤 조건이 만족될 때까지 반환을 지연하는가? 이것이 블로킹/논블로킹이 구분하는 유일한 기준이다.

**블로킹 함수의 정의**: 함수가 자신이 수행해야 할 작업을 완료할 때까지 호출자에게 제어권을 반환하지 않는다.

```java
// 블로킹 함수의 전형적 예
String data = inputStream.read();  // 데이터를 읽을 때까지 반환 안 함
System.out.println(data);          // 위 줄이 끝나야 실행됨
```

이 코드에서 `read()` 메서드는 실제로 데이터를 읽어올 때까지 반환하지 않는다. 네트워크에서 데이터가 도착하지 않았다면, 이 메서드는 데이터가 도착할 때까지 호출자 스레드를 붙잡고 있다. 호출자 관점에서는 `read()` 호출 이후의 코드를 실행할 수 없다.

**논블로킹 함수의 정의**: 함수가 즉시 제어권을 반환하며, 작업 완료 여부와 무관하게 호출자가 다음 코드를 실행할 수 있게 한다.

```java
// 논블로킹 함수의 전형적 예
int bytesRead = channel.read(buffer);  // 즉시 반환
if (bytesRead > 0) {
    processData(buffer);
} else {
    doOtherWork();  // 데이터 없어도 다른 일 가능
}
```

이 코드에서 `read()` 메서드는 데이터 유무와 관계없이 즉시 반환한다. 데이터가 있으면 읽은 바이트 수를 반환하고, 없으면 0이나 -1을 반환한다. 호출자는 반환값을 확인하여 다음 행동을 결정할 수 있다.

### 1.2 동기/비동기가 답하는 질문

동기와 비동기는 **"작업이 완료되었다는 사실을 누가, 어떻게 확인하는가?"**라는 질문에 답한다.

이 질문은 완료 통지 메커니즘에 관한 것이다. 어떤 작업을 요청했을 때, 그 작업이 끝났다는 것을 호출자가 능동적으로 확인하는가, 아니면 시스템이 수동적으로 알려주는가? 이것이 동기/비동기가 구분하는 유일한 기준이다.

**동기적 완료 확인의 정의**: 호출자가 작업 완료 여부를 직접 확인한다. 확인 방법은 반환값, 상태 조회, 명시적 대기 등 다양하다.

```java
// 동기적 완료 확인의 예 1: 반환값
String result = httpClient.get(url);  // 반환값 자체가 완료 증명

// 동기적 완료 확인의 예 2: 상태 조회
Future<String> future = executor.submit(task);
while (!future.isDone()) {  // 호출자가 능동적으로 확인
    Thread.sleep(100);
}
String result = future.get();
```

두 경우 모두 호출자가 완료 여부를 확인하는 주체다. 첫 번째는 반환값으로, 두 번째는 `isDone()` 호출로 확인한다.

**비동기적 완료 통지의 정의**: 시스템(또는 호출된 함수)이 작업 완료를 호출자에게 알린다. 통지 방법은 콜백, 이벤트, 메시지 등 다양하다.

```java
// 비동기적 완료 통지의 예: 콜백
httpClient.getAsync(url, new Callback() {
    @Override
    public void onComplete(String result) {
        // 시스템이 완료 시 이 메서드를 호출
        System.out.println("완료: " + result);
    }
});
// 호출자는 완료를 기다리지 않고 다음 코드 실행
doOtherWork();
```

이 경우 호출자는 콜백만 등록하고 즉시 다른 일을 한다. 작업이 완료되면 시스템이 콜백을 호출하여 완료를 알린다.

### 1.3 두 축의 독립성

블로킹/논블로킹과 동기/비동기가 독립적이라는 것은, 이 두 속성의 4가지 조합이 모두 가능하다는 의미다.

```
             제어권 반환 시점
             블로킹    논블로킹
완료   동기   동기-블로킹  동기-논블로킹
확인   비동기  비동기-블로킹 비동기-논블로킹
방식
```

이 매트릭스의 4개 칸이 모두 실제로 존재한다는 것을 보이면, 두 축이 독립적임이 증명된다.

---

## 2. 네 가지 조합의 실제 구현과 내부 메커니즘

### 2.1 동기-블로킹 (Synchronous-Blocking)

#### 개념적 정의

동기-블로킹은 가장 직관적이고 전통적인 프로그래밍 모델이다. 함수를 호출하면 작업이 완료될 때까지 기다리고(블로킹), 반환값으로 완료를 확인한다(동기).

#### 실제 구현: JDBC의 경우

```java
// JDBC를 이용한 데이터베이스 조회
public User findUserById(Long id) throws SQLException {
    String sql = "SELECT * FROM users WHERE id = ?";
    
    // 1. Connection 획득 (블로킹 가능)
    Connection conn = dataSource.getConnection();
    
    // 2. PreparedStatement 생성
    PreparedStatement pstmt = conn.prepareStatement(sql);
    pstmt.setLong(1, id);
    
    // 3. 쿼리 실행 (블로킹)
    ResultSet rs = pstmt.executeQuery();
    
    // 4. 결과 처리
    if (rs.next()) {
        return new User(
            rs.getLong("id"),
            rs.getString("name"),
            rs.getString("email")
        );
    }
    
    return null;
}
```

**이 코드에서 일어나는 일을 단계별로 분석하면:**

**단계 1: Connection 획득**

`dataSource.getConnection()`이 호출되면, 내부적으로 커넥션 풀에서 가용한 커넥션을 찾는다. 만약 모든 커넥션이 사용 중이면, 이 메서드는 커넥션이 반환될 때까지 대기한다.

```java
// HikariCP 내부 구현 (단순화)
public Connection getConnection() throws SQLException {
    // 커넥션 풀에서 가용 커넥션 대기
    PoolEntry poolEntry = connectionBag.borrow(timeout, MILLISECONDS);
    if (poolEntry == null) {
        throw new SQLException("Connection timeout");
    }
    return poolEntry.connection;
}
```

`connectionBag.borrow()`는 내부적으로 `Semaphore`나 `BlockingQueue`를 사용하며, 가용 리소스가 없으면 스레드를 WAITING 상태로 전환한다.

**단계 2: 쿼리 실행**

`pstmt.executeQuery()`가 호출되면, JDBC 드라이버는 다음 과정을 거친다:

1. SQL 문을 데이터베이스 프로토콜로 인코딩
2. 네트워크 소켓을 통해 데이터베이스 서버로 전송
3. 응답 대기 (이 시점에서 블로킹)
4. 응답 수신 및 파싱
5. ResultSet 객체 생성 및 반환

```java
// MySQL JDBC 드라이버 내부 (단순화)
public ResultSet executeQuery() throws SQLException {
    // SQL을 MySQL 프로토콜로 패킹
    byte[] queryPacket = buildQueryPacket(sql);
    
    // 소켓으로 전송
    socket.getOutputStream().write(queryPacket);
    
    // 응답 대기 (블로킹!!!)
    byte[] response = readFullResponse(socket.getInputStream());
    
    // 결과 파싱
    return parseResultSet(response);
}

private byte[] readFullResponse(InputStream in) {
    // 이 부분에서 실제 블로킹 발생
    int length = in.read();  // 첫 바이트 읽기 (블로킹)
    byte[] data = new byte[length];
    in.read(data);  // 전체 데이터 읽기 (블로킹)
    return data;
}
```

**스레드 상태 변화:**

```
시간    스레드 상태       수행 중인 작업
--------------------------------------------
0ms    RUNNING         executeQuery() 호출
1ms    RUNNING         쿼리 패킷 생성
2ms    RUNNING         소켓 write() 호출
3ms    WAITING         read() 호출 (블로킹 시작)
...    WAITING         (네트워크 응답 대기중)
103ms  WAITING         (계속 대기중)
104ms  RUNNABLE        데이터 도착, 깨어남
105ms  RUNNING         응답 파싱
106ms  RUNNING         ResultSet 반환
```

이 100ms 동안 스레드는 WAITING 상태이며, CPU를 전혀 사용하지 않는다. 하지만 스레드 자체는 점유되어 있어 다른 작업을 할 수 없다.

#### 커널 레벨에서 일어나는 일

```c
// Linux 커널의 socket read 구현 (단순화)
ssize_t sock_read(struct socket *sock, char *buffer, size_t len) {
    struct sock *sk = sock->sk;
    
    while (skb_queue_empty(&sk->receive_queue)) {
        // 수신 큐가 비어있으면
        set_current_state(TASK_INTERRUPTIBLE);
        add_wait_queue(&sk->wait_queue, current);
        
        schedule();  // CPU를 양보하고 대기
        
        // 패킷 도착 시 인터럽트 핸들러가 깨움
        remove_wait_queue(&sk->wait_queue, current);
    }
    
    // 데이터를 사용자 버퍼로 복사
    skb = skb_dequeue(&sk->receive_queue);
    copy_to_user(buffer, skb->data, len);
}
```

네트워크 카드에 패킷이 도착하면:
1. 하드웨어 인터럽트 발생
2. 인터럽트 핸들러가 패킷을 커널 버퍼로 복사
3. 해당 소켓의 wait_queue에 있는 스레드를 깨움
4. 스레드가 RUNNABLE 상태로 전환
5. 스케줄러가 CPU를 할당하면 실행 재개

### 2.2 동기-논블로킹 (Synchronous-Non-Blocking)

#### 개념적 정의

동기-논블로킹은 함수가 즉시 반환하지만(논블로킹), 호출자가 완료 여부를 직접 확인해야 한다(동기). 이는 "폴링(Polling)" 패턴으로 구현된다.

#### 실제 구현: Java NIO의 경우

```java
public class NonBlockingSocketReader {
    private SocketChannel channel;
    private ByteBuffer buffer = ByteBuffer.allocate(1024);
    
    public String readData() throws IOException {
        // 채널을 논블로킹 모드로 설정
        channel.configureBlocking(false);
        
        StringBuilder result = new StringBuilder();
        
        // 폴링 루프
        while (true) {
            // 논블로킹 읽기 시도
            int bytesRead = channel.read(buffer);
            
            if (bytesRead > 0) {
                // 데이터가 있으면 처리
                buffer.flip();
                result.append(StandardCharsets.UTF_8.decode(buffer));
                buffer.clear();
                
                // 메시지 완료 확인
                if (result.toString().endsWith("\n")) {
                    return result.toString();
                }
            } else if (bytesRead == 0) {
                // 데이터가 없음 - 다른 작업 수행 가능
                doOtherWork();
                
                // CPU 양보 (바쁜 대기 방지)
                Thread.yield();
            } else {
                // 연결 종료
                throw new EOFException();
            }
        }
    }
    
    private void doOtherWork() {
        // 데이터 대기 중 다른 작업 수행
        processBackgroundTasks();
        updateUI();
    }
}
```

**이 코드의 핵심 메커니즘:**

**단계 1: 논블로킹 모드 설정**

`channel.configureBlocking(false)`를 호출하면, 내부적으로 소켓을 논블로킹 모드로 전환한다.

```java
// SocketChannel 내부 구현
public SocketChannel configureBlocking(boolean block) {
    // native 메서드 호출
    IOUtil.configureBlocking(fd, block);
    return this;
}

// IOUtil의 native 구현 (C 코드)
void configureBlocking(int fd, boolean blocking) {
    int flags = fcntl(fd, F_GETFL);
    if (!blocking) {
        flags |= O_NONBLOCK;  // 논블로킹 플래그 설정
    } else {
        flags &= ~O_NONBLOCK;
    }
    fcntl(fd, F_SETFL, flags);
}
```

O_NONBLOCK 플래그가 설정되면, 커널은 데이터가 없을 때 대기하지 않고 즉시 EAGAIN 에러를 반환한다.

**단계 2: 논블로킹 읽기**

```c
// 커널의 논블로킹 소켓 읽기
ssize_t sock_read_nonblock(int fd, void *buf, size_t len) {
    struct socket *sock = sockfd_lookup(fd);
    
    if (skb_queue_empty(&sock->receive_queue)) {
        // 데이터 없으면 즉시 반환
        return -EAGAIN;  // Would block
    }
    
    // 데이터 있으면 복사 후 반환
    skb = skb_dequeue(&sock->receive_queue);
    int bytes = copy_to_user(buf, skb->data, len);
    return bytes;
}
```

**스레드 상태 분석:**

```
시간    스레드 상태    수행 중인 작업
----------------------------------------
0ms    RUNNING      channel.read() 호출
1ms    RUNNING      커널에 읽기 요청
2ms    RUNNING      -1 반환 (데이터 없음)
3ms    RUNNING      doOtherWork() 실행
10ms   RUNNING      channel.read() 재시도
11ms   RUNNING      100 bytes 읽음
12ms   RUNNING      데이터 처리
```

스레드가 한 번도 WAITING 상태로 전환되지 않는다. 항상 RUNNING 상태를 유지하며, 데이터가 없을 때는 다른 작업을 수행할 수 있다.

#### Selector를 이용한 효율적인 동기-논블로킹

단순 폴링은 CPU를 낭비한다. Java NIO는 Selector를 제공하여 효율적인 동기-논블로킹을 구현한다.

```java
public class SelectorBasedReader {
    private Selector selector;
    private ServerSocketChannel serverChannel;
    
    public void startServer() throws IOException {
        selector = Selector.open();
        serverChannel = ServerSocketChannel.open();
        serverChannel.configureBlocking(false);
        serverChannel.register(selector, SelectionKey.OP_ACCEPT);
        
        while (true) {
            // 이벤트 대기 (블로킹 가능하지만 타임아웃 설정 가능)
            int readyChannels = selector.select(1000);  // 최대 1초 대기
            
            if (readyChannels == 0) {
                // 타임아웃 - 다른 작업 수행
                performMaintenanceTasks();
                continue;
            }
            
            // 준비된 채널 처리 (논블로킹)
            Set<SelectionKey> selectedKeys = selector.selectedKeys();
            Iterator<SelectionKey> keyIterator = selectedKeys.iterator();
            
            while (keyIterator.hasNext()) {
                SelectionKey key = keyIterator.next();
                
                if (key.isAcceptable()) {
                    acceptConnection(key);
                } else if (key.isReadable()) {
                    readData(key);
                }
                
                keyIterator.remove();
            }
        }
    }
}
```

Selector는 내부적으로 OS의 I/O 다중화 메커니즘(Linux의 epoll, Windows의 IOCP)을 사용한다.

```c
// Linux epoll의 동작
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout) {
    // 준비된 이벤트가 있으면 즉시 반환
    if (ready_events_exist(epfd)) {
        return copy_events_to_user(events);
    }
    
    // 없으면 timeout 시간만큼 대기
    if (timeout > 0) {
        set_current_state(TASK_INTERRUPTIBLE);
        schedule_timeout(timeout);
    }
    
    return ready_event_count;
}
```

### 2.3 비동기-논블로킹 (Asynchronous-Non-Blocking)

#### 개념적 정의

비동기-논블로킹은 함수가 즉시 반환하고(논블로킹), 작업 완료 시 시스템이 콜백을 호출한다(비동기). 이것이 "이벤트 기반" 프로그래밍의 핵심이다.

#### 실제 구현: Java NIO.2 AsynchronousChannel

```java
public class AsyncFileReader {
    private AsynchronousFileChannel fileChannel;
    
    public void readFileAsync(String fileName) throws IOException {
        Path path = Paths.get(fileName);
        fileChannel = AsynchronousFileChannel.open(path);
        
        ByteBuffer buffer = ByteBuffer.allocate(1024);
        
        // 비동기 읽기 시작
        fileChannel.read(
            buffer,                    // 버퍼
            0,                        // 파일 위치
            buffer,                   // attachment
            new CompletionHandler<Integer, ByteBuffer>() {
                @Override
                public void completed(Integer bytesRead, ByteBuffer attachment) {
                    // 시스템이 I/O 완료 시 이 메서드 호출
                    System.out.println("읽기 완료: " + bytesRead + " bytes");
                    attachment.flip();
                    byte[] data = new byte[bytesRead];
                    attachment.get(data);
                    processData(data);
                }
                
                @Override
                public void failed(Throwable exc, ByteBuffer attachment) {
                    // 실패 시 호출
                    exc.printStackTrace();
                }
            }
        );
        
        // read() 메서드는 즉시 반환
        System.out.println("비동기 읽기 시작됨");
        
        // 다른 작업 즉시 수행 가능
        performOtherTasks();
    }
}
```

**내부 메커니즘 분석:**

**단계 1: AsynchronousFileChannel 생성**

```java
// AsynchronousFileChannel.open() 내부
public static AsynchronousFileChannel open(Path path) {
    // 비동기 I/O를 위한 스레드 풀 생성
    AsynchronousChannelGroup group = AsynchronousChannelGroup
        .withThreadPool(ForkJoinPool.commonPool());
    
    // 네이티브 파일 핸들 열기
    int fd = open(path.toString(), O_RDWR | O_DIRECT);
    
    // 비동기 채널 객체 생성
    return new UnixAsynchronousFileChannel(fd, group);
}
```

AsynchronousChannelGroup은 내부적으로 I/O 완료를 감지하는 스레드 풀을 관리한다.

**단계 2: 비동기 읽기 요청**

```java
// read() 메서드 내부 구현
public void read(ByteBuffer dst, long position, A attachment,
                 CompletionHandler<Integer, A> handler) {
    // I/O 요청 객체 생성
    PendingFuture<Integer, A> future = 
        new PendingFuture<>(this, handler, attachment);
    
    // 비동기 I/O 시작
    if (isWindows) {
        // Windows: IOCP 사용
        startWindowsAsyncRead(future);
    } else {
        // Linux: io_uring 또는 AIO 사용
        startLinuxAsyncRead(future);
    }
    
    // 즉시 반환 (논블로킹)
}

private void startLinuxAsyncRead(PendingFuture future) {
    // io_uring 사용 예
    struct io_uring_sqe *sqe = io_uring_get_sqe(&ring);
    io_uring_prep_read(sqe, fd, buffer, size, offset);
    io_uring_sqe_set_data(sqe, future);
    io_uring_submit(&ring);  // 커널에 요청 제출
    
    // 완료 감지 스레드가 별도로 실행 중
}
```

**단계 3: I/O 완료 감지 및 콜백 실행**

```java
// I/O 완료 감지 스레드 (AsynchronousChannelGroup 내부)
class IoCompletionPoller implements Runnable {
    public void run() {
        while (!shutdown) {
            // 커널에서 완료된 I/O 확인
            CompletedIoOperation[] completed = pollCompletedIo();
            
            for (CompletedIoOperation op : completed) {
                PendingFuture future = op.getFuture();
                
                if (op.isSuccessful()) {
                    // 성공 콜백 실행
                    CompletionHandler handler = future.handler();
                    handler.completed(op.getBytesTransferred(), 
                                    future.attachment());
                } else {
                    // 실패 콜백 실행
                    handler.failed(op.getException(), 
                                 future.attachment());
                }
            }
        }
    }
}
```

**실행 타임라인:**

```
시간   메인 스레드              I/O 스레드           커널
------------------------------------------------------------
0ms   read() 호출
1ms   I/O 요청 생성
2ms   커널에 제출             
3ms   즉시 반환
4ms   performOtherTasks()
...                           
50ms                          pollCompletedIo()
51ms                          완료 감지           I/O 완료
52ms                          completed() 호출
53ms                          processData()
```

메인 스레드는 I/O 요청 후 즉시 다른 작업을 수행하고, I/O 완료는 별도 스레드가 감지하여 콜백을 실행한다.

### 2.4 비동기-블로킹 (Asynchronous-Blocking)

#### 개념적 정의

비동기-블로킹은 드문 조합이다. 작업 완료는 콜백으로 통지받지만(비동기), 어떤 이유로 초기 설정이나 등록 과정에서 블로킹이 발생한다(블로킹).

#### 실제 구현 예시

```java
public class AsyncBlockingExample {
    private final ExecutorService executor = Executors.newCachedThreadPool();
    private final BlockingQueue<CompletionHandler> handlerQueue = 
        new LinkedBlockingQueue<>(10);  // 크기 제한
    
    public void processWithBlockingRegistration(Request request) 
            throws InterruptedException {
        
        CompletionHandler handler = new CompletionHandler() {
            @Override
            public void onComplete(Response response) {
                // 비동기 완료 처리
                System.out.println("처리 완료: " + response);
            }
        };
        
        // 핸들러 등록 (큐가 가득 차면 블로킹!)
        handlerQueue.put(handler);  // 블로킹 가능
        
        // 비동기 작업 시작
        executor.submit(() -> {
            try {
                Response response = performLongTask(request);
                CompletionHandler h = handlerQueue.take();
                h.onComplete(response);  // 비동기 통지
            } catch (Exception e) {
                handleError(e);
            }
        });
        
        // put() 이후에만 반환
        System.out.println("작업 제출 완료");
    }
}
```

이 패턴이 발생하는 실제 시나리오:

1. **레거시 시스템 통합**: 오래된 시스템이 콜백 등록 자체를 동기적으로 처리
2. **리소스 제한**: 콜백 핸들러 수 제한으로 등록 대기
3. **초기화 지연**: 비동기 시스템 초기화가 완료될 때까지 대기

```java
// 실제 사례: JDBC 연결 풀과 비동기 래퍼
public class AsyncDatabaseWrapper {
    private DataSource dataSource;  // 블로킹 연결 풀
    private ExecutorService executor;
    
    public CompletableFuture<ResultSet> queryAsync(String sql) {
        CompletableFuture<ResultSet> future = new CompletableFuture<>();
        
        executor.submit(() -> {
            try {
                // 연결 획득 시 블로킹 가능
                Connection conn = dataSource.getConnection();  // 블로킹!
                
                Statement stmt = conn.createStatement();
                ResultSet rs = stmt.executeQuery(sql);
                
                // 비동기 완료 통지
                future.complete(rs);
            } catch (SQLException e) {
                future.completeExceptionally(e);
            }
        });
        
        return future;  // 즉시 반환 (논블로킹처럼 보임)
    }
}
```

이 경우 `queryAsync()` 자체는 즉시 반환하지만, 실제 실행 스레드는 연결 풀에서 블로킹될 수 있다.

---

## 3. 스레드 상태 전이와 운영체제 스케줄링

### 3.1 JVM 스레드 상태와 OS 스레드 상태의 매핑

JVM의 스레드 상태는 운영체제의 네이티브 스레드 상태와 1:1로 매핑된다.

```java
// java.lang.Thread.State 열거형
public enum State {
    NEW,           // 생성됨, 아직 시작 안 됨
    RUNNABLE,      // 실행 중 또는 실행 가능
    BLOCKED,       // 모니터 락 대기
    WAITING,       // 무기한 대기
    TIMED_WAITING, // 시간 제한 대기
    TERMINATED     // 종료됨
}
```

이것이 Linux 커널 태스크 상태와 어떻게 매핑되는가:

```c
// Linux kernel: include/linux/sched.h
#define TASK_RUNNING          0x0000  // 실행 중 또는 준비됨
#define TASK_INTERRUPTIBLE    0x0001  // 인터럽트 가능 대기
#define TASK_UNINTERRUPTIBLE  0x0002  // 인터럽트 불가 대기
#define TASK_STOPPED          0x0004  // 정지됨
#define TASK_TRACED           0x0008  // 디버거에 의해 추적 중

// JVM 매핑
JVM RUNNABLE     → TASK_RUNNING
JVM BLOCKED      → TASK_UNINTERRUPTIBLE
JVM WAITING      → TASK_INTERRUPTIBLE
JVM TIMED_WAITING → TASK_INTERRUPTIBLE (with timeout)
```

### 3.2 블로킹 I/O 시 스레드 상태 전이 상세

블로킹 I/O가 발생하면 다음과 같은 상태 전이가 일어난다:

```java
// Java 코드
InputStream is = socket.getInputStream();
int data = is.read();  // 블로킹 지점
```

**상태 전이 시퀀스:**

```
1. Java 메서드 호출
   Thread.State: RUNNABLE
   OS State: TASK_RUNNING
   
2. JNI를 통한 네이티브 메서드 호출
   native int read0(int fd, byte[] b, int off, int len)
   
3. 시스템 콜 진입
   sys_read(fd, buffer, count)
   
4. 데이터 없음 감지
   if (no_data_available) {
       current->state = TASK_INTERRUPTIBLE;
       add_wait_queue(&socket->wait_queue, current);
   }
   
5. 컨텍스트 스위치
   schedule() 호출
   - 현재 스레드의 레지스터 저장
   - 다음 실행 가능한 태스크 선택
   - 새 태스크의 레지스터 복원
   
6. 대기 상태 유지
   Thread.State: RUNNABLE (JVM 관점)
   OS State: TASK_INTERRUPTIBLE (실제)
   
7. 데이터 도착 (네트워크 인터럽트)
   - IRQ 핸들러 실행
   - 데이터를 소켓 버퍼로 복사
   - wake_up(&socket->wait_queue)
   
8. 스레드 깨어남
   current->state = TASK_RUNNING
   
9. 스케줄러가 CPU 할당
   - 실행 큐에 추가
   - 다음 스케줄링 시점에 실행
   
10. read() 반환
    Thread.State: RUNNABLE
    OS State: TASK_RUNNING
```

### 3.3 컨텍스트 스위치의 실제 비용

컨텍스트 스위치는 다음 작업을 포함한다:

```assembly
; x86-64 컨텍스트 스위치 (단순화)
context_switch:
    ; 현재 스레드 레지스터 저장
    push %rax
    push %rbx
    push %rcx
    push %rdx
    push %rsi
    push %rdi
    push %rbp
    push %r8
    push %r9
    push %r10
    push %r11
    push %r12
    push %r13
    push %r14
    push %r15
    
    ; 스택 포인터 저장
    mov %rsp, current_thread->sp
    
    ; 새 스레드 스택 포인터 로드
    mov next_thread->sp, %rsp
    
    ; 새 스레드 레지스터 복원
    pop %r15
    pop %r14
    ; ... (나머지 레지스터들)
    
    ; 페이지 테이블 전환 (필요시)
    mov next_thread->mm->pgd, %cr3
    
    ret
```

**측정된 비용 (Intel Xeon E5-2680):**
- 레지스터 저장/복원: ~1μs
- 캐시 무효화: ~2μs (L1/L2 캐시)
- TLB 플러시: ~2μs (페이지 테이블 캐시)
- 총 비용: ~5μs per switch

10,000개 스레드가 초당 2번씩 스위치하면:
```
10,000 threads × 2 switches/sec × 5μs = 100ms/sec = 10% CPU
```

### 3.4 논블로킹 I/O의 스레드 효율성

논블로킹 I/O는 스레드 상태 전이를 최소화한다:

```java
// Netty의 EventLoop (단순화)
public class NioEventLoop implements Runnable {
    private final Selector selector;
    
    public void run() {
        while (!shutdown) {
            // 1. 이벤트 대기 (제한된 블로킹)
            int ready = selector.select(100);  // 최대 100ms
            
            // 2. 준비된 이벤트 처리 (논블로킹)
            if (ready > 0) {
                processSelectedKeys();
            }
            
            // 3. 예약된 작업 실행
            runAllTasks(ioTime * (100 - ioRatio) / ioRatio);
        }
    }
}
```

**스레드 상태 분석:**
```
시간    상태        작업
--------------------------------
0ms    RUNNING    selector.select() 호출
1ms    WAITING    epoll_wait() 대기
50ms   RUNNING    이벤트 처리
51ms   RUNNING    작업 1 실행
52ms   RUNNING    작업 2 실행
53ms   RUNNING    작업 3 실행
100ms  RUNNING    selector.select() 재호출
```

하나의 스레드가 수천 개의 연결을 처리할 수 있는 이유:
- 스레드는 대부분 RUNNING 상태 유지
- I/O 대기는 커널이 처리 (epoll)
- 준비된 이벤트만 처리 (no blocking)

---

## 4. 작업 단위와 실행 단위의 분리

### 4.1 전통적 모델: 스레드 = 작업

전통적인 Thread-per-Request 모델에서는 하나의 스레드가 하나의 작업을 처음부터 끝까지 담당한다.

```java
public class TraditionalWebServer {
    public void handleRequest(Socket clientSocket) {
        // 이 스레드가 요청 전체를 처리
        Thread requestHandler = new Thread(() -> {
            try {
                // 1. 요청 읽기 (블로킹)
                BufferedReader reader = new BufferedReader(
                    new InputStreamReader(clientSocket.getInputStream())
                );
                String request = reader.readLine();
                
                // 2. 데이터베이스 조회 (블로킹)
                String data = queryDatabase(request);
                
                // 3. 외부 API 호출 (블로킹)
                String apiResult = callExternalApi(data);
                
                // 4. 응답 전송 (블로킹)
                PrintWriter writer = new PrintWriter(
                    clientSocket.getOutputStream()
                );
                writer.println(apiResult);
                writer.flush();
                
            } catch (Exception e) {
                handleError(e);
            }
        });
        
        requestHandler.start();  // 새 OS 스레드 생성
    }
}
```

**이 모델의 메모리 구조:**

```
Thread-1 Stack:
├─ handleRequest()
├─ readLine() [BLOCKED]
├─ queryDatabase() [BLOCKED]
├─ callExternalApi() [BLOCKED]
└─ println()

Thread-2 Stack:
├─ handleRequest()
├─ readLine() [BLOCKED]
└─ ...

각 스레드가 요청 처리의 전체 문맥을 스택에 보유
```

### 4.2 논블로킹 모델: 스레드 ≠ 작업

논블로킹 모델에서는 작업이 여러 단계로 분리되고, 각 단계가 다른 스레드에서 실행될 수 있다.

```java
public class NonBlockingWebServer {
    private final EventLoop eventLoop;
    
    public void handleRequest(ChannelHandlerContext ctx, HttpRequest request) {
        // 작업을 상태 객체로 표현
        RequestContext requestContext = new RequestContext(request);
        
        // 단계 1: 데이터베이스 조회 시작 (논블로킹)
        databaseClient.query(request.getParam("id"))
            .whenComplete((data, error) -> {
                if (error != null) {
                    ctx.writeAndFlush(errorResponse(error));
                    return;
                }
                
                requestContext.setData(data);
                
                // 단계 2: API 호출 시작 (논블로킹)
                apiClient.call(data)
                    .whenComplete((apiResult, apiError) -> {
                        if (apiError != null) {
                            ctx.writeAndFlush(errorResponse(apiError));
                            return;
                        }
                        
                        // 단계 3: 응답 전송 (논블로킹)
                        ctx.writeAndFlush(successResponse(apiResult));
                    });
            });
    }
}
```

**작업 상태의 힙 저장:**

```java
public class RequestContext {
    private final HttpRequest originalRequest;
    private String databaseResult;
    private String apiResult;
    private CompletionStage currentStage;
    
    // 작업 상태를 객체로 유지
    // 스레드 스택이 아닌 힙에 저장
}
```

**실행 흐름:**
```
시간   EventLoop-1        EventLoop-2        작업 상태(힙)
------------------------------------------------------------
0ms   요청 수신                            RequestContext 생성
1ms   DB 쿼리 시작                         state: DB_PENDING
2ms   다른 요청 처리
...
50ms                     DB 응답 처리       state: DB_COMPLETE
51ms                     API 호출 시작      state: API_PENDING
52ms                     다른 요청 처리
...
100ms  API 응답 처리                        state: API_COMPLETE
101ms  HTTP 응답 전송                       state: FINISHED
```

### 4.3 메모리 효율성 비교

**블로킹 모델 (1000 동시 요청):**
```
스레드 수: 1000
스택 메모리: 1000 × 1MB = 1GB
힙 메모리: 요청 데이터 ~100MB
총 메모리: ~1.1GB

각 스레드 스택에:
- 메서드 호출 프레임
- 지역 변수
- 중간 결과
```

**논블로킹 모델 (1000 동시 요청):**
```
스레드 수: 4 (CPU 코어 수)
스택 메모리: 4 × 1MB = 4MB
힙 메모리: 
  - RequestContext 객체: 1000 × 1KB = 1MB
  - 요청 데이터: ~100MB
총 메모리: ~105MB

힙에:
- RequestContext 객체들
- 콜백 체인
- 중간 결과
```

**10배 이상의 메모리 효율성 차이**

---

## 5. CompletableFuture의 이중 구조 심화 분석

### 5.1 CompletableFuture의 아키텍처

CompletableFuture는 두 개의 다른 패러다임을 하나로 통합한 구조다.

```java
public class CompletableFuture<T> implements Future<T>, CompletionStage<T> {
    // 내부 상태
    volatile Object result;       // 결과 또는 예외
    volatile Completion stack;    // 콜백 체인
    
    // 실행을 위한 Executor
    private static final Executor ASYNC_POOL = 
        ForkJoinPool.commonPool();
}
```

### 5.2 계층별 동작 분석

```java
public class CompletableFutureAnalysis {
    
    public void demonstrateDualNature() {
        // 레이어 1: 사용자 관점 (비동기-논블로킹)
        CompletableFuture<String> future = 
            CompletableFuture.supplyAsync(() -> {
                // 레이어 2: 워커 스레드 관점 (동기-블로킹)
                return performBlockingOperation();
            });
        
        // 메인 스레드는 즉시 계속 (논블로킹)
        System.out.println("작업 제출 완료");
        
        // 콜백 체인 등록 (비동기)
        future
            .thenApply(this::transform)      // 변환
            .thenAccept(this::consume)       // 소비
            .exceptionally(this::handleError); // 예외 처리
    }
    
    private String performBlockingOperation() {
        // RestTemplate은 블로킹 I/O 수행
        RestTemplate restTemplate = new RestTemplate();
        
        // 이 워커 스레드는 여기서 블로킹됨
        String result = restTemplate.getForObject(
            "https://api.example.com/data", 
            String.class
        );
        
        // 데이터베이스도 블로킹
        jdbcTemplate.update("INSERT INTO logs ...");
        
        return result;
    }
}
```

### 5.3 내부 실행 메커니즘

**작업 제출 시:**

```java
// CompletableFuture.supplyAsync() 내부
public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier) {
    return asyncSupplyStage(ASYNC_POOL, supplier);
}

static <U> CompletableFuture<U> asyncSupplyStage(
        Executor e, Supplier<U> f) {
    CompletableFuture<U> d = new CompletableFuture<>();
    
    // AsyncSupply 태스크 생성 및 실행
    e.execute(new AsyncSupply<U>(d, f));
    
    return d;  // 즉시 반환
}

// AsyncSupply 실행
static final class AsyncSupply<T> extends ForkJoinTask<Void> {
    CompletableFuture<T> dep;
    Supplier<T> fn;
    
    public void run() {
        try {
            // 워커 스레드에서 실행 (블로킹 가능)
            T result = fn.get();
            
            // 결과 설정 및 콜백 트리거
            dep.completeValue(result);
        } catch (Throwable ex) {
            dep.completeThrowable(ex);
        }
    }
}
```

**실행 타임라인:**

```
시간   메인 스레드          ForkJoinPool-Worker-1    상태
-----------------------------------------------------------------
0ms   supplyAsync()
1ms   AsyncSupply 생성
2ms   execute() 호출
3ms   Future 반환
4ms   다른 작업 수행       run() 시작
5ms   ...                 fn.get() 호출
6ms   ...                 RestTemplate.get()      [BLOCKED]
...   ...                 [네트워크 대기]         [BLOCKED]
206ms ...                 응답 수신
207ms ...                 completeValue()
208ms                     콜백 체인 실행
```

### 5.4 ForkJoinPool의 작업 도용(Work Stealing)

CompletableFuture가 사용하는 ForkJoinPool은 work-stealing 알고리즘을 구현한다.

```java
public class ForkJoinPool extends AbstractExecutorService {
    // 각 워커는 자신의 작업 큐를 가짐
    static final class WorkQueue {
        ForkJoinTask<?>[] array;  // 작업 배열
        int base;                  // 도용 인덱스 (다른 스레드가 접근)
        int top;                   // 푸시 인덱스 (소유 스레드만 접근)
        
        // 작업 추가 (소유 스레드)
        void push(ForkJoinTask<?> task) {
            array[top++] = task;
        }
        
        // 작업 도용 (다른 스레드)
        ForkJoinTask<?> steal() {
            return array[base++];
        }
    }
}
```

**Work Stealing 동작:**
```
Worker-1 Queue: [Task1, Task2, Task3, Task4]
Worker-2 Queue: [Empty]

Worker-2가 유휴 상태 → Worker-1에서 Task1 도용
Worker-1은 Task4부터 처리 (LIFO)
Worker-2는 Task1 처리 (FIFO)

결과: 부하 균형 자동 조절
```

### 5.5 한계와 문제점

```java
public class CompletableFutureLimitations {
    private final ExecutorService executor = 
        Executors.newFixedThreadPool(10);
    
    public void demonstrateLimitation() {
        List<CompletableFuture<String>> futures = new ArrayList<>();
        
        // 100개의 블로킹 작업 제출
        for (int i = 0; i < 100; i++) {
            CompletableFuture<String> future = 
                CompletableFuture.supplyAsync(() -> {
                    // 각 작업이 2초 블로킹
                    return slowBlockingOperation();
                }, executor);
            
            futures.add(future);
        }
        
        // 스레드 풀 크기 = 10
        // 동시 실행 = 10개
        // 총 시간 = 100 / 10 * 2초 = 20초
        
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
            .join();
    }
    
    private String slowBlockingOperation() {
        try {
            // HTTP 호출 (2초 블로킹)
            Thread.sleep(2000);
            return "result";
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }
}
```

**실행 분석:**
```
시간    실행 중인 작업    대기 중인 작업    완료된 작업
-----------------------------------------------------
0s     1-10           11-100          0
2s     11-20          21-100          1-10
4s     21-30          31-100          1-20
...
18s    91-100         없음            1-90
20s    없음           없음            1-100
```

워커 스레드가 블로킹되면 다른 작업을 처리할 수 없어, 스레드 풀 크기가 병목이 된다.

---

## 6. 실무 적용: 선택 기준과 최적화 전략

### 6.1 작업 특성별 선택 가이드

#### CPU 집약적 작업

```java
public class CpuIntensiveTask {
    // 옳은 선택: 동기-블로킹 또는 병렬 스트림
    public List<Integer> calculatePrimes(int max) {
        return IntStream.range(2, max)
            .parallel()  // ForkJoinPool 사용
            .filter(this::isPrime)
            .boxed()
            .collect(Collectors.toList());
    }
    
    // 잘못된 선택: 불필요한 비동기
    public CompletableFuture<List<Integer>> calculatePrimesAsync(int max) {
        // CPU 작업에 비동기는 오버헤드만 추가
        return CompletableFuture.supplyAsync(() -> {
            return calculatePrimes(max);
        });
    }
}
```

#### I/O 집약적 작업

```java
public class IoIntensiveTask {
    // 초급: 동기-블로킹
    public List<String> fetchDataSequential(List<String> urls) {
        return urls.stream()
            .map(url -> restTemplate.getForObject(url, String.class))
            .collect(Collectors.toList());
        // 시간: urls.size() * 평균응답시간
    }
    
    // 중급: CompletableFuture로 병렬화
    public List<String> fetchDataParallel(List<String> urls) {
        List<CompletableFuture<String>> futures = urls.stream()
            .map(url -> CompletableFuture.supplyAsync(() -> 
                restTemplate.getForObject(url, String.class)))
            .collect(Collectors.toList());
        
        return futures.stream()
            .map(CompletableFuture::join)
            .collect(Collectors.toList());
        // 시간: max(응답시간들)
    }
    
    // 고급: 완전 논블로킹
    public Flux<String> fetchDataReactive(List<String> urls) {
        return Flux.fromIterable(urls)
            .flatMap(url -> webClient.get()
                .uri(url)
                .retrieve()
                .bodyToMono(String.class));
        // 리소스 효율 최대
    }
}
```

### 6.2 점진적 마이그레이션 전략

```java
public class MigrationStrategy {
    
    // 1단계: 기존 블로킹 코드
    public OrderResponse processOrderV1(OrderRequest request) {
        User user = userService.getUser(request.getUserId());
        Product product = productService.getProduct(request.getProductId());
        Payment payment = paymentService.charge(user, product);
        Shipping shipping = shippingService.arrange(product, user);
        
        return new OrderResponse(payment, shipping);
    }
    
    // 2단계: 병렬 실행으로 개선
    public OrderResponse processOrderV2(OrderRequest request) {
        CompletableFuture<User> userFuture = 
            CompletableFuture.supplyAsync(() -> 
                userService.getUser(request.getUserId()));
        
        CompletableFuture<Product> productFuture = 
            CompletableFuture.supplyAsync(() -> 
                productService.getProduct(request.getProductId()));
        
        // 병렬 실행
        CompletableFuture<Payment> paymentFuture = 
            userFuture.thenCombine(productFuture, 
                (user, product) -> paymentService.charge(user, product));
        
        CompletableFuture<Shipping> shippingFuture = 
            userFuture.thenCombine(productFuture,
                (user, product) -> shippingService.arrange(product, user));
        
        // 결과 조합
        return paymentFuture.thenCombine(shippingFuture, 
            OrderResponse::new).join();
    }
    
    // 3단계: 완전 논블로킹 (Reactive)
    public Mono<OrderResponse> processOrderV3(OrderRequest request) {
        Mono<User> userMono = userReactiveService.getUser(request.getUserId());
        Mono<Product> productMono = productReactiveService.getProduct(request.getProductId());
        
        Mono<Payment> paymentMono = Mono.zip(userMono, productMono)
            .flatMap(tuple -> paymentReactiveService.charge(tuple.getT1(), tuple.getT2()));
        
        Mono<Shipping> shippingMono = Mono.zip(userMono, productMono)
            .flatMap(tuple -> shippingReactiveService.arrange(tuple.getT2(), tuple.getT1()));
        
        return Mono.zip(paymentMono, shippingMono)
            .map(tuple -> new OrderResponse(tuple.getT1(), tuple.getT2()));
    }
}
```

### 6.3 성능 측정과 튜닝

```java
public class PerformanceOptimization {
    
    // 스레드 풀 크기 결정
    public int calculateOptimalThreadPoolSize() {
        int cpuCores = Runtime.getRuntime().availableProcessors();
        double targetCpuUtilization = 0.8;  // 80% 목표
        double waitTimeRatio = 0.9;  // I/O 대기 시간 비율
        
        // Little's Law 적용
        int optimalSize = (int) (cpuCores * targetCpuUtilization * 
                                 (1 + waitTimeRatio));
        
        return optimalSize;  // 예: 8코어 시스템 → 13개 스레드
    }
    
    // 성능 모니터링
    public void monitorThreadPool(ThreadPoolExecutor executor) {
        ScheduledExecutorService monitor = 
            Executors.newSingleThreadScheduledExecutor();
        
        monitor.scheduleAtFixedRate(() -> {
            System.out.println("=== Thread Pool Stats ===");
            System.out.println("Pool Size: " + executor.getPoolSize());
            System.out.println("Active: " + executor.getActiveCount());
            System.out.println("Completed: " + executor.getCompletedTaskCount());
            System.out.println("Queue Size: " + executor.getQueue().size());
            
            // 포화 상태 감지
            if (executor.getQueue().size() > 100) {
                System.err.println("WARNING: Queue backing up!");
            }
        }, 0, 1, TimeUnit.SECONDS);
    }
}
```

---

## 결론: 개념의 명확한 이해와 올바른 적용

### 핵심 정리

1. **블로킹/논블로킹은 제어권 반환 시점**을 다룬다. 함수가 즉시 반환하는가, 작업 완료 후 반환하는가의 문제다.

2. **동기/비동기는 완료 확인 방식**을 다룬다. 호출자가 확인하는가, 시스템이 알려주는가의 문제다.

3. **두 개념은 완전히 독립적**이다. 4가지 조합이 모두 실재하며, 각각 다른 사용 사례를 가진다.

4. **CompletableFuture는 이중 구조**를 가진다. 사용자에게는 비동기-논블로킹으로 보이지만, 워커 스레드는 동기-블로킹으로 동작한다.

5. **진정한 논블로킹은 작업과 스레드의 분리**를 의미한다. 작업 상태를 객체로 관리하고, 스레드는 단순히 실행 자원이 된다.

### 실무 적용 지침

- **CPU 집약적**: 동기-블로킹 유지, 병렬 처리로 개선
- **I/O 집약적**: 비동기-논블로킹으로 전환 고려
- **레거시 통합**: CompletableFuture로 점진적 개선
- **고성능 요구**: 완전 논블로킹 (Reactive) 도입

### 최종 통찰

블로킹과 논블로킹의 차이는 단순한 API 차이가 아니라, **시스템 아키텍처의 근본적 차이**다. 스레드를 작업 단위로 보느냐, 실행 자원으로 보느냐의 패러다임 전환이다. 이 차이를 정확히 이해할 때, 시스템의 확장성과 효율성을 극대화할 수 있다.

---

## 참고 자료

### 기술 명세
- Java Language Specification, Chapter 17: Threads and Locks
- Linux Kernel Documentation: Scheduling
- Intel 64 and IA-32 Architectures Software Developer's Manual

### 구현 소스 코드
- OpenJDK Source: java.util.concurrent
- Linux Kernel Source: kernel/sched/
- Netty Framework: io.netty.channel

### 실무 가이드
- "Java Concurrency in Practice" - Brian Goetz
- "Reactive Programming with RxJava" - Tomasz Nurkiewicz
- "High Performance Browser Networking" - Ilya Grigorik