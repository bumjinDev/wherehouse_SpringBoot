# ForkJoinPool I/O 대기의 실제 동작: JVM 스레드와 커널 스케줄러 계층 분석

## 문서 개요

본 문서는 ForkJoinPool에서 발생하는 "I/O 작업을 받을 때까지 대기한다"는 추상화된 표현의 실제 메커니즘을 운영체제 커널 수준, JVM 런타임 수준, 그리고 애플리케이션 수준의 세 계층으로 분해하여 분석한다. 각 계층에서 발생하는 구체적인 상태 전환과 제어 흐름을 명시함으로써, ForkJoinPool이 I/O-bound 작업에 부적합한 구조적 이유를 증명한다.

---

## 1. 서론: 추상화된 표현과 실제 메커니즘 간의 간극

### 1.1 문제 제기

ForkJoinPool 문서나 강의에서 등장하는 "I/O 작업을 받을 때까지 대기한다"는 표현은 실제로는 세 개의 서로 다른 계층에서 발생하는 복잡한 상태 전환과 제어권 이동을 단순화한 추상화이다. 이 추상화 뒤에는 애플리케이션 수준(Java 코드), JVM 런타임 수준(네이티브 스레드 관리), 그리고 커널 수준(OS 스케줄러)의 메커니즘이 계층적으로 연쇄 작용한다.

### 1.2 핵심 질문

"I/O 대기"라는 개념이 각 계층에서 어떤 구체적인 상태 전환과 제어 흐름으로 구현되는지 이해하지 못하면, ForkJoinPool이 왜 I/O 작업에 부적합한지, 그리고 CompletableFuture의 비동기 I/O가 왜 다른 접근법을 요구하는지를 근본적으로 이해할 수 없다.

### 1.3 분석 방법론

본 문서는 Operating System Concepts에서 다루는 프로세스/스레드 스케줄링 모델을 기반으로, JVM의 스레드 구현이 이를 어떻게 활용하는지, 그리고 ForkJoinPool의 work-stealing 메커니즘이 이 구조 위에서 어떻게 동작하는지를 계층별로 분해한다.

---

## 2. 본론: 계층별 I/O 대기 메커니즘의 실제 동작

### 2.1 운영체제 수준: I/O 블로킹 시 스레드 상태 전환의 실제 흐름

#### 2.1.1 초기 상태: Running → Waiting 전환

CPU에서 실행 중이던 스레드(정확히는 커널 수준 스레드, Kernel-Level Thread)가 I/O 시스템 콜(예: `read()`, `write()`, `accept()` 등)을 호출하면, 커널은 즉시 해당 스레드를 CPU에서 제거하고 Waiting 상태로 전환한다. 이는 운영체제 이론에서 말하는 스레드 상태 전환 모델의 실제 구현이다.

이 시점에서 발생하는 일:

1. 커널은 해당 스레드의 컨텍스트(레지스터, 스택 포인터 등)를 PCB(Process Control Block) 또는 TCB(Thread Control Block)에 저장한다.

2. 스레드는 특정 I/O 디바이스의 대기 큐(wait queue)에 연결된다. 예를 들어 네트워크 소켓에서 데이터를 기다리는 경우, 해당 소켓 파일 디스크립터에 연결된 대기 큐에 추가된다.

3. 스케줄러는 Ready Queue에서 다음 실행 가능한 스레드를 선택하여 CPU에 할당한다.

#### 2.1.2 I/O 완료 후: Waiting → Ready → Running 전환

I/O 작업이 완료되면(예: 네트워크 패킷 도착, 디스크 읽기 완료), 다음과 같은 순차적 단계를 거친다:

**단계 1: 인터럽트 발생**
하드웨어 장치가 인터럽트를 발생시켜 커널에 I/O 완료를 알린다.

**단계 2: Interrupt Handler 실행**
커널의 인터럽트 핸들러가 실행되어 대기 큐에서 해당 스레드를 찾는다.

**단계 3: Ready Queue 이동**
스레드를 대기 큐에서 제거하고 스케줄러의 Ready Queue에 삽입한다. 이때 스레드 상태는 Ready 상태로 변경된다.

**단계 4: 스케줄링 대기**
스레드는 Ready Queue에서 스케줄러가 CPU를 할당해주기를 기다린다. 스케줄링 알고리즘(Round-Robin, Priority-based 등)에 따라 우선순위와 대기 시간을 고려하여 선택된다.

**단계 5: CPU 할당**
스케줄러가 이 스레드를 선택하면, 컨텍스트 스위칭을 통해 CPU 제어권을 획득하고 I/O 시스템 콜 이후의 코드를 실행한다.

#### 2.1.3 구조적 포인트: Ready Queue의 필수성

I/O 완료 후 즉시 실행되는 것이 아니라, 반드시 Ready Queue를 거쳐 스케줄러의 선택을 받아야 한다. 이는 CPU 자원의 공정한 분배를 보장하기 위한 설계이다. 

만약 I/O 완료 즉시 실행을 보장하면, I/O 완료 시점의 우연성에 의해 스케줄링 공정성이 깨진다. 예를 들어 100ms 블로킹된 스레드 A와 10초 블로킹된 스레드 B가 있을 때, A가 반복적으로 먼저 깨어나 CPU를 선점하게 되면 B는 기아(starvation) 상태에 빠질 수 있다. Ready Queue를 거치면 스케줄러의 우선순위 알고리즘(time slice, aging 등)이 개입하여 각 스레드에 공정한 CPU 시간을 배분할 수 있다.

또한 I/O 완료 시점에 CPU가 다른 중요한 작업을 처리 중일 수 있다. Ready Queue는 이러한 경우 스케줄러가 시스템 전체의 우선순위를 고려하여 최적의 컨텍스트 스위칭 시점을 결정할 수 있게 한다.

### 2.2 JVM 수준: Java 스레드와 커널 스레드의 매핑 구조

#### 2.2.1 1:1 스레드 매핑 모델

JVM의 스레드 모델은 운영체제의 네이티브 스레드 모델 위에 구현된다. 현대 JVM(HotSpot 기준)은 **1:1 스레드 매핑 모델**을 사용한다. 이는 다음을 의미한다:

**Java Thread ↔ Kernel Thread 직접 매핑**
- `new Thread().start()`로 생성된 Java 스레드 하나는 정확히 하나의 OS 네이티브 스레드(Kernel-Level Thread)에 매핑된다.
- Java 코드에서 `InputStream.read()`나 `Socket.accept()` 같은 블로킹 I/O를 호출하면, 내부적으로 JNI(Java Native Interface)를 통해 OS의 시스템 콜을 직접 호출한다.
  - JNI는 Java 코드가 C/C++로 작성된 네이티브 코드를 호출할 수 있게 하는 인터페이스이다. 시스템 콜은 사용자 모드에서 커널 모드로의 특권 수준 전환을 요구하는 특수 명령이므로, Java는 사용자 모드에서만 실행되기 때문에 네이티브 코드를 통해 이 전환을 수행해야 한다.
  - 구체적으로, Java의 `read()` 메서드는 JNI를 통해 C로 구현된 네이티브 메서드를 호출하고, 이 네이티브 메서드가 POSIX `read()` 시스템 콜(또는 Windows의 `ReadFile()`)을 호출하여 커널 모드로 진입한다.
- 따라서 Java 스레드의 블로킹은 곧 커널 스레드의 블로킹이며, 2.1절에서 설명한 OS 수준의 상태 전환이 그대로 발생한다.

#### 2.2.2 JVM이 개입하지 않는 구조적 이유

JVM은 스레드가 I/O 블로킹 상태에 진입한 후에는 아무런 제어권을 갖지 못한다. 스레드의 상태 관리와 스케줄링은 전적으로 OS 커널이 담당한다. JVM이 할 수 있는 일은 다음으로 제한된다:

1. 스레드 생성 시 네이티브 스레드를 생성하고 Java 스레드 객체와 연결
   - 네이티브 스레드(Native Thread)는 운영체제가 직접 관리하는 커널 수준 스레드로, JVM 외부에서 실제로 CPU를 할당받아 실행되는 스레드를 의미한다.
2. 스레드 종료 시 네이티브 스레드 정리

**JVM은 스레드가 언제 I/O에서 반환될지, 언제 CPU를 다시 할당받을지 알 수 없으며, 이를 제어할 수도 없다. 이는 Java 스레드가 운영체제의 스케줄링 정책에 전적으로 의존한다는 것을 의미한다.**

### 2.3 ForkJoinPool의 I/O 블로킹 문제: Work-Stealing과 커널 스케줄링의 충돌

#### 2.3.1 ForkJoinPool의 설계 전제: CPU-bound 작업

ForkJoinPool은 다음과 같은 아키텍처를 가진다:

- Worker 스레드 수 = `Runtime.getRuntime().availableProcessors()` (기본값)
- 각 Worker 스레드는 자신의 작업 큐(deque)를 가진다
- Work-stealing: 유휴 Worker가 다른 Worker의 큐에서 작업을 훔쳐온다
- **가정**: 모든 작업은 CPU-bound이며, 블로킹 없이 신속하게 완료된다

이 설계는 작업이 CPU를 집약적으로 사용하며, 블로킹 없이 빠르게 완료된다는 전제 위에 최적화되었다.

#### 2.3.2 I/O 블로킹 시 발생하는 구조적 문제

ForkJoinPool의 Worker 스레드가 I/O 블로킹 작업을 실행하면 다음과 같은 일련의 문제가 발생한다:

**문제 1: 커널 수준 블로킹 발생**

Worker 스레드(Java 스레드 = 커널 스레드)가 `fileService.findSearch01()` 같은 블로킹 I/O 호출을 수행한다. 내부적으로 OS 시스템 콜이 호출되고, 커널이 해당 스레드를 Waiting 상태로 전환한다. 스레드는 I/O 대기 큐로 이동하고 CPU에서 제거된다.

**문제 2: ForkJoinPool의 통제력 상실**

ForkJoinPool은 이 Worker 스레드가 블로킹되었다는 사실을 알 수 없다. Work-stealing 메커니즘은 "다른 Worker의 큐에 작업이 있는지"만 확인할 뿐, "어떤 Worker가 I/O에서 블로킹되었는지"는 알 수 없다. JVM 수준에서는 스레드가 단지 "실행 중"으로 보인다. 실제 블로킹 상태는 커널만 알고 있다.

**문제 3: 스레드 자원 고갈**

4개의 Worker 스레드 중 3개가 I/O 블로킹 상태라면, 실제로 CPU를 사용할 수 있는 스레드는 1개뿐이다. 나머지 CPU 코어들은 유휴 상태가 되지만, ForkJoinPool은 새 Worker를 생성하지 않는다. 이는 이미 설정된 parallelism에 도달했기 때문이다. ForkJoinPool의 작업 큐에 계산 작업들이 쌓여있어도, Worker 스레드들이 커널의 I/O 대기 큐에서 블로킹 상태이므로 이 작업들을 가져와 실행할 수 없는 상황이 발생한다. 커널의 Ready Queue(실행 가능한 스레드들의 큐)와 ForkJoinPool의 작업 큐(실행할 태스크들의 큐)는 서로 다른 계층의 자료구조이며, 전자는 커널 스케줄러가, 후자는 JVM이 관리한다.

**문제 4: I/O 완료 후 재실행 과정**

I/O가 완료되면 다음 과정을 거친다:
1. I/O 완료 → 인터럽트 발생
2. 커널이 스레드를 Ready Queue에 삽입
3. 스케줄러가 이 스레드를 선택하면 CPU 할당
4. 스레드는 I/O 시스템 콜 이후 지점부터 실행 재개
5. `thenAccept()`의 콜백 실행

그러나 이 전체 과정 동안 다른 Worker 스레드들은 여전히 블로킹 상태일 수 있다. 이는 전체 시스템의 처리량을 심각하게 저하시킨다.

#### 2.3.3 "I/O 작업을 받을 때까지 대기"의 실제 의미

- **애플리케이션 수준**: CompletableFuture 객체가 완료되지 않은 상태로 유지됨
- **JVM 수준**: Java 스레드가 블로킹 메서드 내부에서 대기
- **커널 수준**: 커널 스레드가 Waiting 상태로 I/O 대기 큐에 있으며, I/O 완료 후 Ready Queue → 스케줄러 선택 → CPU 할당의 경로를 따라 재실행됨

### 2.4 사용자 정의 ForkJoinPool과 I/O 바운드 처리의 실제 동작

#### 2.4.1 코드 분석: 생성 스레드 풀

다음과 같은 코드를 고려한다:

```java
int parallelism = 4; // 원하는 병렬 스레드 수
ForkJoinPool customPool = new ForkJoinPool(parallelism);
CompletableFuture<Integer> future = CompletableFuture.supplyAsync(() -> {
    return fileService.findSearch01(); // I/O Bound 작업
}, customPool); // 스레드 풀을 외부로 정의
```

#### 2.4.2 실제 동작 흐름의 단계별 분석

**단계 1: 작업 제출**

`supplyAsync()`가 호출되면 customPool의 작업 큐에 람다 작업이 추가된다. ForkJoinPool의 Worker 스레드 중 하나가 이 작업을 가져와 실행을 시작한다.

**단계 2: I/O 블로킹 진입**

Worker 스레드가 `fileService.findSearch01()` 메서드를 실행한다. 내부적으로 HTTP 클라이언트나 JDBC 등의 블로킹 I/O가 호출된다. 시스템 콜이 발생한다. 예를 들어 `read(socket_fd, buffer, size)`가 호출된다.

**커널 동작:**
1. 현재 스레드(Worker)의 컨텍스트를 TCB에 저장
2. 스레드 상태를 Waiting 상태로 변경
3. 스레드를 소켓의 wait queue에 연결
4. CPU 스케줄러를 호출하여 다른 스레드에게 CPU 할당

**단계 3: 대기 기간**

Worker 스레드는 메모리에 존재하지만 CPU를 사용하지 않는다. 커널의 I/O 대기 큐에서 네트워크 패킷 도착을 기다린다. 이 시간 동안 ForkJoinPool의 다른 Worker들이 다른 작업을 처리하거나, 역시 I/O에서 블로킹될 수 있다.

**단계 4: I/O 완료 및 재개**

네트워크 패킷이 도착하면 다음 과정이 진행된다:

1. **NIC 인터럽트**: 네트워크 패킷 도착 → NIC(Network Interface Card)가 인터럽트 발생

2. **인터럽트 핸들러 실행**:
   - 소켓 버퍼에 데이터 복사
   - wait queue에서 대기 중인 스레드(Worker) 찾기
   - 스레드를 wait queue에서 제거하고 Ready Queue에 삽입
   - 스레드 상태를 Ready 상태로 변경

3. **스케줄링 대기**: 스레드는 Ready Queue에서 스케줄러의 선택을 기다린다.

4. **CPU 할당**: 스케줄러가 이 스레드를 선택하면 컨텍스트 스위칭이 발생한다:
   - TCB에 저장된 레지스터 복원
   - 프로그램 카운터를 `read()` 시스템 콜 반환 지점으로 설정
   - 스레드 실행 재개

5. **작업 완료**: `fileService.findSearch01()`의 반환값을 받아 CompletableFuture 완료 처리를 수행한다. 이때 `thenAccept()` 콜백이 **I/O에서 깨어난 동일한 Worker 스레드에서 동기적으로 실행**된다.
   - `thenAccept()`는 CompletableFuture의 비동기 작업이 완료된 후 실행될 후속 작업을 등록하는 메서드로, I/O 결과를 받아 추가 처리(예: 결과 출력, 데이터 변환 등)를 수행한다.
   - 중요한 점은, 단순 `thenAccept()`는 작업을 완료한 스레드에서 직접 실행되므로, 콜백 처리 시간만큼 Worker 스레드가 추가로 점유된다. 이는 ForkJoinPool의 스레드 자원 고갈 문제를 더욱 악화시킨다.
   - 만약 `thenAcceptAsync(executor)`를 사용하면 콜백을 다른 스레드 풀로 위임할 수 있지만, 기본 `thenAccept()`는 동일 스레드에서 동기 실행된다.

**단계 5: ForkJoinPool의 제한된 관점**

ForkJoinPool은 이 전체 과정에서 "작업이 제출되었고, 언젠가 완료될 것"만 알 뿐이다. 스레드가 언제 블로킹되었는지, 언제 재개되었는지 알 수 없다. Work-stealing은 "큐에 작업이 있는지"만 확인하므로, 블로킹된 스레드를 보상할 방법이 없다.

#### 2.4.3 구조적 설계 결함

ForkJoinPool의 작업 분할 및 work-stealing 메커니즘은 "작업이 짧고 CPU-bound"라는 전제 위에 설계되었다. 그러나 I/O 블로킹은 다음과 같은 특성을 가진다:

1. **작업을 길게 만든다**: 네트워크 지연 시간만큼 작업이 늘어난다 (수십~수백 ms)
2. **CPU를 사용하지 않는다**: 커널 I/O 대기 상태에서는 CPU 사이클을 전혀 소비하지 않는다
3. **예측 불가능하다**: 네트워크 상황에 따라 지연 시간이 수 밀리초에서 수 초까지 변동한다

따라서 parallelism=4로 설정해도, 4개 스레드가 모두 I/O에서 블로킹되면 실제 병렬 처리 능력은 0이 된다. 이것이 강의 자료에서 "기본 스레드 풀"의 문제점으로 지적된 이유다.

### 2.5 올바른 I/O 비동기 처리: 별도 스레드 풀의 구조적 필요성

#### 2.5.1 ThreadPoolExecutor 기반 I/O 전용 풀

다음 코드를 고려한다:

```java
ExecutorService ioExecutor = Executors.newFixedThreadPool(20);

CompletableFuture<Integer> future = CompletableFuture.supplyAsync(() -> {
    return fileService.findSearch01(); // I/O 작업
}, ioExecutor); // I/O 전용 스레드 풀 사용
```

#### 2.5.2 이 설계가 해결하는 구조적 문제

**해결책 1: 스레드 자원 격리**

ForkJoinPool(CPU 작업용)과 ioExecutor(I/O 작업용)를 분리한다. I/O 작업이 블로킹되어도 ForkJoinPool의 Worker들은 영향받지 않는다. CPU-bound 계산 작업은 계속 병렬 처리가 가능하다.

**해결책 2: 스레드 수 최적화 전략 분리**

작업 유형에 따라 최적 스레드 수가 다르다:

- **CPU-bound**: 스레드 수 ≈ CPU 코어 수 (컨텍스트 스위칭 최소화)
- **I/O-bound**: 스레드 수 >> CPU 코어 수 (블로킹 시간 동안 다른 스레드 실행)

I/O 스레드가 블로킹되어도 충분한 여유 스레드가 새 작업을 처리할 수 있다.

**해결책 3: 커널 수준의 병렬성 활용**

20개의 I/O 스레드가 동시에 다른 소켓에서 I/O 대기가 가능하다. 각 스레드는 독립적으로 "커널 대기 → Ready Queue → CPU 할당" 사이클을 수행한다. 일부 스레드가 I/O 대기 중이어도 다른 스레드들이 CPU를 사용하여 새 요청을 발송할 수 있다.

#### 2.5.3 실제 런타임 동작 예시

다음과 같은 상황을 고려한다:

- 스레드 1: Kakao API 요청 전송 → 커널 I/O 대기
- 스레드 2: 다른 Kakao API 요청 전송 → 커널 I/O 대기
- 스레드 3: 이미 완료된 응답 처리 중(CPU 사용)
- 스레드 4-20: Ready Queue에서 스케줄링 대기 또는 새 작업 대기

각 스레드는 독립적으로 "요청 전송 → 커널 블로킹 → 응답 도착 → Ready Queue → CPU 할당 → 응답 처리 → 다음 작업"의 사이클을 반복한다. 커널 스케줄러는 각 스레드의 I/O 완료를 독립적으로 관리하고, JVM은 이 모든 스레드를 관리한다.

---

## 3. 결론: 추상화 계층의 분리와 설계적 책임

### 3.1 패러다임 변화: 동기 I/O에서 비동기 I/O로

#### 3.1.1 전통적인 동기 I/O 모델

전통적인 동기 I/O 모델(스레드 블로킹 방식)은 다음과 같은 제어 흐름을 가진다:

애플리케이션 → JVM → 커널 시스템 콜 → 커널 블로킹 → I/O 완료 → 커널 스케줄링 → JVM 재개 → 애플리케이션

이 모델에서 "대기"는 물리적으로 스레드가 커널의 I/O 대기 큐에 있다가 Ready Queue를 거쳐 CPU를 다시 할당받는 과정이다. 이는 컨텍스트 스위칭, 메모리 오버헤드, 스케줄링 지연을 동반한다.

#### 3.1.2 CompletableFuture 기반 비동기 I/O 모델

CompletableFuture와 별도 스레드 풀을 사용하는 비동기 I/O 모델은 이 흐름을 다음과 같이 재구성한다:

1. 작업 유형에 따라 스레드 풀을 분리하여 자원 격리
2. I/O 블로킹이 발생해도 다른 계층(CPU 계산)에 영향을 주지 않음
3. 커널 수준의 병렬 I/O 대기를 최대한 활용

### 3.2 아키텍처 관점의 의의

"I/O 대기"라는 추상적 표현을 이해하기 위해서는 다음 세 계층의 메커니즘을 모두 이해해야 한다:

**계층 1: 커널 계층**
- 스레드 상태 전환(Running → Waiting → Ready → Running)
- I/O 대기 큐
- 인터럽트 처리
- 스케줄러 알고리즘

**계층 2: JVM 계층**
- Java 스레드와 커널 스레드의 1:1 매핑
- JNI를 통한 시스템 콜
- 스레드 생명주기 관리

**계층 3: 애플리케이션 계층**
- ForkJoinPool의 work-stealing
- CompletableFuture의 비동기 체인
- ExecutorService를 통한 스레드 풀 제어

각 계층은 서로 다른 추상화 수준에서 작동하며, 하위 계층의 동작 방식이 상위 계층의 설계 제약을 결정한다. ForkJoinPool이 I/O에 부적합한 이유는 단순히 "블로킹되어서"가 아니라, **커널의 스레드 스케줄링 메커니즘과 ForkJoinPool의 work-stealing 알고리즘 사이의 정보 비대칭성** 때문이다.

### 3.3 설계적 책임: 실전 프로젝트에서의 적용

#### 3.3.1 스레드 풀 분리의 이유

Kakao API 호출과 같은 I/O 작업은 커널 수준에서 스레드를 블로킹시키므로, CPU-bound 작업용 ForkJoinPool과 격리해야 한다. 블로킹된 스레드는 Ready Queue → 스케줄러 선택 → CPU 재할당의 경로를 거치므로, 충분한 여유 스레드 풀이 필요하다.

#### 3.3.2 스레드 수 설정의 근거

I/O 전용 ExecutorService의 스레드 수를 20으로 설정하는 이유는 동시에 실행될 수 있는 I/O 요청 수의 상한을 의미한다. 각 스레드는 "HTTP 요청 전송 → 커널 I/O 블로킹 → 응답 도착 시 Ready Queue 진입 → 스케줄러 선택 후 응답 처리"의 독립적인 사이클을 수행한다.

#### 3.3.3 성능 측정 시 고려사항

응답 시간에는 "네트워크 지연 + Ready Queue 대기 시간 + 응답 처리 시간"이 모두 포함된다. 스레드 수를 늘려도 네트워크 지연은 줄어들지 않으므로, 최적 스레드 수는 "블로킹 시간 동안 새 요청을 발송할 수 있는 충분한 수"가 되어야 한다.

### 3.4 기술 백서 작성 시 포함해야 할 내용

실전 프로젝트의 기술 백서에서 이러한 메커니즘을 정확히 설명함으로써, 단순히 "CompletableFuture를 사용했다"가 아니라 "왜 이 설계가 구조적으로 필요한지, 그리고 각 계층에서 어떤 메커니즘이 작동하는지"를 증명할 수 있다.

구체적으로 다음 사항을 명시해야 한다:

1. I/O 작업의 블로킹 특성을 커널 수준에서 설명
2. ForkJoinPool의 work-stealing이 작동하지 않는 이유를 메커니즘 수준에서 분석
3. ThreadPoolExecutor의 스레드 수 설정 근거를 정량적으로 제시
4. 실측 성능 데이터와 이론적 분석의 연결

---

## 4. 요약 및 핵심 포인트

### 4.1 계층별 I/O 대기 메커니즘

**운영체제 수준:**
- I/O 시스템 콜 → 스레드 Waiting 상태 전환 → I/O 대기 큐 삽입
- I/O 완료 → 인터럽트 → Ready Queue 삽입 → 스케줄러 선택 → CPU 할당

**JVM 수준:**
- Java 스레드와 커널 스레드의 1:1 매핑
- 블로킹 I/O는 JNI를 통해 직접 시스템 콜 호출
- JVM은 스레드 블로킹 후 제어권 없음

**ForkJoinPool 수준:**
- Work-stealing은 큐의 작업 존재 여부만 확인
- 스레드의 블로킹 상태를 감지 불가
- CPU 코어 수로 제한된 Worker로는 I/O 병렬성 부족

### 4.2 ForkJoinPool이 I/O에 부적합한 구조적 이유

1. **정보 비대칭성**: 커널만 스레드의 블로킹 상태를 알고, ForkJoinPool은 알 수 없음
2. **스레드 수 제약**: CPU 코어 수만큼의 Worker로는 충분한 I/O 병렬성 확보 불가
3. **Work-stealing 무용화**: I/O 블로킹 시간 >> 작업 생성 시간으로 인해 stealing할 작업 부족
4. **동적 확장 불가**: Parallelism 제한으로 블로킹 시 추가 Worker 생성 불가

### 4.3 ThreadPoolExecutor가 I/O에 적합한 이유

1. **유연한 스레드 수**: I/O 병렬성을 고려한 충분한 스레드 할당 가능
2. **단순한 큐 구조**: 복잡한 work-stealing 불필요, 공유 큐로 충분
3. **블로킹 허용 설계**: 많은 스레드가 블로킹되어도 시스템 동작 가능
4. **독립적 I/O 처리**: 각 스레드가 커널 수준에서 독립적으로 I/O 대기

---

## 5. 참고 문헌 및 추가 학습 자료

### 5.1 운영체제 스케줄링
- Operating System Concepts (Silberschatz et al.)
- Linux Kernel Development (Robert Love)

### 5.2 JVM 스레드 모델
- Java Concurrency in Practice (Brian Goetz)
- The Java Virtual Machine Specification

### 5.3 ForkJoinPool 설계
- A Java Fork/Join Framework (Doug Lea)
- Java 8 in Action (Raoul-Gabriel Urma et al.)

---

## 문서 버전 정보
- 버전: 1.0
- 작성일: 2025-11-17
- 분석 대상: ForkJoinPool I/O 블로킹 메커니즘
- 키워드: ForkJoinPool, I/O Blocking, Kernel Thread, Work-Stealing, Thread Pool